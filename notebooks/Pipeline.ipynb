{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sb\n",
    "\n",
    "# Read and sanitize the data\n",
    "df = pd.read_excel(\"./UG_HH_NEW_continuous_no200.xls\")\n",
    "#df = pd.read_excel(\"./UG_HH_NEW_categorical_no200.xls\")\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "NORMALISE_DATA = True\n",
    "\n",
    "\n",
    "x = df.values[:, 3:-1]\n",
    "y = df.values[:, -1:]\n",
    "\n",
    "if NORMALISE_DATA:\n",
    "    x_min = x.min(axis=0)\n",
    "    x_max = x.max(axis=0)\n",
    "    x = (x - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (continuous dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import multiply\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "def simple_model(loss=None, metrics=None):\n",
    "    \"\"\"\n",
    "    build a simple regression model\n",
    "    :param loss: (str|callable, default: mse)\n",
    "    \"\"\"\n",
    "    if loss is None:\n",
    "        loss = \"mse\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3, input_dim=NB_FEATURES, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer='Adam', metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy / Loss - For model comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GAIN = 200\n",
    "\n",
    "def loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute loss for the ultimatum game,\n",
    "    as the difference between the possible gain and the actual one\n",
    "    \"\"\"\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    rejected = min_offer > predicted\n",
    "    res = predicted - min_offer\n",
    "    if rejected.sum() != 0:\n",
    "        res[rejected] = MAX_GAIN - min_offer[rejected]\n",
    "    bad_predictions = (predicted < 0) | (predicted > MAX_GAIN)\n",
    "    if bad_predictions.sum() != 0:\n",
    "        res[bad_predictions] = MAX_GAIN - min_offer[bad_predictions]\n",
    "    return res\n",
    "\n",
    "def loss_sum(min_offer, predicted):\n",
    "    return loss(min_offer, predicted).sum()\n",
    "\n",
    "def avg_loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute avg loss for the ultimatum game\n",
    "    \"\"\"\n",
    "    return np.mean(loss(min_offer, predicted))\n",
    "\n",
    "def mse(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute mse using the loss as error\n",
    "    \"\"\"\n",
    "    return np.mean(np.square(loss(min_offer, predicted)))\n",
    "\n",
    "def rejection_ratio(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute ratio of rejected proposals without consideration of values\n",
    "    \"\"\"\n",
    "    accepted = (min_offer <= predicted)\n",
    "    return 1 - np.mean(accepted)\n",
    "\n",
    "def avg_win_loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute avg_loss of accepted proposals\n",
    "    \"\"\"\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    accepted = (min_offer <= predicted)\n",
    "    if accepted.sum() == 0:\n",
    "        return 0\n",
    "    return avg_loss(min_offer[accepted], predicted[accepted])\n",
    "\n",
    "\n",
    "def gain(min_offer, predicted):\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()    \n",
    "    res = MAX_GAIN - predicted\n",
    "    res[predicted < min_offer] = 0\n",
    "    return res\n",
    "\n",
    "def avg_loss_ratio(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute the avg gain ratio in relation to the maximal gain\n",
    "    \"\"\"\n",
    "    return 1 - np.mean(gain(min_offer, predicted) / gain(min_offer, min_offer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: put a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_functions = [avg_loss, mse, rejection_ratio, avg_win_loss, avg_loss_ratio, loss_sum]\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def process_model(model, xTrain, yTrain, xTest, yTest, fit_kwargs=None, predict_kwargs=None):\n",
    "    fit_kwargs = {} if fit_kwargs is None else fit_kwargs\n",
    "    predict_kwargs = {} if predict_kwargs is None else predict_kwargs\n",
    "    model.fit(xTrain, yTrain, **fit_kwargs)\n",
    "    yPredict = model.predict(xTest, **predict_kwargs)\n",
    "    results = {func.__name__: func(yTest, yPredict) for func in benchmark_functions}\n",
    "    return results\n",
    "    \n",
    "def process_benchmark_cv(model, X, y, cv=5, metrics=None, fit_kwargs=None, predict_kwargs=None):\n",
    "    kf = KFold(n_splits=cv)\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        xTrain, yTrain = X[train_index], y[train_index]\n",
    "        xTest, yTest = X[test_index], y[test_index]\n",
    "        benchmark_result = process_model(model, xTrain, yTrain, xTest, yTest, fit_kwargs, predict_kwargs)\n",
    "        results.append(benchmark_result)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sci-kit like training\n",
    "# sm = simple_model(\"mse\") \n",
    "# history = sm.fit(xTrain, yTrain, validation_split=0.33, epochs=100, batch_size=64, verbose=0)\n",
    "# loss_hist = pd.DataFrame(data={'loss': history.history['loss']})\n",
    "# loss_hist.plot(figsize=(30,10))\n",
    "# smPredict = sm.predict(xTest, batch_size=128)\n",
    "\n",
    "# out_data = pd.DataFrame(data={'y_test': np.ravel(yTest), 'y_pred': np.ravel(smPredict)})\n",
    "# stl = sm.evaluate(xTest, yTest, verbose=0)\n",
    "# print(\"Results: %2.2f (%.2f) MSE, Scalar test loss: %.2f\" % (smPredict.mean(), smPredict.std(), stl))\n",
    "# #out_data.plot(figsize=(30,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gain_ratio(yTest, smPredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation of the the \"accuracy\" *gain_ratio* **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#gr = process_mlp(xTrain, yTrain, xTest, yTest, loss_gain_sigmoid, [gain_ratio_tf, \"mse\"], validation_split=1/4, verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation checking mse, mse+offset(poor), and loss_gain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_mlp_cv(x, y, loss_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_mlp_cv(x, y, loss_mse_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_mlp_cv(x, y, loss_gain_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#process_mlp_cv(x, y, loss_gain_sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Featureless model (fixed value)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLessModel(object):\n",
    "    def __init__(self, max_value, loss=None):\n",
    "        self.value = None\n",
    "        self.max_value = max_value\n",
    "        self.loss = loss or avg_loss_ratio\n",
    "        self._trained = False\n",
    "    \n",
    "    def fit(self, xTrain, yTrain, **kwargs):\n",
    "        min_loss = float('inf')\n",
    "        best_value = 0\n",
    "        for value in np.arange(self.max_value):\n",
    "            fixedPredict = np.ones_like(yTrain) * value\n",
    "            loss = self.loss(yTrain, fixedPredict)\n",
    "            if loss < min_loss:\n",
    "                min_loss = loss\n",
    "                best_value = value\n",
    "        self._trained = True\n",
    "        self.value = best_value\n",
    "    \n",
    "    def predict(self, xTrain, **kwargs):\n",
    "        if not self._trained:\n",
    "            raise ValueError(\"The model first need to be trained!!!\")\n",
    "        res = np.ones((xTrain.shape[0], 1) ) * self.value\n",
    "        return res\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.916667</td>\n",
       "      <td>0.212045</td>\n",
       "      <td>25.294118</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1664.583333</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.250000</td>\n",
       "      <td>0.227199</td>\n",
       "      <td>23.030303</td>\n",
       "      <td>945.0</td>\n",
       "      <td>1396.527778</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.262607</td>\n",
       "      <td>25.937500</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1861.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.750000</td>\n",
       "      <td>0.192169</td>\n",
       "      <td>21.323529</td>\n",
       "      <td>855.0</td>\n",
       "      <td>1296.527778</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.571429</td>\n",
       "      <td>0.196613</td>\n",
       "      <td>24.558824</td>\n",
       "      <td>930.0</td>\n",
       "      <td>1332.857143</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    avg_loss  avg_loss_ratio  avg_win_loss  loss_sum          mse  \\\n",
       "0  27.916667        0.212045     25.294118    1005.0  1664.583333   \n",
       "1  26.250000        0.227199     23.030303     945.0  1396.527778   \n",
       "2  30.000000        0.262607     25.937500    1080.0  1861.111111   \n",
       "3  23.750000        0.192169     21.323529     855.0  1296.527778   \n",
       "4  26.571429        0.196613     24.558824     930.0  1332.857143   \n",
       "\n",
       "   rejection_ratio  \n",
       "0         0.055556  \n",
       "1         0.083333  \n",
       "2         0.111111  \n",
       "3         0.055556  \n",
       "4         0.028571  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FeatureLessModel(MAX_GAIN, loss=avg_loss)\n",
    "res = process_benchmark_cv(model, x, y)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convervative model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConservativeModel(object):\n",
    "    def __init__(self, max_value):\n",
    "        self.value = None\n",
    "        self.max_value = max_value\n",
    "        self._trained = False\n",
    "\n",
    "    def fit(self, xTrain, yTrain, **kwargs):\n",
    "        self.value = self.max_value - 1\n",
    "        self._trained = True\n",
    "    \n",
    "    def predict(self, xTest, **kwargs):\n",
    "        if not self._trained:\n",
    "            raise ValueError(\"The model should first be trained\")\n",
    "        return np.ones((xTest.shape[0], 1)) * self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121.361111</td>\n",
       "      <td>0.991272</td>\n",
       "      <td>121.361111</td>\n",
       "      <td>4369.0</td>\n",
       "      <td>15643.083333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116.916667</td>\n",
       "      <td>0.990883</td>\n",
       "      <td>116.916667</td>\n",
       "      <td>4209.0</td>\n",
       "      <td>14550.583333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117.888889</td>\n",
       "      <td>0.986044</td>\n",
       "      <td>117.888889</td>\n",
       "      <td>4244.0</td>\n",
       "      <td>15124.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117.194444</td>\n",
       "      <td>0.991019</td>\n",
       "      <td>117.194444</td>\n",
       "      <td>4219.0</td>\n",
       "      <td>14533.361111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122.714286</td>\n",
       "      <td>0.991665</td>\n",
       "      <td>122.714286</td>\n",
       "      <td>4295.0</td>\n",
       "      <td>15572.142857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     avg_loss  avg_loss_ratio  avg_win_loss  loss_sum           mse  \\\n",
       "0  121.361111        0.991272    121.361111    4369.0  15643.083333   \n",
       "1  116.916667        0.990883    116.916667    4209.0  14550.583333   \n",
       "2  117.888889        0.986044    117.888889    4244.0  15124.333333   \n",
       "3  117.194444        0.991019    117.194444    4219.0  14533.361111   \n",
       "4  122.714286        0.991665    122.714286    4295.0  15572.142857   \n",
       "\n",
       "   rejection_ratio  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConservativeModel(MAX_GAIN)\n",
    "res = process_benchmark_cv(model, x, y)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# regressor = LinearRegression(copy_X=True)\n",
    "# res = process_benchmark_cv(regressor, x, y)\n",
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random forest regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#model = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=10)\n",
    "model = RandomForestClassifier()\n",
    "res = process_benchmark_cv(model, x, y.ravel())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomModel(object):\n",
    "    def __init__(self, max_value):\n",
    "        self.value = max_value\n",
    "        self._trained = False\n",
    "\n",
    "    def fit(self, xTrain, yTrain, **kwargs):\n",
    "        self._trained = True\n",
    "    \n",
    "    def predict(self, xTest, **kwargs):\n",
    "        if not self._trained:\n",
    "            raise ValueError(\"The model should first be trained\")\n",
    "        return np.random.random((xTest.shape[0], 1)) * self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.943469</td>\n",
       "      <td>0.696981</td>\n",
       "      <td>58.141184</td>\n",
       "      <td>2985.964866</td>\n",
       "      <td>8832.529562</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.301764</td>\n",
       "      <td>0.732303</td>\n",
       "      <td>73.124500</td>\n",
       "      <td>3106.863507</td>\n",
       "      <td>9229.827661</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.478808</td>\n",
       "      <td>0.684484</td>\n",
       "      <td>67.169483</td>\n",
       "      <td>2789.237078</td>\n",
       "      <td>7856.372625</td>\n",
       "      <td>0.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.603314</td>\n",
       "      <td>0.576651</td>\n",
       "      <td>44.161709</td>\n",
       "      <td>2325.719296</td>\n",
       "      <td>6128.532745</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.695946</td>\n",
       "      <td>0.631246</td>\n",
       "      <td>57.146005</td>\n",
       "      <td>2684.358119</td>\n",
       "      <td>7844.318755</td>\n",
       "      <td>0.342857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    avg_loss  avg_loss_ratio  avg_win_loss     loss_sum          mse  \\\n",
       "0  82.943469        0.696981     58.141184  2985.964866  8832.529562   \n",
       "1  86.301764        0.732303     73.124500  3106.863507  9229.827661   \n",
       "2  77.478808        0.684484     67.169483  2789.237078  7856.372625   \n",
       "3  64.603314        0.576651     44.161709  2325.719296  6128.532745   \n",
       "4  76.695946        0.631246     57.146005  2684.358119  7844.318755   \n",
       "\n",
       "   rejection_ratio  \n",
       "0         0.416667  \n",
       "1         0.361111  \n",
       "2         0.305556  \n",
       "3         0.361111  \n",
       "4         0.342857  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomModel(MAX_GAIN)\n",
    "res = process_benchmark_cv(model, x, y)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MeanShift, DBSCAN, SpectralClustering, Birch, MiniBatchKMeans, AffinityPropagation\n",
    "\n",
    "\n",
    "class ClusterModel(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        if \"base_model\" in kwargs:\n",
    "            base_model_ = kwargs.pop(\"base_model\")\n",
    "            if isinstance(base_model_, str):\n",
    "                models = {\n",
    "                    \"kmeans\": KMeans,\n",
    "                    \"meanshift\": MeanShift,\n",
    "                    \"birch\": Birch,\n",
    "                    \"spectral\": SpectralClustering,\n",
    "                    \"minibatch\": MiniBatchKMeans,\n",
    "                    \"affinity\": AffinityPropagation,\n",
    "                }\n",
    "                self.base_model = models.get(base_model_, MeanShift)(**kwargs)\n",
    "            else:\n",
    "                self.base_model = base_model_\n",
    "        else:\n",
    "            self.base_model = MeanShift(**kwargs)\n",
    "        super().__init__()\n",
    "        self.clustersClasses = None\n",
    "        self._trained = False\n",
    "    \n",
    "    def fit(self, xTrain, yTrain, **kwargs):\n",
    "        self.base_model.fit(xTrain)\n",
    "        labels = np.array([item for item in np.unique(self.base_model.labels_) if item >= 0])\n",
    "        clustersClasses = np.zeros_like(labels)\n",
    "        for cluster in range(len(labels)):\n",
    "            values = yTrain[self.base_model.labels_==cluster]\n",
    "            clustersClasses[cluster] = values.mean() + values.std()\n",
    "        self.clustersClasses = clustersClasses\n",
    "        self._trained = True\n",
    "    \n",
    "    def predict(self, xTest, **kwargs):\n",
    "        if self._trained is None:\n",
    "            raise ValueError(\"Model not trained yet\")\n",
    "        predClusters = self.base_model.predict(xTest)\n",
    "        return self.clustersClasses[predClusters]\n",
    "\n",
    "class ClusterExtModel(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        if \"base_model\" in kwargs:\n",
    "            base_model_ = kwargs.pop(\"base_model\")\n",
    "            if isinstance(base_model_, str):\n",
    "                models = {\n",
    "                    \"kmeans\": KMeans,\n",
    "                    \"meanshift\": MeanShift,\n",
    "                    \"dbscan\": DBSCAN,\n",
    "                    \"spectral\": SpectralClustering,\n",
    "                    \"minibatch\": MiniBatchKMeans,\n",
    "                }\n",
    "                self.base_model = models.get(base_model_, MeanShift)(**kwargs)\n",
    "            else:\n",
    "                self.base_model = base_model_\n",
    "        else:\n",
    "            self.base_model = MeanShift(**kwargs)\n",
    "        self._trained = False\n",
    "        self.sub_models = None\n",
    "        self.max_value = MAX_GAIN\n",
    "        \n",
    "    def fit(self, xTrain, yTrain, **kwargs):        \n",
    "        self.base_model.fit(xTrain, yTrain, **kwargs)\n",
    "        labels = np.array([item for item in np.unique(self.base_model.labels_) if item >= 0])\n",
    "        clustersClasses = np.zeros_like(labels)\n",
    "        sub_models = []\n",
    "        for cluster in range(len(labels)):\n",
    "            sub_model = FeatureLessModel(self.max_value)\n",
    "            mask = self.base_model.labels_==cluster\n",
    "            sub_model.fit(xTrain[mask], yTrain[mask])\n",
    "            sub_models.append(sub_model)\n",
    "        # We use an array instead of a list for better indexing\n",
    "        self.clustersClasses = [sub_model.value for sub_model in sub_models]\n",
    "        self.sub_models = np.array(sub_models)\n",
    "        print(self.clustersClasses)\n",
    "        self._trained = True\n",
    "    \n",
    "    def predict(self, xTest, **kwargs):\n",
    "        if self._trained is None:\n",
    "            raise ValueError(\"Model not trained yet\")\n",
    "        predClusters = self.base_model.predict(xTest)\n",
    "        sub_models = self.sub_models[predClusters]\n",
    "        preds = []\n",
    "        dummy_x = np.array([0])\n",
    "        for idx in range(xTest.shape[0]):\n",
    "            preds.append(sub_models[idx].predict(dummy_x))\n",
    "        res = np.array(preds).ravel()\n",
    "        return res\n",
    "        #return self.clustersClasses[predClusters]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([110, 121,  99, 104,  89,  90, 100,  98, 109,  93, 110,  99, 144,\n",
       "        87, 104, 118, 112])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClusterModel(base_model=\"affinity\", )\n",
    "#res = process_benchmark_cv(model, x, y)\n",
    "model.fit(x, y.ravel())\n",
    "model.clustersClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.436018</td>\n",
       "      <td>0.596191</td>\n",
       "      <td>30.816481</td>\n",
       "      <td>2319.696665</td>\n",
       "      <td>5606.077763</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.744591</td>\n",
       "      <td>0.597377</td>\n",
       "      <td>23.400310</td>\n",
       "      <td>2222.805263</td>\n",
       "      <td>5474.712463</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.713889</td>\n",
       "      <td>0.606452</td>\n",
       "      <td>27.511765</td>\n",
       "      <td>2257.700000</td>\n",
       "      <td>5587.652435</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.269444</td>\n",
       "      <td>0.574558</td>\n",
       "      <td>23.594444</td>\n",
       "      <td>2169.700000</td>\n",
       "      <td>5324.722361</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.037164</td>\n",
       "      <td>0.480866</td>\n",
       "      <td>25.740943</td>\n",
       "      <td>1891.300741</td>\n",
       "      <td>4507.754319</td>\n",
       "      <td>0.371429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    avg_loss  avg_loss_ratio  avg_win_loss     loss_sum          mse  \\\n",
       "0  64.436018        0.596191     30.816481  2319.696665  5606.077763   \n",
       "1  61.744591        0.597377     23.400310  2222.805263  5474.712463   \n",
       "2  62.713889        0.606452     27.511765  2257.700000  5587.652435   \n",
       "3  60.269444        0.574558     23.594444  2169.700000  5324.722361   \n",
       "4  54.037164        0.480866     25.740943  1891.300741  4507.754319   \n",
       "\n",
       "   rejection_ratio  \n",
       "0         0.500000  \n",
       "1         0.527778  \n",
       "2         0.527778  \n",
       "3         0.500000  \n",
       "4         0.371429  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "res = process_benchmark_cv(model, x, y.ravel())\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 100, 100, 100, 120, 100, 100, 100, 100, 125, 105, 100, 80, 100, 100, 80]\n",
      "[100, 100, 100, 100, 100, 100, 50, 105, 100, 100, 120, 100, 105, 100, 100, 100]\n",
      "[75, 100, 100, 100, 100, 100, 100, 80, 120, 100, 100, 100, 100, 100, 105, 105]\n",
      "[100, 100, 100, 100, 110, 100, 100, 105, 100, 100, 100, 80, 100, 105, 80, 100]\n",
      "[100, 100, 95, 100, 90, 105, 100, 100, 100, 100, 100, 100, 100, 100, 100, 110]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n",
      "[100]\n"
     ]
    }
   ],
   "source": [
    "benchmark_models = {\n",
    "    #\"random\": RandomModel(MAX_GAIN),\n",
    "    \"affinity\": ClusterModel(base_model=\"affinity\"),\n",
    "    #\"cluster_km\": ClusterModel(base_model=\"kmeans\", n_clusters=16),\n",
    "    #\"cluster_meanshift\": ClusterModel(base_model=\"meanshift\", cluster_all=True),\n",
    "    #\"cluster_birch\": ClusterModel(base_model=\"birch\"),\n",
    "    \"affinity_ext\": ClusterExtModel(base_model=\"kmeans\", n_clusters=16),\n",
    "    \"cluster_ext_meanshift\": ClusterExtModel(base_model=\"meanshift\", cluster_all=True),\n",
    "    #\"cluster_meanshift\": ClusterModel(base_model=\"meanshift\"),\n",
    "    #\"cluster_ext\": ClusterExtModel(base_model=\"birch\"),\n",
    "    #\"linear_regressor\": LinearRegression(copy_X=True),\n",
    "    #\"conservative\": ConservativeModel(MAX_GAIN),\n",
    "    \"featureless\": FeatureLessModel(MAX_GAIN),\n",
    "    #\"random_forest\": RandomForestClassifier(),#max_depth=3, random_state=0, n_estimators=10),\n",
    "    \"random_forest_regr\": RandomForestRegressor(),\n",
    "    #\"nn_regression:\": simple_model(),\n",
    "}\n",
    "\n",
    "results = {key: process_benchmark_cv(model, x, y.ravel()) for key, model in benchmark_models.items()}\n",
    "\n",
    "results_mean = {key: item.mean() for key, item in results.items()}\n",
    "results_std = {key: item.std() for key, item in results.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>affinity</th>\n",
       "      <td>42.093492</td>\n",
       "      <td>0.358552</td>\n",
       "      <td>33.541260</td>\n",
       "      <td>1506.6</td>\n",
       "      <td>2851.099206</td>\n",
       "      <td>0.156349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affinity_ext</th>\n",
       "      <td>28.971429</td>\n",
       "      <td>0.236096</td>\n",
       "      <td>25.815898</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>1687.246032</td>\n",
       "      <td>0.072540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_ext_meanshift</th>\n",
       "      <td>26.897619</td>\n",
       "      <td>0.218127</td>\n",
       "      <td>24.028855</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1510.321429</td>\n",
       "      <td>0.066825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>featureless</th>\n",
       "      <td>26.897619</td>\n",
       "      <td>0.218127</td>\n",
       "      <td>24.028855</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1510.321429</td>\n",
       "      <td>0.066825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest_regr</th>\n",
       "      <td>67.971825</td>\n",
       "      <td>0.628300</td>\n",
       "      <td>25.952460</td>\n",
       "      <td>2433.9</td>\n",
       "      <td>6424.044087</td>\n",
       "      <td>0.552857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        avg_loss  avg_loss_ratio  avg_win_loss  loss_sum  \\\n",
       "affinity               42.093492        0.358552     33.541260    1506.6   \n",
       "affinity_ext           28.971429        0.236096     25.815898    1037.0   \n",
       "cluster_ext_meanshift  26.897619        0.218127     24.028855     963.0   \n",
       "featureless            26.897619        0.218127     24.028855     963.0   \n",
       "random_forest_regr     67.971825        0.628300     25.952460    2433.9   \n",
       "\n",
       "                               mse  rejection_ratio  \n",
       "affinity               2851.099206         0.156349  \n",
       "affinity_ext           1687.246032         0.072540  \n",
       "cluster_ext_meanshift  1510.321429         0.066825  \n",
       "featureless            1510.321429         0.066825  \n",
       "random_forest_regr     6424.044087         0.552857  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_mean).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>affinity</th>\n",
       "      <td>4.367382</td>\n",
       "      <td>0.045683</td>\n",
       "      <td>3.140378</td>\n",
       "      <td>154.062650</td>\n",
       "      <td>308.092206</td>\n",
       "      <td>0.036864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affinity_ext</th>\n",
       "      <td>3.488044</td>\n",
       "      <td>0.032673</td>\n",
       "      <td>3.138044</td>\n",
       "      <td>124.378455</td>\n",
       "      <td>343.136827</td>\n",
       "      <td>0.024588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_ext_meanshift</th>\n",
       "      <td>2.296549</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>1.860146</td>\n",
       "      <td>84.454130</td>\n",
       "      <td>243.413449</td>\n",
       "      <td>0.031429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>featureless</th>\n",
       "      <td>2.296549</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>1.860146</td>\n",
       "      <td>84.454130</td>\n",
       "      <td>243.413449</td>\n",
       "      <td>0.031429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest_regr</th>\n",
       "      <td>5.719627</td>\n",
       "      <td>0.051398</td>\n",
       "      <td>4.958455</td>\n",
       "      <td>215.055632</td>\n",
       "      <td>818.769309</td>\n",
       "      <td>0.050385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       avg_loss  avg_loss_ratio  avg_win_loss    loss_sum  \\\n",
       "affinity               4.367382        0.045683      3.140378  154.062650   \n",
       "affinity_ext           3.488044        0.032673      3.138044  124.378455   \n",
       "cluster_ext_meanshift  2.296549        0.028436      1.860146   84.454130   \n",
       "featureless            2.296549        0.028436      1.860146   84.454130   \n",
       "random_forest_regr     5.719627        0.051398      4.958455  215.055632   \n",
       "\n",
       "                              mse  rejection_ratio  \n",
       "affinity               308.092206         0.036864  \n",
       "affinity_ext           343.136827         0.024588  \n",
       "cluster_ext_meanshift  243.413449         0.031429  \n",
       "featureless            243.413449         0.031429  \n",
       "random_forest_regr     818.769309         0.050385  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_std).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3fc2de4048>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "df_results_mean = pd.DataFrame(results_mean)\n",
    "df_results_std = pd.DataFrame(results_std)\n",
    "df_results_mean.plot.bar(logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.80446927374301, 29.570307886750392)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, -1].mean(), y[:, -1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prop</th>\n",
       "      <th>other_resp</th>\n",
       "      <th>other_prop</th>\n",
       "      <th>time_spent_risk</th>\n",
       "      <th>cells</th>\n",
       "      <th>selfish</th>\n",
       "      <th>time_spent_prop</th>\n",
       "      <th>count_effort</th>\n",
       "      <th>Honesty_Humility</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>min_offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>92.765363</td>\n",
       "      <td>78.156425</td>\n",
       "      <td>79.525140</td>\n",
       "      <td>45955.307263</td>\n",
       "      <td>27.340782</td>\n",
       "      <td>28.379888</td>\n",
       "      <td>53273.743017</td>\n",
       "      <td>13.273743</td>\n",
       "      <td>3.503352</td>\n",
       "      <td>3.307821</td>\n",
       "      <td>3.254190</td>\n",
       "      <td>79.804469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.240156</td>\n",
       "      <td>28.008989</td>\n",
       "      <td>32.652807</td>\n",
       "      <td>29132.942323</td>\n",
       "      <td>16.082689</td>\n",
       "      <td>19.940948</td>\n",
       "      <td>29945.417255</td>\n",
       "      <td>5.305068</td>\n",
       "      <td>0.556564</td>\n",
       "      <td>0.720366</td>\n",
       "      <td>0.595226</td>\n",
       "      <td>29.653254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>26000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>35500.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>39000.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>60500.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>152000.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>269000.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>195.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             prop  other_resp  other_prop  time_spent_risk       cells  \\\n",
       "count  179.000000  179.000000  179.000000       179.000000  179.000000   \n",
       "mean    92.765363   78.156425   79.525140     45955.307263   27.340782   \n",
       "std     28.240156   28.008989   32.652807     29132.942323   16.082689   \n",
       "min     10.000000    5.000000    0.000000         0.000000    1.000000   \n",
       "25%     85.000000   50.000000   50.000000     26000.000000   12.000000   \n",
       "50%    100.000000   80.000000   80.000000     39000.000000   22.000000   \n",
       "75%    100.000000  100.000000  100.000000     60000.000000   48.500000   \n",
       "max    200.000000  190.000000  190.000000    152000.000000   50.000000   \n",
       "\n",
       "          selfish  time_spent_prop  count_effort  Honesty_Humility  \\\n",
       "count  179.000000       179.000000    179.000000        179.000000   \n",
       "mean    28.379888     53273.743017     13.273743          3.503352   \n",
       "std     19.940948     29945.417255      5.305068          0.556564   \n",
       "min      0.000000     16000.000000      0.000000          1.900000   \n",
       "25%     12.500000     35500.000000      9.000000          3.100000   \n",
       "50%     30.000000     47000.000000     14.000000          3.500000   \n",
       "75%     45.000000     60500.000000     18.000000          3.900000   \n",
       "max     60.000000    269000.000000     20.000000          4.900000   \n",
       "\n",
       "       Extraversion  Agreeableness   min_offer  \n",
       "count    179.000000     179.000000  179.000000  \n",
       "mean       3.307821       3.254190   79.804469  \n",
       "std        0.720366       0.595226   29.653254  \n",
       "min        1.100000       1.500000    0.000000  \n",
       "25%        2.900000       2.900000   50.000000  \n",
       "50%        3.400000       3.300000   85.000000  \n",
       "75%        3.800000       3.600000  100.000000  \n",
       "max        4.800000       4.800000  195.000000  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prop</th>\n",
       "      <th>other_resp</th>\n",
       "      <th>other_prop</th>\n",
       "      <th>time_spent_risk</th>\n",
       "      <th>cells</th>\n",
       "      <th>selfish</th>\n",
       "      <th>time_spent_prop</th>\n",
       "      <th>count_effort</th>\n",
       "      <th>Honesty_Humility</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>min_offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>19000</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>55000</td>\n",
       "      <td>20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>60000</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>33000</td>\n",
       "      <td>18</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>31000</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>35000</td>\n",
       "      <td>15</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>12000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>94000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>25000</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>44000</td>\n",
       "      <td>20</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>77000</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>36000</td>\n",
       "      <td>19</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>29000</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>42000</td>\n",
       "      <td>14</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prop  other_resp  other_prop  time_spent_risk  cells  selfish  \\\n",
       "14    100          50          45            19000     20       60   \n",
       "42    100         100          50            60000     50        0   \n",
       "94     10           5           5            31000     50       40   \n",
       "97    160          50          20            12000     11        0   \n",
       "115   100          50          50            25000     25       30   \n",
       "122    20          50          30            77000     36       15   \n",
       "149    10           5           5            29000      4       15   \n",
       "\n",
       "     time_spent_prop  count_effort  Honesty_Humility  Extraversion  \\\n",
       "14             55000            20               3.0           2.6   \n",
       "42             33000            18               4.4           2.5   \n",
       "94             35000            15               2.9           3.5   \n",
       "97             94000             2               3.6           3.8   \n",
       "115            44000            20               2.9           1.8   \n",
       "122            36000            19               3.4           4.0   \n",
       "149            42000            14               2.5           3.8   \n",
       "\n",
       "     Agreeableness  min_offer  \n",
       "14             2.5          5  \n",
       "42             3.0          0  \n",
       "94             3.0         10  \n",
       "97             3.4         10  \n",
       "115            1.6          5  \n",
       "122            3.2         10  \n",
       "149            3.2         10  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.min_offer<=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
