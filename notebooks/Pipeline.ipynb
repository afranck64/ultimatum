{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sb\n",
    "\n",
    "# Read and sanitize the data\n",
    "df = pd.read_excel(\"../data/UG_HH_NEW_continuous_no200.xls\")\n",
    "#df = pd.read_excel(\"./UG_HH_NEW_categorical_no200.xls\")\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "NORMALISE_DATA = False\n",
    "\n",
    "\n",
    "x = df.values[:, :-1]\n",
    "y = df.values[:, -1:]\n",
    "\n",
    "if NORMALISE_DATA:\n",
    "    x_min = x.min(axis=0)\n",
    "    x_max = x.max(axis=0)\n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    \n",
    "NB_FEATURES = x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (continuous dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy / Loss - For model comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GAIN = 200\n",
    "\n",
    "def loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute loss for the ultimatum game,\n",
    "    as the difference between the possible gain and the actual one\n",
    "    \"\"\"\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    rejected = min_offer > predicted\n",
    "    res = predicted - min_offer\n",
    "    if rejected.sum() != 0:\n",
    "        res[rejected] = MAX_GAIN - min_offer[rejected]\n",
    "    bad_predictions = (predicted < 0) | (predicted > MAX_GAIN)\n",
    "    if bad_predictions.sum() != 0:\n",
    "        res[bad_predictions] = MAX_GAIN - min_offer[bad_predictions]\n",
    "    return res\n",
    "\n",
    "def loss_sum(min_offer, predicted):\n",
    "    return loss(min_offer, predicted).sum()\n",
    "\n",
    "def avg_loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute avg loss for the ultimatum game\n",
    "    \"\"\"\n",
    "    return np.mean(loss(min_offer, predicted))\n",
    "\n",
    "def mse(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute mse using the loss as error\n",
    "    \"\"\"\n",
    "    return np.mean(np.square(loss(min_offer, predicted)))\n",
    "\n",
    "def rejection_ratio(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute ratio of rejected proposals without consideration of values\n",
    "    \"\"\"\n",
    "    accepted = (min_offer <= predicted)\n",
    "    return 1 - np.mean(accepted)\n",
    "\n",
    "def avg_win_loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute avg_loss of accepted proposals\n",
    "    \"\"\"\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    accepted = (min_offer <= predicted)\n",
    "    if accepted.sum() == 0:\n",
    "        return 0\n",
    "    return avg_loss(min_offer[accepted], predicted[accepted])\n",
    "\n",
    "\n",
    "def gain(min_offer, predicted):\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()    \n",
    "    res = MAX_GAIN - predicted\n",
    "    res[predicted < min_offer] = 0\n",
    "    return res\n",
    "\n",
    "def avg_loss_ratio(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute the avg gain ratio in relation to the maximal gain\n",
    "    \"\"\"\n",
    "    return 1 - np.mean(gain(min_offer, predicted) / gain(min_offer, min_offer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_functions = [avg_loss, mse, rejection_ratio, avg_win_loss, avg_loss_ratio, loss_sum]\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def process_model(model, xTrain, yTrain, xTest, yTest, fit_kwargs=None, predict_kwargs=None):\n",
    "    fit_kwargs = {} if fit_kwargs is None else fit_kwargs\n",
    "    predict_kwargs = {} if predict_kwargs is None else predict_kwargs\n",
    "    model.fit(xTrain, yTrain, **fit_kwargs)\n",
    "    yPredict = model.predict(xTest, **predict_kwargs)\n",
    "    results = {func.__name__: func(yTest, yPredict) for func in benchmark_functions}\n",
    "    return results\n",
    "    \n",
    "def process_benchmark_cv(model, X, y, cv=5, metrics=None, fit_kwargs=None, predict_kwargs=None):\n",
    "    # We make sure original values aren't modified, even by mistake\n",
    "    X = np.copy(X)\n",
    "    y = np.copy(y)\n",
    "    \n",
    "    kf = KFold(n_splits=cv)\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        xTrain, yTrain = X[train_index], y[train_index]\n",
    "        xTrain, yTrain = DACombine().fit_predict(xTrain, yTrain)\n",
    "        xTest, yTest = X[test_index], y[test_index]\n",
    "        benchmark_result = process_model(model, xTrain, yTrain, xTest, yTest, fit_kwargs, predict_kwargs)\n",
    "        results.append(benchmark_result)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import multiply\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "\n",
    "def sigmoid1024_tf(x):\n",
    "    return (1024**x) / (1024**x + 1)\n",
    "\n",
    "def sigmoid_tf(x):\n",
    "    return K.sigmoid(x)\n",
    "\n",
    "def gain_tf(x):\n",
    "    math_pi = tf.constant(math.pi)\n",
    "    one = tf.constant(1.0)\n",
    "    ten = tf.constant(10.0)\n",
    "    x = tf.math.subtract(y_true, y_pred)\n",
    "    x = tf.math.truediv(x, ten)\n",
    "    left_mul = sigmoid_tf(x)\n",
    "    right_mul = tf.math.cos(tf.math.divide(x, math_pi))\n",
    "    return tf.math.multiply(left_mul, right_mul)\n",
    "\n",
    "def loss_tf(y_true, y_pred):\n",
    "    math_pi = tf.constant(math.pi)\n",
    "    one = tf.constant(1.0)\n",
    "    ten = tf.constant(10.0)\n",
    "    x0 = tf.math.subtract(y_true, y_pred)\n",
    "    x = tf.math.truediv(x0, ten)\n",
    "    left_mul = sigmoid_tf(x)\n",
    "    right_mul = tf.math.cos(tf.math.divide(x, math_pi))\n",
    "    return tf.math.subtract(one*2, tf.math.multiply(left_mul, right_mul))\n",
    "\n",
    "def _keras_model(loss=None, metrics=None):\n",
    "    \"\"\"\n",
    "    build a simple regression model\n",
    "    :param loss: (str|callable, default: loss_tf)\n",
    "    \"\"\"\n",
    "    if loss is None:\n",
    "        loss = loss_tf\n",
    "    if metrics is None:\n",
    "        metrics = [\"mae\"]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=NB_FEATURES, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def keras_model(loss=None, metrics=None, nb_epoch=100, batch_size=32, verbose=False):\n",
    "    build_fn = lambda : _keras_model(loss, metrics)\n",
    "    return KerasRegressor(build_fn=build_fn, epochs=nb_epoch, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sci-kit like training\n",
    "# sm = keras_model(\"mse\") \n",
    "# history = sm.fit(xTrain, yTrain, validation_split=0.33, epochs=100, batch_size=64, verbose=0)\n",
    "# loss_hist = pd.DataFrame(data={'loss': history.history['loss']})\n",
    "# loss_hist.plot(figsize=(30,10))\n",
    "# smPredict = sm.predict(xTest, batch_size=128)\n",
    "\n",
    "# out_data = pd.DataFrame(data={'y_test': np.ravel(yTest), 'y_pred': np.ravel(smPredict)})\n",
    "# stl = sm.evaluate(xTest, yTest, verbose=0)\n",
    "# print(\"Results: %2.2f (%.2f) MSE, Scalar test loss: %.2f\" % (smPredict.mean(), smPredict.std(), stl))\n",
    "# #out_data.plot(figsize=(30,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Featureless model (fixed value)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLessModel(object):\n",
    "    def __init__(self, max_value, loss=None):\n",
    "        self.value = None\n",
    "        self.max_value = max_value\n",
    "        self.loss = loss or avg_loss_ratio\n",
    "        self._trained = False\n",
    "    \n",
    "    def fit(self, xTrain, yTrain, **kwargs):\n",
    "        min_loss = float('inf')\n",
    "        best_value = 0\n",
    "        for value in np.arange(self.max_value):\n",
    "            fixedPredict = np.ones_like(yTrain) * value\n",
    "            loss = self.loss(yTrain, fixedPredict)\n",
    "            if loss < min_loss:\n",
    "                min_loss = loss\n",
    "                best_value = value\n",
    "        self._trained = True\n",
    "        self.value = best_value\n",
    "    \n",
    "    def predict(self, xTrain, **kwargs):\n",
    "        if not self._trained:\n",
    "            raise ValueError(\"The model first need to be trained!!!\")\n",
    "        res = np.ones((xTrain.shape[0], 1) ) * self.value\n",
    "        return res\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convervative model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConservativeModel(object):\n",
    "    def __init__(self, max_value):\n",
    "        self.value = None\n",
    "        self.max_value = max_value\n",
    "        self._trained = False\n",
    "\n",
    "    def fit(self, xTrain, yTrain, **kwargs):\n",
    "        self.value = self.max_value - 1\n",
    "        self._trained = True\n",
    "    \n",
    "    def predict(self, xTest, **kwargs):\n",
    "        if not self._trained:\n",
    "            raise ValueError(\"The model should first be trained\")\n",
    "        return np.ones((xTest.shape[0], 1)) * self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomModel(object):\n",
    "    def __init__(self, max_value):\n",
    "        self.value = max_value\n",
    "        self._trained = False\n",
    "\n",
    "    def fit(self, xTrain, yTrain, **kwargs):\n",
    "        self._trained = True\n",
    "    \n",
    "    def predict(self, xTest, **kwargs):\n",
    "        if not self._trained:\n",
    "            raise ValueError(\"The model should first be trained\")\n",
    "        return np.random.random((xTest.shape[0], 1)) * self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble.forest import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MeanShift, DBSCAN, SpectralClustering, Birch, MiniBatchKMeans, AffinityPropagation\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "\n",
    "class ClusterModel(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        if \"base_model\" in kwargs:\n",
    "            base_model_ = kwargs.pop(\"base_model\")\n",
    "            if isinstance(base_model_, str):\n",
    "                models = {\n",
    "                    \"kmeans\": KMeans,\n",
    "                    \"meanshift\": MeanShift,\n",
    "                    \"birch\": Birch,\n",
    "                    \"spectral\": SpectralClustering,\n",
    "                    \"minibatch\": MiniBatchKMeans,\n",
    "                    \"affinity\": AffinityPropagation,\n",
    "                    \"bayes\": BayesianGaussianMixture,\n",
    "                }\n",
    "                self.base_model = models.get(base_model_, MeanShift)(**kwargs)\n",
    "            else:\n",
    "                self.base_model = base_model_\n",
    "        else:\n",
    "            self.base_model = MeanShift(**kwargs)\n",
    "        super().__init__()\n",
    "        self.clustersClasses = None\n",
    "        self._trained = False\n",
    "    \n",
    "    def fit(self, xTrain, yTrain, **kwargs):\n",
    "        self.base_model.fit(xTrain)\n",
    "        labels = np.array([item for item in np.unique(self.base_model.labels_) if item >= 0])\n",
    "        clustersClasses = np.zeros_like(labels)\n",
    "        for cluster in range(len(labels)):\n",
    "            values = yTrain[self.base_model.labels_==cluster]\n",
    "            clustersClasses[cluster] = values.mean() + values.std()\n",
    "        self.clustersClasses = clustersClasses\n",
    "        self._trained = True\n",
    "    \n",
    "    def predict(self, xTest, **kwargs):\n",
    "        if self._trained is None:\n",
    "            raise ValueError(\"Model not trained yet\")\n",
    "        predClusters = self.base_model.predict(xTest)\n",
    "        return self.clustersClasses[predClusters]\n",
    "\n",
    "class ClusterExtModel(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        if \"base_model\" in kwargs:\n",
    "            base_model_ = kwargs.pop(\"base_model\")\n",
    "            if isinstance(base_model_, str):\n",
    "                models = {\n",
    "                    \"kmeans\": KMeans,\n",
    "                    \"meanshift\": MeanShift,\n",
    "                    \"birch\": Birch,\n",
    "                    \"spectral\": SpectralClustering,\n",
    "                    \"minibatch\": MiniBatchKMeans,\n",
    "                    \"affinity\": AffinityPropagation,\n",
    "                    \"bayes\": BayesianGaussianMixture,\n",
    "                }\n",
    "                self.base_model = models.get(base_model_, MeanShift)(**kwargs)\n",
    "            else:\n",
    "                self.base_model = base_model_\n",
    "        else:\n",
    "            self.base_model = MeanShift(**kwargs)\n",
    "        self._trained = False\n",
    "        self.sub_models = None\n",
    "        self.max_value = MAX_GAIN\n",
    "        \n",
    "    def fit(self, xTrain, yTrain, **kwargs):        \n",
    "        self.base_model.fit(xTrain, yTrain, **kwargs)\n",
    "        labels = np.array([item for item in np.unique(self.base_model.labels_) if item >= 0])\n",
    "        clustersClasses = np.zeros_like(labels)\n",
    "        sub_models = []\n",
    "        for cluster in range(len(labels)):\n",
    "            sub_model = FeatureLessModel(self.max_value)\n",
    "            mask = self.base_model.labels_==cluster\n",
    "            sub_model.fit(xTrain[mask], yTrain[mask])\n",
    "            sub_models.append(sub_model)\n",
    "        # We use an array instead of a list for better indexing\n",
    "        self.clustersClasses = [sub_model.value for sub_model in sub_models]\n",
    "        self.sub_models = np.array(sub_models)\n",
    "        self._trained = True\n",
    "    \n",
    "    def predict(self, xTest, **kwargs):\n",
    "        if self._trained is None:\n",
    "            raise ValueError(\"Model not trained yet\")\n",
    "        predClusters = self.base_model.predict(xTest)\n",
    "        sub_models = self.sub_models[predClusters]\n",
    "        preds = []\n",
    "        dummy_x = np.array([0])\n",
    "        for idx in range(xTest.shape[0]):\n",
    "            preds.append(sub_models[idx].predict(dummy_x))\n",
    "        res = np.array(preds).ravel()\n",
    "        return res\n",
    "        #return self.clustersClasses[predClusters]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Data augmentation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DACombine(object):\n",
    "    def __init__(self, size=None, nb_features=NB_FEATURES):\n",
    "        self.size = size\n",
    "        self.nb_features = nb_features\n",
    "    \n",
    "    def fit_predict(self, xTrain, yTrain, size=None):\n",
    "        size = size or self.size or len(xTrain) * 4\n",
    "        indices = np.arange(self.nb_features)\n",
    "        np.random.shuffle(indices)\n",
    "        targets = yTrain.ravel()\n",
    "        xRes = []\n",
    "        yRes = []\n",
    "        for _ in range(size):\n",
    "            target = np.random.choice(targets)\n",
    "            target_mask = yTrain.ravel()==target\n",
    "            xTrain_target = xTrain[target_mask]\n",
    "            i = np.random.randint(xTrain_target.shape[0])\n",
    "            j = np.random.randint(xTrain_target.shape[0])\n",
    "            x = np.zeros_like(xTrain_target[0])\n",
    "            np.random.shuffle(indices)\n",
    "            split = int(np.random.randint(self.nb_features))\n",
    "            mask_i = indices[:split]\n",
    "            mask_j = indices[split:]\n",
    "            x[mask_i] = xTrain_target[i, mask_i]\n",
    "            x[mask_j] = xTrain_target[j, mask_j]\n",
    "            xRes.append(x)\n",
    "            yRes.append(target)\n",
    "        return np.array(xRes), np.array(yRes)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>119.215079</td>\n",
       "      <td>0.990177</td>\n",
       "      <td>119.215079</td>\n",
       "      <td>4267.200000</td>\n",
       "      <td>15084.700794</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>featureless</th>\n",
       "      <td>26.897619</td>\n",
       "      <td>0.218127</td>\n",
       "      <td>24.028855</td>\n",
       "      <td>963.000000</td>\n",
       "      <td>1510.321429</td>\n",
       "      <td>0.066825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>80.169453</td>\n",
       "      <td>0.686153</td>\n",
       "      <td>64.867733</td>\n",
       "      <td>2868.724604</td>\n",
       "      <td>8065.651091</td>\n",
       "      <td>0.358787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                avg_loss  avg_loss_ratio  avg_win_loss     loss_sum  \\\n",
       "conservative  119.215079        0.990177    119.215079  4267.200000   \n",
       "featureless    26.897619        0.218127     24.028855   963.000000   \n",
       "random         80.169453        0.686153     64.867733  2868.724604   \n",
       "\n",
       "                       mse  rejection_ratio  \n",
       "conservative  15084.700794         0.000000  \n",
       "featureless    1510.321429         0.066825  \n",
       "random         8065.651091         0.358787  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_models = {\n",
    "    #Featureless:\n",
    "    \"random\": RandomModel(MAX_GAIN),\n",
    "    \"conservative\": ConservativeModel(MAX_GAIN),\n",
    "    \"featureless\": FeatureLessModel(MAX_GAIN),\n",
    "    #\"linear_regressor\": LinearRegression(copy_X=False),\n",
    "}\n",
    "\n",
    "results = {key: process_benchmark_cv(model, x, y.ravel()) for key, model in benchmark_models.items()}\n",
    "\n",
    "results_mean = {key: item.mean() for key, item in results.items()}\n",
    "results_std = {key: item.std() for key, item in results.items()}\n",
    "pd.DataFrame(results_mean).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results_mean = pd.DataFrame(results_mean)\n",
    "# df_results_std = pd.DataFrame(results_std)\n",
    "# df_results_mean.plot.bar(logy=True, figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering based models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark_models = {\n",
    "#     #Cluster-based\n",
    "#     \"affinity\": ClusterModel(base_model=\"affinity\"),\n",
    "#     \"bayes\": ClusterModel(base_model=\"bayes\", n_components=8),\n",
    "#     \"birch\": ClusterModel(base_model=\"birch\"),\n",
    "#     \"kmeans\": ClusterModel(base_model=\"kmeans\", n_clusters=16),\n",
    "#     \"meanshift\": ClusterModel(base_model=\"meanshift\", cluster_all=True),\n",
    "#     \"affinity_ext\": ClusterExtModel(base_model=\"affinity\"),\n",
    "#     \"bayes_ext\": ClusterExtModel(base_model=\"bayes\", n_components=8),\n",
    "#     \"birch_ext\": ClusterExtModel(base_model=\"birch\"),\n",
    "#     \"kmeans_ext\": ClusterModel(base_model=\"kmeans\", n_clusters=16),\n",
    "#     \"meanshift_ext\": ClusterExtModel(base_model=\"meanshift\", cluster_all=True),\n",
    "# }\n",
    "\n",
    "# results = {key: process_benchmark_cv(model, x, y.ravel()) for key, model in benchmark_models.items()}\n",
    "\n",
    "# results_mean = {key: item.mean() for key, item in results.items()}\n",
    "# results_std = {key: item.std() for key, item in results.items()}\n",
    "# pd.DataFrame(results_mean).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results_mean = pd.DataFrame(results_mean)\n",
    "# df_results_std = pd.DataFrame(results_std)\n",
    "# df_results_mean.plot.bar(logy=True, figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nn_regression:</th>\n",
       "      <td>98.363827</td>\n",
       "      <td>0.857665</td>\n",
       "      <td>9.482579</td>\n",
       "      <td>3525.658008</td>\n",
       "      <td>11581.679462</td>\n",
       "      <td>0.842540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>36.180952</td>\n",
       "      <td>0.315999</td>\n",
       "      <td>12.455026</td>\n",
       "      <td>1295.000000</td>\n",
       "      <td>3496.095238</td>\n",
       "      <td>0.251270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest_regr</th>\n",
       "      <td>70.401708</td>\n",
       "      <td>0.646872</td>\n",
       "      <td>16.841368</td>\n",
       "      <td>2521.450982</td>\n",
       "      <td>7228.438942</td>\n",
       "      <td>0.602857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     avg_loss  avg_loss_ratio  avg_win_loss     loss_sum  \\\n",
       "nn_regression:      98.363827        0.857665      9.482579  3525.658008   \n",
       "random_forest       36.180952        0.315999     12.455026  1295.000000   \n",
       "random_forest_regr  70.401708        0.646872     16.841368  2521.450982   \n",
       "\n",
       "                             mse  rejection_ratio  \n",
       "nn_regression:      11581.679462         0.842540  \n",
       "random_forest        3496.095238         0.251270  \n",
       "random_forest_regr   7228.438942         0.602857  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_models = {\n",
    "    # Regression\n",
    "    \"random_forest_regr\": RandomForestRegressor(min_samples_leaf=5),\n",
    "    \"nn_regression:\": keras_model(),\n",
    "    \n",
    "    # Classification\n",
    "    \"random_forest\": RandomForestClassifier(min_samples_leaf=5),#max_depth=3, random_state=0, n_estimators=10),\n",
    "}\n",
    "\n",
    "results = {key: process_benchmark_cv(model, x, y.ravel()) for key, model in benchmark_models.items()}\n",
    "\n",
    "results_mean = {key: item.mean() for key, item in results.items()}\n",
    "results_std = {key: item.std() for key, item in results.items()}\n",
    "pd.DataFrame(results_mean).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f791df4fa20>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results_mean = pd.DataFrame(results_mean)\n",
    "df_results_std = pd.DataFrame(results_std)\n",
    "df_results_mean.plot.bar(logy=True, figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
