{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sb\n",
    "import imblearn\n",
    "\n",
    "# Read and sanitize the data\n",
    "df = pd.read_excel(\"../data/UG_HH_NEW_continuous_no200.xls\")\n",
    "#df = pd.read_excel(\"./UG_HH_NEW_categorical_no200.xls\")\n",
    "df = df.dropna()\n",
    "\n",
    "df_effort = df[['time_spent_prop', 'count_effort']]\n",
    "df_effort = (df_effort - df_effort.min()) / (df_effort.max() - df_effort.min())\n",
    "\n",
    "df['effort'] = df_effort['time_spent_prop'] * df_effort['count_effort']\n",
    "df = df[['time_spent_risk', 'cells', 'selfish', 'effort',\n",
    "         'Honesty_Humility','Extraversion', 'Agreeableness', 'min_offer']]\n",
    "\n",
    "df = df[['selfish','Honesty_Humility','Extraversion', 'Agreeableness', 'min_offer']]\n",
    "\n",
    "\n",
    "NORMALISE_DATA = True\n",
    "\n",
    "\n",
    "x = df.values[:, :-1]\n",
    "y = df.values[:, -1:]\n",
    "\n",
    "if NORMALISE_DATA:\n",
    "    x_min = x.min(axis=0)\n",
    "    x_max = x.max(axis=0)\n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    \n",
    "NB_FEATURES = x.shape[1]\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 1/3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (continuous dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy / Loss - For model comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GAIN = 200\n",
    "\n",
    "def loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute loss for the ultimatum game,\n",
    "    as the difference between the possible gain and the actual one\n",
    "    \"\"\"\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    rejected = min_offer > predicted\n",
    "    res = predicted - min_offer\n",
    "    if rejected.sum() != 0:\n",
    "        res[rejected] = MAX_GAIN - min_offer[rejected]\n",
    "    bad_predictions = (predicted < 0) | (predicted > MAX_GAIN)\n",
    "    if bad_predictions.sum() != 0:\n",
    "        res[bad_predictions] = MAX_GAIN - min_offer[bad_predictions]\n",
    "    return res\n",
    "\n",
    "def loss_sum(min_offer, predicted):\n",
    "    return loss(min_offer, predicted).sum()\n",
    "\n",
    "def avg_loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute avg loss for the ultimatum game\n",
    "    \"\"\"\n",
    "    return np.mean(loss(min_offer, predicted))\n",
    "\n",
    "def mse(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute mse using the loss as error\n",
    "    \"\"\"\n",
    "    return np.mean(np.square(loss(min_offer, predicted)))\n",
    "\n",
    "def rejection_ratio(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute ratio of rejected proposals without consideration of values\n",
    "    \"\"\"\n",
    "    accepted = (min_offer <= predicted)\n",
    "    return 1 - np.mean(accepted)\n",
    "\n",
    "def avg_win_loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute avg_loss of accepted proposals\n",
    "    \"\"\"\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    accepted = (min_offer <= predicted)\n",
    "    if accepted.sum() == 0:\n",
    "        return 0\n",
    "    return avg_loss(min_offer[accepted], predicted[accepted])\n",
    "\n",
    "\n",
    "def gain(min_offer, predicted):\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()    \n",
    "    res = MAX_GAIN - predicted\n",
    "    res[predicted < min_offer] = 0\n",
    "    return res\n",
    "\n",
    "def avg_loss_ratio(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute the avg gain ratio in relation to the maximal gain\n",
    "    \"\"\"\n",
    "    return 1 - np.mean(gain(min_offer, predicted) / gain(min_offer, min_offer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_functions = [avg_loss, mse, rejection_ratio, avg_win_loss, avg_loss_ratio, loss_sum]\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def process_model(model, xTrain, yTrain, xTest, yTest, fit_kwargs=None, predict_kwargs=None):\n",
    "    fit_kwargs = {} if fit_kwargs is None else fit_kwargs\n",
    "    predict_kwargs = {} if predict_kwargs is None else predict_kwargs\n",
    "    model.fit(xTrain, yTrain, **fit_kwargs)\n",
    "    yPredict = model.predict(xTest, **predict_kwargs)\n",
    "    results = {func.__name__: func(yTest, yPredict) for func in benchmark_functions}\n",
    "    return results\n",
    "    \n",
    "def process_benchmark_cv(model, X, y, cv=5, metrics=None, fit_kwargs=None, predict_kwargs=None, augment_kwargs=None):\n",
    "    # We make sure original values aren't modified, even by mistake\n",
    "    X = np.copy(X)\n",
    "    y = np.copy(y)\n",
    "    \n",
    "    kf = KFold(n_splits=cv)\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        xTrain, yTrain = X[train_index], y[train_index]\n",
    "        if augment_kwargs:\n",
    "            xTrain, yTrain = DACombine().fit_predict(xTrain, yTrain, **augment_kwargs)\n",
    "        xTest, yTest = X[test_index], y[test_index]\n",
    "        benchmark_result = process_model(model, xTrain, yTrain, xTest, yTest, fit_kwargs, predict_kwargs)\n",
    "        results.append(benchmark_result)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Data augmentation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DACombine(object):\n",
    "    def __init__(self, size=None, nb_features=NB_FEATURES, max_gain=MAX_GAIN):\n",
    "        self.size = size\n",
    "        self.nb_features = nb_features\n",
    "        self.max_gain = max_gain\n",
    "    \n",
    "    def fit_predict(self, xTrain, yTrain, size=None, distance=10, upsample=True, include_xy=False, retarget=False, distribution=False, combine=False):\n",
    "        \"\"\"\n",
    "        :param size: (int) size of the new generated dataset\n",
    "        :param distance: (int) distance between parents or similar items\n",
    "        :param upsample: (bool) if True, try balance the dataset\n",
    "        :param include_xy: (bool) if True, include xTrain and yTrain to the data (on top of size items)\n",
    "        :param retarget: (bool) if True, set all targets to the nearest higher multiple of distance without generating new samples\n",
    "        :param distribution: (bool) if True, create new sample based on percentiles of features's std\n",
    "        :param combine: (bool) if True: combine different methods (dist + retarget)\n",
    "        \"\"\"\n",
    "        \n",
    "        size = size or self.size or len(xTrain) * 4\n",
    "        if combine:\n",
    "            if distribution:\n",
    "                xTrain, yTrain = self.dist_resample(xTrain, yTrain, size)\n",
    "        else:\n",
    "            if retarget:\n",
    "                return self.retarget(xTrain, yTrain, distance)\n",
    "\n",
    "            if distribution:\n",
    "                return self.dist_resample(xTrain, yTrain, size)\n",
    "    \n",
    "        indices = np.arange(self.nb_features)\n",
    "        np.random.shuffle(indices)\n",
    "        targets = yTrain.ravel()\n",
    "        if upsample:\n",
    "            targets, counts = np.unique(yTrain, return_counts=True)\n",
    "            #NOTE: minimize selection of target with only one sample\n",
    "            probs = (1 - counts/counts.sum())**2\n",
    "            probs[counts==1] = probs.min()\n",
    "            probs /= probs.sum()\n",
    "        else:\n",
    "            targets = yTrain.ravel()\n",
    "            probs = None\n",
    "        xRes = []\n",
    "        yRes = []\n",
    "        if include_xy:\n",
    "            xRes.extend(xTrain)\n",
    "            yRes.extend(yTrain.ravel())\n",
    "        for _ in range(size):\n",
    "            target = np.random.choice(targets, p=probs)\n",
    "            target_mask = (yTrain.ravel()<target+distance) & (yTrain.ravel()>=(target))\n",
    "            xTrain_target = xTrain[target_mask]\n",
    "            i = np.random.randint(xTrain_target.shape[0])\n",
    "            j = np.random.randint(xTrain_target.shape[0])\n",
    "            x = np.zeros_like(xTrain_target[0])\n",
    "            np.random.shuffle(indices)\n",
    "            split = np.random.randint(self.nb_features)\n",
    "            mask_i = indices[:split]\n",
    "            mask_j = indices[split:]\n",
    "            x[mask_i] = xTrain_target[i, mask_i]\n",
    "            x[mask_j] = xTrain_target[j, mask_j]\n",
    "            xRes.append(x)\n",
    "            yRes.append(target)\n",
    "        xRes = np.array(xRes)\n",
    "        yRes = np.array(yRes)\n",
    "        if combine and retarget:\n",
    "            return self.retarget(xRes, yRes, distance)\n",
    "        return np.array(xRes), np.array(yRes)\n",
    "\n",
    "    def retarget(self, xTrain, yTrain, distance=10):\n",
    "        yNew = np.zeros(yTrain.shape[0])\n",
    "        for y in np.arange(self.max_gain, 0, -distance):\n",
    "            mask = (yTrain <= y) & (yTrain > y-distance)\n",
    "            yNew[mask] = y + np.random.randint(0, distance, mask.shape)[mask]\n",
    "        yNew = np.array(yNew)\n",
    "        yNew[yNew > self.max_gain] = self.max_gain\n",
    "        return xTrain, yNew\n",
    "    \n",
    "    def dist_resample(self, xTrain, yTrain, size=None, std_ratio=0.1):\n",
    "        size = size or self.size or len(xTrain) * 4\n",
    "        xTrain_mean = xTrain.mean()\n",
    "        xTrain_std = xTrain.std()\n",
    "        xNew = []\n",
    "        yNew = []\n",
    "        for _ in range(size):\n",
    "            idx = np.random.randint(0, xTrain.shape[0])\n",
    "            x = np.random.normal(xTrain[idx], xTrain_std*std_ratio)\n",
    "            y = yTrain[idx]\n",
    "            xNew.append(x)\n",
    "            yNew.append(y)\n",
    "        return np.array(xNew), np.array(yNew)\n",
    "            \n",
    "\n",
    "    def fit_resample(self, xTrain, yTrain, size=None, distance=5, include_xy=True):\n",
    "        return self.fit_predict(xTrain, yTrain, size=size, distance=distance, include_xy=include_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#keras\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import multiply\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "\n",
    "def sigmoid1024_tf(x):\n",
    "    return (1024**x) / (1024**x + 1)\n",
    "\n",
    "def sigmoid_tf(x):\n",
    "    return K.sigmoid(x)\n",
    "\n",
    "def gain_tf(y_true, y_pred):\n",
    "    math_pi = tf.constant(math.pi)\n",
    "    one = tf.constant(1.0)\n",
    "    ten = tf.constant(10.0)\n",
    "    x = tf.math.subtract(y_true, y_pred)\n",
    "    x = tf.math.truediv(x, ten)\n",
    "    left_mul = sigmoid_tf(x)\n",
    "    right_mul = tf.math.cos(tf.math.divide(x, math_pi))\n",
    "    return tf.math.multiply(left_mul, right_mul)\n",
    "\n",
    "\n",
    "def loss_tf(y_true, y_pred):\n",
    "    math_pi = tf.constant(math.pi)\n",
    "    one = tf.constant(1.0)\n",
    "    ten = tf.constant(10.0)\n",
    "    x0 = tf.math.subtract(y_true, y_pred)\n",
    "    x = tf.math.truediv(x0, ten)\n",
    "    left_mul = sigmoid_tf(x)\n",
    "    right_mul = tf.math.cos(tf.math.divide(x, math_pi))\n",
    "    return tf.math.subtract(one*2, tf.math.multiply(left_mul, right_mul))\n",
    "\n",
    "def _keras_model(loss=None, metrics=None):\n",
    "    \"\"\"\n",
    "    build a simple regression model\n",
    "    :param loss: (str|callable, default: loss_tf)\n",
    "    \"\"\"\n",
    "    if loss is None:\n",
    "        loss = loss_tf\n",
    "    if metrics is None:\n",
    "        metrics = [\"mse\"]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=NB_FEATURES, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def _keras_linear_regression(loss=None, metrics=None):\n",
    "    if loss is None:\n",
    "        loss = \"mse\"\n",
    "    if metrics is None:\n",
    "        metrics = [\"mse\"]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=NB_FEATURES, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def keras_linear_regression(loss=None, metrics=None, nb_epoch=100, batch_size=32, verbose=False):\n",
    "    build_fn = lambda : _keras_linear_regression(loss, metrics)\n",
    "    return KerasRegressor(build_fn=build_fn, epochs=nb_epoch, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "def keras_model(loss=None, metrics=None, nb_epoch=100, batch_size=32, verbose=False):\n",
    "    build_fn = lambda : _keras_model(loss, metrics)\n",
    "    return KerasRegressor(build_fn=build_fn, epochs=nb_epoch, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4,  5, 28, 13, 26, 38,  1,  3,  0,  1]),\n",
       " array([  0. ,  19.5,  39. ,  58.5,  78. ,  97.5, 117. , 136.5, 156. ,\n",
       "        175.5, 195. ]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imblearn\n",
    "import imblearn.over_sampling\n",
    "o_s = imblearn.over_sampling.RandomOverSampler()\n",
    "xTrain_a, yTrain_a = o_s.fit_resample(xTrain, yTrain.ravel(), )\n",
    "pd.DataFrame(xTrain).hist()\n",
    "pd.DataFrame(xTrain_a).hist()\n",
    "np.histogram(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_regression_base</th>\n",
       "      <td>70.742931</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>27.443891</td>\n",
       "      <td>2532.130878</td>\n",
       "      <td>6658.271315</td>\n",
       "      <td>0.586508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_retarget</th>\n",
       "      <td>61.636186</td>\n",
       "      <td>0.575220</td>\n",
       "      <td>27.483636</td>\n",
       "      <td>2207.663929</td>\n",
       "      <td>5438.381463</td>\n",
       "      <td>0.485556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_x16</th>\n",
       "      <td>73.479820</td>\n",
       "      <td>0.676930</td>\n",
       "      <td>25.417040</td>\n",
       "      <td>2630.085476</td>\n",
       "      <td>7214.976783</td>\n",
       "      <td>0.614444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_x16-up</th>\n",
       "      <td>72.822679</td>\n",
       "      <td>0.672122</td>\n",
       "      <td>25.213374</td>\n",
       "      <td>2606.841556</td>\n",
       "      <td>7101.605434</td>\n",
       "      <td>0.608730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_x16_combine</th>\n",
       "      <td>62.614871</td>\n",
       "      <td>0.584576</td>\n",
       "      <td>27.496726</td>\n",
       "      <td>2242.433712</td>\n",
       "      <td>5560.801202</td>\n",
       "      <td>0.496825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_x16_dist</th>\n",
       "      <td>71.286799</td>\n",
       "      <td>0.662960</td>\n",
       "      <td>27.695264</td>\n",
       "      <td>2551.744702</td>\n",
       "      <td>6715.048389</td>\n",
       "      <td>0.592063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_base</th>\n",
       "      <td>26.913492</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>23.429033</td>\n",
       "      <td>963.000000</td>\n",
       "      <td>1543.257937</td>\n",
       "      <td>0.072540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_retarget</th>\n",
       "      <td>32.173016</td>\n",
       "      <td>0.264399</td>\n",
       "      <td>27.518634</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1962.720952</td>\n",
       "      <td>0.089048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_x16</th>\n",
       "      <td>77.700794</td>\n",
       "      <td>0.669020</td>\n",
       "      <td>46.095363</td>\n",
       "      <td>2781.000000</td>\n",
       "      <td>8266.670635</td>\n",
       "      <td>0.480317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_x16-up</th>\n",
       "      <td>85.774603</td>\n",
       "      <td>0.739705</td>\n",
       "      <td>54.187500</td>\n",
       "      <td>3070.000000</td>\n",
       "      <td>9344.674603</td>\n",
       "      <td>0.558571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_x16_combine</th>\n",
       "      <td>36.723492</td>\n",
       "      <td>0.313899</td>\n",
       "      <td>27.546663</td>\n",
       "      <td>1315.000000</td>\n",
       "      <td>2489.654921</td>\n",
       "      <td>0.150794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_x16_dist</th>\n",
       "      <td>37.473016</td>\n",
       "      <td>0.317342</td>\n",
       "      <td>21.468464</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>3103.793651</td>\n",
       "      <td>0.201270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                avg_loss  avg_loss_ratio  avg_win_loss  \\\n",
       "linear_regression_base         70.742931        0.657645     27.443891   \n",
       "linear_regression_retarget     61.636186        0.575220     27.483636   \n",
       "linear_regression_x16          73.479820        0.676930     25.417040   \n",
       "linear_regression_x16-up       72.822679        0.672122     25.213374   \n",
       "linear_regression_x16_combine  62.614871        0.584576     27.496726   \n",
       "linear_regression_x16_dist     71.286799        0.662960     27.695264   \n",
       "log_regression_base            26.913492        0.219422     23.429033   \n",
       "log_regression_retarget        32.173016        0.264399     27.518634   \n",
       "log_regression_x16             77.700794        0.669020     46.095363   \n",
       "log_regression_x16-up          85.774603        0.739705     54.187500   \n",
       "log_regression_x16_combine     36.723492        0.313899     27.546663   \n",
       "log_regression_x16_dist        37.473016        0.317342     21.468464   \n",
       "\n",
       "                                  loss_sum          mse  rejection_ratio  \n",
       "linear_regression_base         2532.130878  6658.271315         0.586508  \n",
       "linear_regression_retarget     2207.663929  5438.381463         0.485556  \n",
       "linear_regression_x16          2630.085476  7214.976783         0.614444  \n",
       "linear_regression_x16-up       2606.841556  7101.605434         0.608730  \n",
       "linear_regression_x16_combine  2242.433712  5560.801202         0.496825  \n",
       "linear_regression_x16_dist     2551.744702  6715.048389         0.592063  \n",
       "log_regression_base             963.000000  1543.257937         0.072540  \n",
       "log_regression_retarget        1152.000000  1962.720952         0.089048  \n",
       "log_regression_x16             2781.000000  8266.670635         0.480317  \n",
       "log_regression_x16-up          3070.000000  9344.674603         0.558571  \n",
       "log_regression_x16_combine     1315.000000  2489.654921         0.150794  \n",
       "log_regression_x16_dist        1340.000000  3103.793651         0.201270  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression, PassiveAggressiveRegressor, \\\n",
    "                                 ElasticNet, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble.bagging import BaggingRegressor, DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "benchmark_models = {\n",
    "    'linear_regression': LinearRegression(),\n",
    "    'log_regression': LogisticRegression(penalty='l1', solver='liblinear', multi_class='auto'),\n",
    "}\n",
    "    \n",
    "augment_params = {\n",
    "    'base': {},\n",
    "    'retarget': {'retarget': True, 'distance': 10},\n",
    "#     'x2': {'size':len(xTrain)*2},\n",
    "#     'x2-up': {'size':len(xTrain)*2, 'upsample': True},\n",
    "#     'x2+xy': {'size':len(xTrain)*2, 'include_xy':True},\n",
    "#     'x4': {'size': len(xTrain)*4},\n",
    "#     'x4+xy-up': {'size': len(xTrain)*4, 'include_xy':True, 'upsample':True},\n",
    "    'x16': {'size': len(xTrain)*16},\n",
    "    'x16-up': {'size': len(xTrain)*16, 'upsample': True},\n",
    "    'x16_dist': {'size': len(xTrain)*16, 'distribution': True},\n",
    "    'x16_combine': {'size': len(xTrain)*16, 'retarget': True, 'distribution': True, 'upsample': True},\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for key, model in benchmark_models.items():\n",
    "    for aug_key, aug_params in augment_params.items():\n",
    "        results[key+\"_\" + aug_key] = process_benchmark_cv(model=model, X=x, y=y.ravel(), augment_kwargs=aug_params)\n",
    "\n",
    "results_mean = {key: item.mean() for key, item in results.items()}\n",
    "results_std = {key: item.std() for key, item in results.items()}\n",
    "pd.DataFrame(results_mean).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Actual best model:**\n",
    "- LogisticRegression (penalty='l1')\n",
    "\n",
    "** Data Augmentation improve following models:**\n",
    "- Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bag_base</th>\n",
       "      <td>68.586984</td>\n",
       "      <td>0.631243</td>\n",
       "      <td>27.583969</td>\n",
       "      <td>2456.600000</td>\n",
       "      <td>6506.318413</td>\n",
       "      <td>0.552540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_retarget</th>\n",
       "      <td>61.737651</td>\n",
       "      <td>0.566591</td>\n",
       "      <td>27.298211</td>\n",
       "      <td>2211.040000</td>\n",
       "      <td>5600.825908</td>\n",
       "      <td>0.468730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_x16</th>\n",
       "      <td>70.353962</td>\n",
       "      <td>0.644930</td>\n",
       "      <td>27.016091</td>\n",
       "      <td>2519.555126</td>\n",
       "      <td>6776.191804</td>\n",
       "      <td>0.569365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_x16-up</th>\n",
       "      <td>76.458529</td>\n",
       "      <td>0.694387</td>\n",
       "      <td>30.203376</td>\n",
       "      <td>2738.604280</td>\n",
       "      <td>7610.258286</td>\n",
       "      <td>0.619524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_x16_combine</th>\n",
       "      <td>62.952286</td>\n",
       "      <td>0.579672</td>\n",
       "      <td>28.709822</td>\n",
       "      <td>2253.820000</td>\n",
       "      <td>5671.096737</td>\n",
       "      <td>0.480159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_x16_dist</th>\n",
       "      <td>63.713333</td>\n",
       "      <td>0.588673</td>\n",
       "      <td>27.875210</td>\n",
       "      <td>2282.300000</td>\n",
       "      <td>5852.069206</td>\n",
       "      <td>0.496667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_base</th>\n",
       "      <td>67.767016</td>\n",
       "      <td>0.625122</td>\n",
       "      <td>26.599220</td>\n",
       "      <td>2426.540000</td>\n",
       "      <td>6390.267200</td>\n",
       "      <td>0.547143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_retarget</th>\n",
       "      <td>60.541616</td>\n",
       "      <td>0.560677</td>\n",
       "      <td>27.328312</td>\n",
       "      <td>2167.652000</td>\n",
       "      <td>5365.878859</td>\n",
       "      <td>0.463333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_x16</th>\n",
       "      <td>78.600265</td>\n",
       "      <td>0.708613</td>\n",
       "      <td>33.396578</td>\n",
       "      <td>2815.228460</td>\n",
       "      <td>7935.518168</td>\n",
       "      <td>0.630635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_x16-up</th>\n",
       "      <td>75.219094</td>\n",
       "      <td>0.684116</td>\n",
       "      <td>30.026739</td>\n",
       "      <td>2693.877265</td>\n",
       "      <td>7407.228087</td>\n",
       "      <td>0.608413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_x16_combine</th>\n",
       "      <td>63.659648</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>28.926000</td>\n",
       "      <td>2279.020000</td>\n",
       "      <td>5753.165655</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_x16_dist</th>\n",
       "      <td>65.922016</td>\n",
       "      <td>0.608158</td>\n",
       "      <td>28.431426</td>\n",
       "      <td>2360.760000</td>\n",
       "      <td>6133.086233</td>\n",
       "      <td>0.513492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     avg_loss  avg_loss_ratio  avg_win_loss     loss_sum  \\\n",
       "bag_base            68.586984        0.631243     27.583969  2456.600000   \n",
       "bag_retarget        61.737651        0.566591     27.298211  2211.040000   \n",
       "bag_x16             70.353962        0.644930     27.016091  2519.555126   \n",
       "bag_x16-up          76.458529        0.694387     30.203376  2738.604280   \n",
       "bag_x16_combine     62.952286        0.579672     28.709822  2253.820000   \n",
       "bag_x16_dist        63.713333        0.588673     27.875210  2282.300000   \n",
       "forest_base         67.767016        0.625122     26.599220  2426.540000   \n",
       "forest_retarget     60.541616        0.560677     27.328312  2167.652000   \n",
       "forest_x16          78.600265        0.708613     33.396578  2815.228460   \n",
       "forest_x16-up       75.219094        0.684116     30.026739  2693.877265   \n",
       "forest_x16_combine  63.659648        0.584458     28.926000  2279.020000   \n",
       "forest_x16_dist     65.922016        0.608158     28.431426  2360.760000   \n",
       "\n",
       "                            mse  rejection_ratio  \n",
       "bag_base            6506.318413         0.552540  \n",
       "bag_retarget        5600.825908         0.468730  \n",
       "bag_x16             6776.191804         0.569365  \n",
       "bag_x16-up          7610.258286         0.619524  \n",
       "bag_x16_combine     5671.096737         0.480159  \n",
       "bag_x16_dist        5852.069206         0.496667  \n",
       "forest_base         6390.267200         0.547143  \n",
       "forest_retarget     5365.878859         0.463333  \n",
       "forest_x16          7935.518168         0.630635  \n",
       "forest_x16-up       7407.228087         0.608413  \n",
       "forest_x16_combine  5753.165655         0.485714  \n",
       "forest_x16_dist     6133.086233         0.513492  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "benchmark_models = {\n",
    "    'bag': BaggingRegressor(),\n",
    "    'forest': RandomForestRegressor(n_estimators=50),\n",
    "    #keras_linear_regression(nb_epoch=100, batch_size=60),\n",
    "}\n",
    "    \n",
    "augment_params = {\n",
    "    'base': {},\n",
    "    'retarget': {'retarget': True, 'distance': 10},\n",
    "    'x16': {'size': len(xTrain)*16},\n",
    "    'x16-up': {'size': len(xTrain)*16, 'upsample': True},\n",
    "    'x16_dist': {'size': len(xTrain)*16, 'distribution': True},\n",
    "    'x16_combine': {'size': len(xTrain)*16, 'retarget': True, 'distribution': True},\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for key, model in benchmark_models.items():\n",
    "    for aug_key, aug_params in augment_params.items():\n",
    "        results[key+\"_\" + aug_key] = process_benchmark_cv(model=model, X=x, y=y.ravel(), augment_kwargs=aug_params)\n",
    "\n",
    "results_mean = {key: item.mean() for key, item in results.items()}\n",
    "results_std = {key: item.std() for key, item in results.items()}\n",
    "pd.DataFrame(results_mean).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franck/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 256 samples\n",
      "Epoch 1/500\n",
      "768/768 [==============================] - 2s 2ms/step - loss: 7131.6598 - gain_tf: -0.1574 - val_loss: 6601.5392 - val_gain_tf: -0.2018\n",
      "Epoch 2/500\n",
      "768/768 [==============================] - 0s 189us/step - loss: 7121.0742 - gain_tf: -0.1568 - val_loss: 6590.9635 - val_gain_tf: -0.2010\n",
      "Epoch 3/500\n",
      "768/768 [==============================] - 0s 216us/step - loss: 7110.3446 - gain_tf: -0.1563 - val_loss: 6580.5612 - val_gain_tf: -0.2002\n",
      "Epoch 4/500\n",
      "768/768 [==============================] - 0s 195us/step - loss: 7099.7375 - gain_tf: -0.1557 - val_loss: 6570.0441 - val_gain_tf: -0.1994\n",
      "Epoch 5/500\n",
      "768/768 [==============================] - 0s 203us/step - loss: 7089.0842 - gain_tf: -0.1552 - val_loss: 6559.5668 - val_gain_tf: -0.1986\n",
      "Epoch 6/500\n",
      "768/768 [==============================] - 0s 204us/step - loss: 7078.4274 - gain_tf: -0.1547 - val_loss: 6549.1409 - val_gain_tf: -0.1978\n",
      "Epoch 7/500\n",
      "768/768 [==============================] - 0s 227us/step - loss: 7067.8430 - gain_tf: -0.1542 - val_loss: 6538.6665 - val_gain_tf: -0.1970\n",
      "Epoch 8/500\n",
      "768/768 [==============================] - 0s 226us/step - loss: 7057.2626 - gain_tf: -0.1536 - val_loss: 6528.2105 - val_gain_tf: -0.1962\n",
      "Epoch 9/500\n",
      "768/768 [==============================] - 0s 226us/step - loss: 7046.5908 - gain_tf: -0.1531 - val_loss: 6517.9589 - val_gain_tf: -0.1954\n",
      "Epoch 10/500\n",
      "768/768 [==============================] - 0s 210us/step - loss: 7036.0503 - gain_tf: -0.1526 - val_loss: 6507.6051 - val_gain_tf: -0.1946\n",
      "Epoch 11/500\n",
      "768/768 [==============================] - 0s 218us/step - loss: 7025.5522 - gain_tf: -0.1520 - val_loss: 6497.1439 - val_gain_tf: -0.1938\n",
      "Epoch 12/500\n",
      "768/768 [==============================] - 0s 234us/step - loss: 7014.9926 - gain_tf: -0.1515 - val_loss: 6486.7594 - val_gain_tf: -0.1930\n",
      "Epoch 13/500\n",
      "768/768 [==============================] - 0s 212us/step - loss: 7004.5106 - gain_tf: -0.1510 - val_loss: 6476.3283 - val_gain_tf: -0.1922\n",
      "Epoch 14/500\n",
      "768/768 [==============================] - 0s 202us/step - loss: 6993.9281 - gain_tf: -0.1504 - val_loss: 6466.1145 - val_gain_tf: -0.1914\n",
      "Epoch 15/500\n",
      "768/768 [==============================] - 0s 222us/step - loss: 6983.4763 - gain_tf: -0.1499 - val_loss: 6455.8266 - val_gain_tf: -0.1906\n",
      "Epoch 16/500\n",
      "768/768 [==============================] - 0s 225us/step - loss: 6972.9867 - gain_tf: -0.1494 - val_loss: 6445.5920 - val_gain_tf: -0.1898\n",
      "Epoch 17/500\n",
      "768/768 [==============================] - 0s 276us/step - loss: 6962.5376 - gain_tf: -0.1489 - val_loss: 6435.3386 - val_gain_tf: -0.1890\n",
      "Epoch 18/500\n",
      "768/768 [==============================] - 0s 227us/step - loss: 6952.1448 - gain_tf: -0.1483 - val_loss: 6425.0016 - val_gain_tf: -0.1882\n",
      "Epoch 19/500\n",
      "768/768 [==============================] - 0s 227us/step - loss: 6941.6568 - gain_tf: -0.1478 - val_loss: 6414.8223 - val_gain_tf: -0.1874\n",
      "Epoch 20/500\n",
      "768/768 [==============================] - 0s 220us/step - loss: 6931.2991 - gain_tf: -0.1473 - val_loss: 6404.5464 - val_gain_tf: -0.1866\n",
      "Epoch 21/500\n",
      "768/768 [==============================] - 0s 215us/step - loss: 6920.8663 - gain_tf: -0.1468 - val_loss: 6394.3764 - val_gain_tf: -0.1858\n",
      "Epoch 22/500\n",
      "768/768 [==============================] - 0s 188us/step - loss: 6910.5195 - gain_tf: -0.1462 - val_loss: 6384.1547 - val_gain_tf: -0.1850\n",
      "Epoch 23/500\n",
      "768/768 [==============================] - 0s 209us/step - loss: 6900.1172 - gain_tf: -0.1457 - val_loss: 6374.0406 - val_gain_tf: -0.1843\n",
      "Epoch 24/500\n",
      "768/768 [==============================] - 0s 246us/step - loss: 6889.8693 - gain_tf: -0.1452 - val_loss: 6363.7276 - val_gain_tf: -0.1834\n",
      "Epoch 25/500\n",
      "768/768 [==============================] - 0s 213us/step - loss: 6879.5072 - gain_tf: -0.1447 - val_loss: 6353.5386 - val_gain_tf: -0.1826\n",
      "Epoch 26/500\n",
      "768/768 [==============================] - 0s 222us/step - loss: 6869.1290 - gain_tf: -0.1442 - val_loss: 6343.5182 - val_gain_tf: -0.1819\n",
      "Epoch 27/500\n",
      "768/768 [==============================] - 0s 252us/step - loss: 6858.8393 - gain_tf: -0.1436 - val_loss: 6333.4922 - val_gain_tf: -0.1811\n",
      "Epoch 28/500\n",
      "768/768 [==============================] - 0s 242us/step - loss: 6848.6496 - gain_tf: -0.1431 - val_loss: 6323.2647 - val_gain_tf: -0.1803\n",
      "Epoch 29/500\n",
      "768/768 [==============================] - 0s 237us/step - loss: 6838.3013 - gain_tf: -0.1426 - val_loss: 6313.2493 - val_gain_tf: -0.1795\n",
      "Epoch 30/500\n",
      "768/768 [==============================] - 0s 228us/step - loss: 6828.0683 - gain_tf: -0.1420 - val_loss: 6303.2077 - val_gain_tf: -0.1787\n",
      "Epoch 31/500\n",
      "768/768 [==============================] - 0s 203us/step - loss: 6817.8532 - gain_tf: -0.1415 - val_loss: 6293.1318 - val_gain_tf: -0.1779\n",
      "Epoch 32/500\n",
      "768/768 [==============================] - 0s 234us/step - loss: 6807.6302 - gain_tf: -0.1410 - val_loss: 6283.0848 - val_gain_tf: -0.1771\n",
      "Epoch 33/500\n",
      "768/768 [==============================] - 0s 207us/step - loss: 6797.3968 - gain_tf: -0.1405 - val_loss: 6273.1207 - val_gain_tf: -0.1763\n",
      "Epoch 34/500\n",
      "768/768 [==============================] - 0s 217us/step - loss: 6787.2507 - gain_tf: -0.1400 - val_loss: 6263.0778 - val_gain_tf: -0.1755\n",
      "Epoch 35/500\n",
      "768/768 [==============================] - 0s 197us/step - loss: 6777.0728 - gain_tf: -0.1394 - val_loss: 6253.0760 - val_gain_tf: -0.1747\n",
      "Epoch 36/500\n",
      "768/768 [==============================] - 0s 235us/step - loss: 6766.8990 - gain_tf: -0.1389 - val_loss: 6243.1290 - val_gain_tf: -0.1739\n",
      "Epoch 37/500\n",
      "768/768 [==============================] - 0s 172us/step - loss: 6756.7453 - gain_tf: -0.1384 - val_loss: 6233.2291 - val_gain_tf: -0.1731\n",
      "Epoch 38/500\n",
      "768/768 [==============================] - 0s 204us/step - loss: 6746.6037 - gain_tf: -0.1379 - val_loss: 6223.3746 - val_gain_tf: -0.1723\n",
      "Epoch 39/500\n",
      "768/768 [==============================] - 0s 227us/step - loss: 6736.5986 - gain_tf: -0.1374 - val_loss: 6213.2844 - val_gain_tf: -0.1715\n",
      "Epoch 40/500\n",
      "768/768 [==============================] - 0s 219us/step - loss: 6726.4256 - gain_tf: -0.1368 - val_loss: 6203.4047 - val_gain_tf: -0.1707\n",
      "Epoch 41/500\n",
      "768/768 [==============================] - 0s 217us/step - loss: 6716.3798 - gain_tf: -0.1364 - val_loss: 6193.4709 - val_gain_tf: -0.1699\n",
      "Epoch 42/500\n",
      "768/768 [==============================] - 0s 195us/step - loss: 6706.2774 - gain_tf: -0.1358 - val_loss: 6183.6449 - val_gain_tf: -0.1691\n",
      "Epoch 43/500\n",
      "768/768 [==============================] - 0s 215us/step - loss: 6696.3230 - gain_tf: -0.1353 - val_loss: 6173.6330 - val_gain_tf: -0.1683\n",
      "Epoch 44/500\n",
      "768/768 [==============================] - 0s 169us/step - loss: 6686.1838 - gain_tf: -0.1348 - val_loss: 6163.8929 - val_gain_tf: -0.1675\n",
      "Epoch 45/500\n",
      "768/768 [==============================] - 0s 215us/step - loss: 6676.2124 - gain_tf: -0.1343 - val_loss: 6154.0623 - val_gain_tf: -0.1667\n",
      "Epoch 46/500\n",
      "768/768 [==============================] - 0s 261us/step - loss: 6666.1976 - gain_tf: -0.1338 - val_loss: 6144.2761 - val_gain_tf: -0.1660\n",
      "Epoch 47/500\n",
      "768/768 [==============================] - 0s 220us/step - loss: 6656.2448 - gain_tf: -0.1333 - val_loss: 6134.4255 - val_gain_tf: -0.1652\n",
      "Epoch 48/500\n",
      "768/768 [==============================] - 0s 206us/step - loss: 6646.2468 - gain_tf: -0.1327 - val_loss: 6124.6697 - val_gain_tf: -0.1644\n",
      "Epoch 49/500\n",
      "768/768 [==============================] - 0s 235us/step - loss: 6636.2980 - gain_tf: -0.1322 - val_loss: 6114.9000 - val_gain_tf: -0.1636\n",
      "Epoch 50/500\n",
      "768/768 [==============================] - 0s 237us/step - loss: 6626.3563 - gain_tf: -0.1317 - val_loss: 6105.1440 - val_gain_tf: -0.1628\n",
      "Epoch 51/500\n",
      "768/768 [==============================] - 0s 227us/step - loss: 6616.4246 - gain_tf: -0.1312 - val_loss: 6095.4154 - val_gain_tf: -0.1620\n",
      "Epoch 52/500\n",
      "768/768 [==============================] - 0s 214us/step - loss: 6606.5094 - gain_tf: -0.1307 - val_loss: 6085.7059 - val_gain_tf: -0.1612\n",
      "Epoch 53/500\n",
      "768/768 [==============================] - 0s 232us/step - loss: 6596.6326 - gain_tf: -0.1302 - val_loss: 6075.9577 - val_gain_tf: -0.1604\n",
      "Epoch 54/500\n",
      "768/768 [==============================] - 0s 217us/step - loss: 6586.8012 - gain_tf: -0.1296 - val_loss: 6066.1246 - val_gain_tf: -0.1596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "768/768 [==============================] - 0s 223us/step - loss: 6576.7826 - gain_tf: -0.1291 - val_loss: 6056.6471 - val_gain_tf: -0.1588\n",
      "Epoch 56/500\n",
      "768/768 [==============================] - 0s 201us/step - loss: 6567.0208 - gain_tf: -0.1286 - val_loss: 6046.9586 - val_gain_tf: -0.1581\n",
      "Epoch 57/500\n",
      "768/768 [==============================] - 0s 193us/step - loss: 6557.2065 - gain_tf: -0.1281 - val_loss: 6037.2266 - val_gain_tf: -0.1573\n",
      "Epoch 58/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 6547.3459 - gain_tf: -0.1276 - val_loss: 6027.5895 - val_gain_tf: -0.1565\n",
      "Epoch 59/500\n",
      "768/768 [==============================] - 0s 179us/step - loss: 6537.5538 - gain_tf: -0.1271 - val_loss: 6017.9245 - val_gain_tf: -0.1557\n",
      "Epoch 60/500\n",
      "768/768 [==============================] - 0s 174us/step - loss: 6527.7659 - gain_tf: -0.1266 - val_loss: 6008.2700 - val_gain_tf: -0.1549\n",
      "Epoch 61/500\n",
      "768/768 [==============================] - 0s 197us/step - loss: 6517.9549 - gain_tf: -0.1261 - val_loss: 5998.6982 - val_gain_tf: -0.1541\n",
      "Epoch 62/500\n",
      "768/768 [==============================] - 0s 194us/step - loss: 6508.1621 - gain_tf: -0.1256 - val_loss: 5989.2001 - val_gain_tf: -0.1533\n",
      "Epoch 63/500\n",
      "768/768 [==============================] - 0s 215us/step - loss: 6498.4407 - gain_tf: -0.1251 - val_loss: 5979.6379 - val_gain_tf: -0.1525\n",
      "Epoch 64/500\n",
      "768/768 [==============================] - 0s 200us/step - loss: 6488.7410 - gain_tf: -0.1245 - val_loss: 5969.9998 - val_gain_tf: -0.1517\n",
      "Epoch 65/500\n",
      "768/768 [==============================] - 0s 214us/step - loss: 6478.9724 - gain_tf: -0.1240 - val_loss: 5960.4775 - val_gain_tf: -0.1510\n",
      "Epoch 66/500\n",
      "768/768 [==============================] - 0s 171us/step - loss: 6469.2066 - gain_tf: -0.1235 - val_loss: 5951.0883 - val_gain_tf: -0.1502\n",
      "Epoch 67/500\n",
      "768/768 [==============================] - 0s 183us/step - loss: 6459.6316 - gain_tf: -0.1230 - val_loss: 5941.4263 - val_gain_tf: -0.1494\n",
      "Epoch 68/500\n",
      "768/768 [==============================] - 0s 198us/step - loss: 6449.8010 - gain_tf: -0.1226 - val_loss: 5932.1182 - val_gain_tf: -0.1486\n",
      "Epoch 69/500\n",
      "768/768 [==============================] - 0s 189us/step - loss: 6440.2556 - gain_tf: -0.1220 - val_loss: 5922.5277 - val_gain_tf: -0.1478\n",
      "Epoch 70/500\n",
      "768/768 [==============================] - 0s 210us/step - loss: 6430.5355 - gain_tf: -0.1215 - val_loss: 5913.0915 - val_gain_tf: -0.1470\n",
      "Epoch 71/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 6420.8624 - gain_tf: -0.1211 - val_loss: 5903.7361 - val_gain_tf: -0.1463\n",
      "Epoch 72/500\n",
      "768/768 [==============================] - 0s 177us/step - loss: 6411.3482 - gain_tf: -0.1205 - val_loss: 5894.1252 - val_gain_tf: -0.1455\n",
      "Epoch 73/500\n",
      "768/768 [==============================] - 0s 221us/step - loss: 6401.6063 - gain_tf: -0.1200 - val_loss: 5884.8256 - val_gain_tf: -0.1447\n",
      "Epoch 74/500\n",
      "768/768 [==============================] - 0s 184us/step - loss: 6392.1317 - gain_tf: -0.1195 - val_loss: 5875.2510 - val_gain_tf: -0.1439\n",
      "Epoch 75/500\n",
      "768/768 [==============================] - 0s 256us/step - loss: 6382.4215 - gain_tf: -0.1190 - val_loss: 5865.9739 - val_gain_tf: -0.1431\n",
      "Epoch 76/500\n",
      "768/768 [==============================] - 0s 230us/step - loss: 6372.8922 - gain_tf: -0.1185 - val_loss: 5856.6014 - val_gain_tf: -0.1424\n",
      "Epoch 77/500\n",
      "768/768 [==============================] - 0s 234us/step - loss: 6363.3539 - gain_tf: -0.1180 - val_loss: 5847.1926 - val_gain_tf: -0.1416\n",
      "Epoch 78/500\n",
      "768/768 [==============================] - 0s 224us/step - loss: 6353.7847 - gain_tf: -0.1175 - val_loss: 5837.8442 - val_gain_tf: -0.1408\n",
      "Epoch 79/500\n",
      "768/768 [==============================] - 0s 200us/step - loss: 6344.2670 - gain_tf: -0.1170 - val_loss: 5828.4834 - val_gain_tf: -0.1400\n",
      "Epoch 80/500\n",
      "768/768 [==============================] - 0s 211us/step - loss: 6334.6740 - gain_tf: -0.1165 - val_loss: 5819.3142 - val_gain_tf: -0.1392\n",
      "Epoch 81/500\n",
      "768/768 [==============================] - 0s 194us/step - loss: 6325.3173 - gain_tf: -0.1160 - val_loss: 5809.7982 - val_gain_tf: -0.1384\n",
      "Epoch 82/500\n",
      "768/768 [==============================] - 0s 207us/step - loss: 6315.7942 - gain_tf: -0.1155 - val_loss: 5800.3885 - val_gain_tf: -0.1377\n",
      "Epoch 83/500\n",
      "768/768 [==============================] - 0s 190us/step - loss: 6306.1636 - gain_tf: -0.1150 - val_loss: 5791.3538 - val_gain_tf: -0.1369\n",
      "Epoch 84/500\n",
      "768/768 [==============================] - 0s 205us/step - loss: 6296.8603 - gain_tf: -0.1145 - val_loss: 5781.9454 - val_gain_tf: -0.1361\n",
      "Epoch 85/500\n",
      "768/768 [==============================] - 0s 189us/step - loss: 6287.3490 - gain_tf: -0.1140 - val_loss: 5772.6973 - val_gain_tf: -0.1353\n",
      "Epoch 86/500\n",
      "768/768 [==============================] - 0s 204us/step - loss: 6277.8805 - gain_tf: -0.1135 - val_loss: 5763.5324 - val_gain_tf: -0.1346\n",
      "Epoch 87/500\n",
      "768/768 [==============================] - 0s 161us/step - loss: 6268.5264 - gain_tf: -0.1130 - val_loss: 5754.2131 - val_gain_tf: -0.1338\n",
      "Epoch 88/500\n",
      "768/768 [==============================] - 0s 205us/step - loss: 6259.1085 - gain_tf: -0.1125 - val_loss: 5744.9353 - val_gain_tf: -0.1330\n",
      "Epoch 89/500\n",
      "768/768 [==============================] - 0s 197us/step - loss: 6249.6522 - gain_tf: -0.1121 - val_loss: 5735.8001 - val_gain_tf: -0.1322\n",
      "Epoch 90/500\n",
      "768/768 [==============================] - 0s 195us/step - loss: 6240.3072 - gain_tf: -0.1116 - val_loss: 5726.5822 - val_gain_tf: -0.1315\n",
      "Epoch 91/500\n",
      "768/768 [==============================] - 0s 183us/step - loss: 6230.9213 - gain_tf: -0.1111 - val_loss: 5717.4135 - val_gain_tf: -0.1307\n",
      "Epoch 92/500\n",
      "768/768 [==============================] - 0s 202us/step - loss: 6221.5218 - gain_tf: -0.1106 - val_loss: 5708.3485 - val_gain_tf: -0.1299\n",
      "Epoch 93/500\n",
      "768/768 [==============================] - 0s 207us/step - loss: 6212.2385 - gain_tf: -0.1101 - val_loss: 5699.1454 - val_gain_tf: -0.1291\n",
      "Epoch 94/500\n",
      "768/768 [==============================] - 0s 207us/step - loss: 6202.9386 - gain_tf: -0.1096 - val_loss: 5689.8882 - val_gain_tf: -0.1284\n",
      "Epoch 95/500\n",
      "768/768 [==============================] - 0s 201us/step - loss: 6193.5868 - gain_tf: -0.1091 - val_loss: 5680.7319 - val_gain_tf: -0.1276\n",
      "Epoch 96/500\n",
      "768/768 [==============================] - 0s 225us/step - loss: 6184.2462 - gain_tf: -0.1086 - val_loss: 5671.6747 - val_gain_tf: -0.1268\n",
      "Epoch 97/500\n",
      "768/768 [==============================] - 0s 242us/step - loss: 6174.9576 - gain_tf: -0.1081 - val_loss: 5662.6246 - val_gain_tf: -0.1260\n",
      "Epoch 98/500\n",
      "768/768 [==============================] - 0s 205us/step - loss: 6165.6482 - gain_tf: -0.1076 - val_loss: 5653.6624 - val_gain_tf: -0.1253\n",
      "Epoch 99/500\n",
      "768/768 [==============================] - 0s 227us/step - loss: 6156.4883 - gain_tf: -0.1071 - val_loss: 5644.4525 - val_gain_tf: -0.1245\n",
      "Epoch 100/500\n",
      "768/768 [==============================] - 0s 221us/step - loss: 6147.2120 - gain_tf: -0.1066 - val_loss: 5635.3187 - val_gain_tf: -0.1237\n",
      "Epoch 101/500\n",
      "768/768 [==============================] - 0s 212us/step - loss: 6137.9277 - gain_tf: -0.1061 - val_loss: 5626.3065 - val_gain_tf: -0.1230\n",
      "Epoch 102/500\n",
      "768/768 [==============================] - 0s 202us/step - loss: 6128.7241 - gain_tf: -0.1057 - val_loss: 5617.2536 - val_gain_tf: -0.1222\n",
      "Epoch 103/500\n",
      "768/768 [==============================] - 0s 251us/step - loss: 6119.4891 - gain_tf: -0.1052 - val_loss: 5608.2628 - val_gain_tf: -0.1214\n",
      "Epoch 104/500\n",
      "768/768 [==============================] - 0s 226us/step - loss: 6110.2432 - gain_tf: -0.1047 - val_loss: 5599.3902 - val_gain_tf: -0.1207\n",
      "Epoch 105/500\n",
      "768/768 [==============================] - 0s 173us/step - loss: 6101.1338 - gain_tf: -0.1042 - val_loss: 5590.3326 - val_gain_tf: -0.1199\n",
      "Epoch 106/500\n",
      "768/768 [==============================] - 0s 195us/step - loss: 6091.9575 - gain_tf: -0.1037 - val_loss: 5581.2934 - val_gain_tf: -0.1191\n",
      "Epoch 107/500\n",
      "768/768 [==============================] - 0s 198us/step - loss: 6082.7074 - gain_tf: -0.1033 - val_loss: 5572.4714 - val_gain_tf: -0.1184\n",
      "Epoch 108/500\n",
      "768/768 [==============================] - 0s 206us/step - loss: 6073.6645 - gain_tf: -0.1028 - val_loss: 5563.3989 - val_gain_tf: -0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/500\n",
      "768/768 [==============================] - 0s 191us/step - loss: 6064.4582 - gain_tf: -0.1023 - val_loss: 5554.5015 - val_gain_tf: -0.1168\n",
      "Epoch 110/500\n",
      "768/768 [==============================] - 0s 205us/step - loss: 6055.4082 - gain_tf: -0.1018 - val_loss: 5545.4509 - val_gain_tf: -0.1161\n",
      "Epoch 111/500\n",
      "768/768 [==============================] - 0s 186us/step - loss: 6046.2165 - gain_tf: -0.1013 - val_loss: 5536.6000 - val_gain_tf: -0.1153\n",
      "Epoch 112/500\n",
      "768/768 [==============================] - 0s 211us/step - loss: 6037.1758 - gain_tf: -0.1008 - val_loss: 5527.6335 - val_gain_tf: -0.1145\n",
      "Epoch 113/500\n",
      "768/768 [==============================] - 0s 218us/step - loss: 6028.0905 - gain_tf: -0.1003 - val_loss: 5518.6876 - val_gain_tf: -0.1138\n",
      "Epoch 114/500\n",
      "768/768 [==============================] - 0s 220us/step - loss: 6018.8987 - gain_tf: -0.0999 - val_loss: 5510.0329 - val_gain_tf: -0.1130\n",
      "Epoch 115/500\n",
      "768/768 [==============================] - 0s 218us/step - loss: 6009.9977 - gain_tf: -0.0994 - val_loss: 5501.0176 - val_gain_tf: -0.1122\n",
      "Epoch 116/500\n",
      "768/768 [==============================] - 0s 225us/step - loss: 6000.8399 - gain_tf: -0.0989 - val_loss: 5492.2660 - val_gain_tf: -0.1115\n",
      "Epoch 117/500\n",
      "768/768 [==============================] - 0s 193us/step - loss: 5991.8899 - gain_tf: -0.0984 - val_loss: 5483.3194 - val_gain_tf: -0.1107\n",
      "Epoch 118/500\n",
      "768/768 [==============================] - 0s 243us/step - loss: 5982.7892 - gain_tf: -0.0979 - val_loss: 5474.5690 - val_gain_tf: -0.1100\n",
      "Epoch 119/500\n",
      "768/768 [==============================] - 0s 183us/step - loss: 5973.7998 - gain_tf: -0.0975 - val_loss: 5465.7767 - val_gain_tf: -0.1092\n",
      "Epoch 120/500\n",
      "768/768 [==============================] - 0s 204us/step - loss: 5964.8269 - gain_tf: -0.0970 - val_loss: 5456.9269 - val_gain_tf: -0.1084\n",
      "Epoch 121/500\n",
      "768/768 [==============================] - 0s 192us/step - loss: 5955.8369 - gain_tf: -0.0965 - val_loss: 5448.1035 - val_gain_tf: -0.1077\n",
      "Epoch 122/500\n",
      "768/768 [==============================] - 0s 161us/step - loss: 5946.8547 - gain_tf: -0.0961 - val_loss: 5439.3107 - val_gain_tf: -0.1069\n",
      "Epoch 123/500\n",
      "768/768 [==============================] - 0s 229us/step - loss: 5937.9076 - gain_tf: -0.0956 - val_loss: 5430.5018 - val_gain_tf: -0.1062\n",
      "Epoch 124/500\n",
      "768/768 [==============================] - 0s 234us/step - loss: 5928.9405 - gain_tf: -0.0951 - val_loss: 5421.7546 - val_gain_tf: -0.1054\n",
      "Epoch 125/500\n",
      "768/768 [==============================] - 0s 179us/step - loss: 5919.9883 - gain_tf: -0.0946 - val_loss: 5413.0630 - val_gain_tf: -0.1047\n",
      "Epoch 126/500\n",
      "768/768 [==============================] - 0s 249us/step - loss: 5911.1162 - gain_tf: -0.0941 - val_loss: 5404.2743 - val_gain_tf: -0.1039\n",
      "Epoch 127/500\n",
      "768/768 [==============================] - 0s 247us/step - loss: 5902.1701 - gain_tf: -0.0936 - val_loss: 5395.5804 - val_gain_tf: -0.1031\n",
      "Epoch 128/500\n",
      "768/768 [==============================] - 0s 209us/step - loss: 5893.2604 - gain_tf: -0.0932 - val_loss: 5386.9285 - val_gain_tf: -0.1024\n",
      "Epoch 129/500\n",
      "768/768 [==============================] - 0s 237us/step - loss: 5884.4138 - gain_tf: -0.0927 - val_loss: 5378.1966 - val_gain_tf: -0.1016\n",
      "Epoch 130/500\n",
      "768/768 [==============================] - 0s 266us/step - loss: 5875.5153 - gain_tf: -0.0922 - val_loss: 5369.5387 - val_gain_tf: -0.1009\n",
      "Epoch 131/500\n",
      "768/768 [==============================] - 0s 180us/step - loss: 5866.6418 - gain_tf: -0.0918 - val_loss: 5360.9201 - val_gain_tf: -0.1001\n",
      "Epoch 132/500\n",
      "768/768 [==============================] - 0s 166us/step - loss: 5857.7832 - gain_tf: -0.0913 - val_loss: 5352.3298 - val_gain_tf: -0.0994\n",
      "Epoch 133/500\n",
      "768/768 [==============================] - 0s 202us/step - loss: 5849.0515 - gain_tf: -0.0908 - val_loss: 5343.5134 - val_gain_tf: -0.0986\n",
      "Epoch 134/500\n",
      "768/768 [==============================] - 0s 210us/step - loss: 5840.0874 - gain_tf: -0.0903 - val_loss: 5335.0242 - val_gain_tf: -0.0979\n",
      "Epoch 135/500\n",
      "768/768 [==============================] - 0s 210us/step - loss: 5831.3455 - gain_tf: -0.0899 - val_loss: 5326.3767 - val_gain_tf: -0.0971\n",
      "Epoch 136/500\n",
      "768/768 [==============================] - 0s 305us/step - loss: 5822.5574 - gain_tf: -0.0894 - val_loss: 5317.7171 - val_gain_tf: -0.0964\n",
      "Epoch 137/500\n",
      "768/768 [==============================] - 0s 201us/step - loss: 5813.7194 - gain_tf: -0.0889 - val_loss: 5309.1815 - val_gain_tf: -0.0956\n",
      "Epoch 138/500\n",
      "768/768 [==============================] - 0s 188us/step - loss: 5804.9977 - gain_tf: -0.0885 - val_loss: 5300.5370 - val_gain_tf: -0.0949\n",
      "Epoch 139/500\n",
      "768/768 [==============================] - 0s 205us/step - loss: 5796.1911 - gain_tf: -0.0880 - val_loss: 5292.0088 - val_gain_tf: -0.0941\n",
      "Epoch 140/500\n",
      "768/768 [==============================] - 0s 196us/step - loss: 5787.4681 - gain_tf: -0.0875 - val_loss: 5283.4214 - val_gain_tf: -0.0934\n",
      "Epoch 141/500\n",
      "768/768 [==============================] - 0s 229us/step - loss: 5778.6847 - gain_tf: -0.0871 - val_loss: 5274.9509 - val_gain_tf: -0.0926\n",
      "Epoch 142/500\n",
      "768/768 [==============================] - 0s 211us/step - loss: 5770.0083 - gain_tf: -0.0866 - val_loss: 5266.3717 - val_gain_tf: -0.0919\n",
      "Epoch 143/500\n",
      "768/768 [==============================] - 0s 218us/step - loss: 5761.2567 - gain_tf: -0.0861 - val_loss: 5257.8907 - val_gain_tf: -0.0912\n",
      "Epoch 144/500\n",
      "768/768 [==============================] - 0s 227us/step - loss: 5752.5681 - gain_tf: -0.0857 - val_loss: 5249.3819 - val_gain_tf: -0.0904\n",
      "Epoch 145/500\n",
      "768/768 [==============================] - 0s 236us/step - loss: 5743.8839 - gain_tf: -0.0852 - val_loss: 5240.8748 - val_gain_tf: -0.0897\n",
      "Epoch 146/500\n",
      "768/768 [==============================] - 0s 213us/step - loss: 5735.2085 - gain_tf: -0.0847 - val_loss: 5232.3715 - val_gain_tf: -0.0889\n",
      "Epoch 147/500\n",
      "768/768 [==============================] - 0s 218us/step - loss: 5726.5381 - gain_tf: -0.0843 - val_loss: 5223.8901 - val_gain_tf: -0.0882\n",
      "Epoch 148/500\n",
      "768/768 [==============================] - 0s 225us/step - loss: 5717.8507 - gain_tf: -0.0838 - val_loss: 5215.4981 - val_gain_tf: -0.0874\n",
      "Epoch 149/500\n",
      "768/768 [==============================] - 0s 203us/step - loss: 5709.2774 - gain_tf: -0.0833 - val_loss: 5206.9629 - val_gain_tf: -0.0867\n",
      "Epoch 150/500\n",
      "768/768 [==============================] - 0s 164us/step - loss: 5700.5483 - gain_tf: -0.0829 - val_loss: 5198.6681 - val_gain_tf: -0.0860\n",
      "Epoch 151/500\n",
      "768/768 [==============================] - 0s 247us/step - loss: 5692.0271 - gain_tf: -0.0824 - val_loss: 5190.1521 - val_gain_tf: -0.0852\n",
      "Epoch 152/500\n",
      "768/768 [==============================] - 0s 220us/step - loss: 5683.3644 - gain_tf: -0.0819 - val_loss: 5181.7780 - val_gain_tf: -0.0845\n",
      "Epoch 153/500\n",
      "768/768 [==============================] - 0s 251us/step - loss: 5674.8050 - gain_tf: -0.0815 - val_loss: 5173.3336 - val_gain_tf: -0.0837\n",
      "Epoch 154/500\n",
      "768/768 [==============================] - 0s 219us/step - loss: 5666.1829 - gain_tf: -0.0810 - val_loss: 5164.9925 - val_gain_tf: -0.0830\n",
      "Epoch 155/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 5657.6282 - gain_tf: -0.0806 - val_loss: 5156.6235 - val_gain_tf: -0.0823\n",
      "Epoch 156/500\n",
      "768/768 [==============================] - 0s 216us/step - loss: 5649.0289 - gain_tf: -0.0801 - val_loss: 5148.3585 - val_gain_tf: -0.0816\n",
      "Epoch 157/500\n",
      "768/768 [==============================] - 0s 200us/step - loss: 5640.5056 - gain_tf: -0.0797 - val_loss: 5140.0492 - val_gain_tf: -0.0808\n",
      "Epoch 158/500\n",
      "768/768 [==============================] - 0s 223us/step - loss: 5632.0706 - gain_tf: -0.0792 - val_loss: 5131.5203 - val_gain_tf: -0.0801\n",
      "Epoch 159/500\n",
      "768/768 [==============================] - 0s 214us/step - loss: 5623.4255 - gain_tf: -0.0787 - val_loss: 5123.2762 - val_gain_tf: -0.0793\n",
      "Epoch 160/500\n",
      "768/768 [==============================] - 0s 233us/step - loss: 5614.9479 - gain_tf: -0.0783 - val_loss: 5114.9592 - val_gain_tf: -0.0786\n",
      "Epoch 161/500\n",
      "768/768 [==============================] - 0s 212us/step - loss: 5606.4771 - gain_tf: -0.0779 - val_loss: 5106.5834 - val_gain_tf: -0.0779\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 262us/step - loss: 5597.9539 - gain_tf: -0.0774 - val_loss: 5098.2966 - val_gain_tf: -0.0771\n",
      "Epoch 163/500\n",
      "768/768 [==============================] - 0s 200us/step - loss: 5589.4278 - gain_tf: -0.0769 - val_loss: 5090.1351 - val_gain_tf: -0.0764\n",
      "Epoch 164/500\n",
      "768/768 [==============================] - 0s 211us/step - loss: 5581.0050 - gain_tf: -0.0765 - val_loss: 5081.8732 - val_gain_tf: -0.0757\n",
      "Epoch 165/500\n",
      "768/768 [==============================] - 0s 253us/step - loss: 5572.5715 - gain_tf: -0.0760 - val_loss: 5073.5758 - val_gain_tf: -0.0750\n",
      "Epoch 166/500\n",
      "768/768 [==============================] - 0s 219us/step - loss: 5564.1170 - gain_tf: -0.0756 - val_loss: 5065.3150 - val_gain_tf: -0.0742\n",
      "Epoch 167/500\n",
      "768/768 [==============================] - 0s 191us/step - loss: 5555.6700 - gain_tf: -0.0751 - val_loss: 5057.1054 - val_gain_tf: -0.0735\n",
      "Epoch 168/500\n",
      "768/768 [==============================] - 0s 196us/step - loss: 5547.3142 - gain_tf: -0.0747 - val_loss: 5048.7603 - val_gain_tf: -0.0728\n",
      "Epoch 169/500\n",
      "768/768 [==============================] - 0s 148us/step - loss: 5538.8558 - gain_tf: -0.0742 - val_loss: 5040.5496 - val_gain_tf: -0.0720\n",
      "Epoch 170/500\n",
      "768/768 [==============================] - 0s 204us/step - loss: 5530.4407 - gain_tf: -0.0738 - val_loss: 5032.3972 - val_gain_tf: -0.0713\n",
      "Epoch 171/500\n",
      "768/768 [==============================] - 0s 214us/step - loss: 5522.0545 - gain_tf: -0.0733 - val_loss: 5024.2596 - val_gain_tf: -0.0706\n",
      "Epoch 172/500\n",
      "768/768 [==============================] - 0s 173us/step - loss: 5513.6490 - gain_tf: -0.0728 - val_loss: 5016.2055 - val_gain_tf: -0.0699\n",
      "Epoch 173/500\n",
      "768/768 [==============================] - 0s 182us/step - loss: 5505.3654 - gain_tf: -0.0724 - val_loss: 5007.9684 - val_gain_tf: -0.0692\n",
      "Epoch 174/500\n",
      "768/768 [==============================] - 0s 218us/step - loss: 5497.0164 - gain_tf: -0.0720 - val_loss: 4999.7379 - val_gain_tf: -0.0684\n",
      "Epoch 175/500\n",
      "768/768 [==============================] - 0s 231us/step - loss: 5488.5715 - gain_tf: -0.0715 - val_loss: 4991.7723 - val_gain_tf: -0.0677\n",
      "Epoch 176/500\n",
      "768/768 [==============================] - 0s 243us/step - loss: 5480.3635 - gain_tf: -0.0711 - val_loss: 4983.5253 - val_gain_tf: -0.0670\n",
      "Epoch 177/500\n",
      "768/768 [==============================] - 0s 200us/step - loss: 5471.9769 - gain_tf: -0.0706 - val_loss: 4975.4460 - val_gain_tf: -0.0663\n",
      "Epoch 178/500\n",
      "768/768 [==============================] - 0s 197us/step - loss: 5463.7488 - gain_tf: -0.0702 - val_loss: 4967.2077 - val_gain_tf: -0.0656\n",
      "Epoch 179/500\n",
      "768/768 [==============================] - 0s 161us/step - loss: 5455.3369 - gain_tf: -0.0697 - val_loss: 4959.2504 - val_gain_tf: -0.0648\n",
      "Epoch 180/500\n",
      "768/768 [==============================] - 0s 194us/step - loss: 5447.1320 - gain_tf: -0.0693 - val_loss: 4951.1229 - val_gain_tf: -0.0641\n",
      "Epoch 181/500\n",
      "768/768 [==============================] - 0s 212us/step - loss: 5438.8550 - gain_tf: -0.0688 - val_loss: 4943.0258 - val_gain_tf: -0.0634\n",
      "Epoch 182/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 5430.5731 - gain_tf: -0.0684 - val_loss: 4934.9946 - val_gain_tf: -0.0627\n",
      "Epoch 183/500\n",
      "768/768 [==============================] - 0s 186us/step - loss: 5422.3485 - gain_tf: -0.0680 - val_loss: 4926.9210 - val_gain_tf: -0.0620\n",
      "Epoch 184/500\n",
      "768/768 [==============================] - 0s 203us/step - loss: 5414.0464 - gain_tf: -0.0675 - val_loss: 4919.0110 - val_gain_tf: -0.0613\n",
      "Epoch 185/500\n",
      "768/768 [==============================] - 0s 158us/step - loss: 5405.9259 - gain_tf: -0.0671 - val_loss: 4910.8647 - val_gain_tf: -0.0606\n",
      "Epoch 186/500\n",
      "768/768 [==============================] - 0s 197us/step - loss: 5397.7121 - gain_tf: -0.0666 - val_loss: 4902.7450 - val_gain_tf: -0.0598\n",
      "Epoch 187/500\n",
      "768/768 [==============================] - 0s 226us/step - loss: 5389.3920 - gain_tf: -0.0662 - val_loss: 4894.9048 - val_gain_tf: -0.0591\n",
      "Epoch 188/500\n",
      "768/768 [==============================] - 0s 202us/step - loss: 5381.3094 - gain_tf: -0.0658 - val_loss: 4886.8244 - val_gain_tf: -0.0584\n",
      "Epoch 189/500\n",
      "768/768 [==============================] - 0s 197us/step - loss: 5373.0825 - gain_tf: -0.0653 - val_loss: 4878.8680 - val_gain_tf: -0.0577\n",
      "Epoch 190/500\n",
      "768/768 [==============================] - 0s 223us/step - loss: 5364.8931 - gain_tf: -0.0649 - val_loss: 4870.9739 - val_gain_tf: -0.0570\n",
      "Epoch 191/500\n",
      "768/768 [==============================] - 0s 198us/step - loss: 5356.7473 - gain_tf: -0.0644 - val_loss: 4863.0589 - val_gain_tf: -0.0563\n",
      "Epoch 192/500\n",
      "768/768 [==============================] - 0s 188us/step - loss: 5348.6469 - gain_tf: -0.0640 - val_loss: 4855.0548 - val_gain_tf: -0.0556\n",
      "Epoch 193/500\n",
      "768/768 [==============================] - 0s 227us/step - loss: 5340.4546 - gain_tf: -0.0636 - val_loss: 4847.1906 - val_gain_tf: -0.0549\n",
      "Epoch 194/500\n",
      "768/768 [==============================] - 0s 186us/step - loss: 5332.3726 - gain_tf: -0.0631 - val_loss: 4839.2378 - val_gain_tf: -0.0542\n",
      "Epoch 195/500\n",
      "768/768 [==============================] - 0s 197us/step - loss: 5324.2431 - gain_tf: -0.0627 - val_loss: 4831.3366 - val_gain_tf: -0.0535\n",
      "Epoch 196/500\n",
      "768/768 [==============================] - 0s 187us/step - loss: 5316.1555 - gain_tf: -0.0622 - val_loss: 4823.4161 - val_gain_tf: -0.0528\n",
      "Epoch 197/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 5308.0993 - gain_tf: -0.0618 - val_loss: 4815.4469 - val_gain_tf: -0.0521\n",
      "Epoch 198/500\n",
      "768/768 [==============================] - 0s 201us/step - loss: 5299.9085 - gain_tf: -0.0614 - val_loss: 4807.7541 - val_gain_tf: -0.0514\n",
      "Epoch 199/500\n",
      "768/768 [==============================] - 0s 203us/step - loss: 5291.9381 - gain_tf: -0.0609 - val_loss: 4799.8397 - val_gain_tf: -0.0507\n",
      "Epoch 200/500\n",
      "768/768 [==============================] - 0s 205us/step - loss: 5283.8345 - gain_tf: -0.0605 - val_loss: 4792.0503 - val_gain_tf: -0.0500\n",
      "Epoch 201/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 5275.8691 - gain_tf: -0.0601 - val_loss: 4784.0955 - val_gain_tf: -0.0493\n",
      "Epoch 202/500\n",
      "768/768 [==============================] - 0s 190us/step - loss: 5267.7728 - gain_tf: -0.0597 - val_loss: 4776.3012 - val_gain_tf: -0.0486\n",
      "Epoch 203/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 5259.7505 - gain_tf: -0.0592 - val_loss: 4768.5154 - val_gain_tf: -0.0479\n",
      "Epoch 204/500\n",
      "768/768 [==============================] - 0s 228us/step - loss: 5251.7661 - gain_tf: -0.0588 - val_loss: 4760.6817 - val_gain_tf: -0.0472\n",
      "Epoch 205/500\n",
      "768/768 [==============================] - 0s 197us/step - loss: 5243.7504 - gain_tf: -0.0584 - val_loss: 4752.9035 - val_gain_tf: -0.0465\n",
      "Epoch 206/500\n",
      "768/768 [==============================] - 0s 242us/step - loss: 5235.7613 - gain_tf: -0.0580 - val_loss: 4745.1383 - val_gain_tf: -0.0458\n",
      "Epoch 207/500\n",
      "768/768 [==============================] - 0s 217us/step - loss: 5227.7457 - gain_tf: -0.0575 - val_loss: 4737.4828 - val_gain_tf: -0.0451\n",
      "Epoch 208/500\n",
      "768/768 [==============================] - 0s 232us/step - loss: 5219.8696 - gain_tf: -0.0571 - val_loss: 4729.6196 - val_gain_tf: -0.0444\n",
      "Epoch 209/500\n",
      "768/768 [==============================] - 0s 196us/step - loss: 5211.9332 - gain_tf: -0.0566 - val_loss: 4721.7468 - val_gain_tf: -0.0437\n",
      "Epoch 210/500\n",
      "768/768 [==============================] - 0s 218us/step - loss: 5203.8646 - gain_tf: -0.0562 - val_loss: 4714.1844 - val_gain_tf: -0.0430\n",
      "Epoch 211/500\n",
      "768/768 [==============================] - 0s 195us/step - loss: 5196.0333 - gain_tf: -0.0558 - val_loss: 4706.3917 - val_gain_tf: -0.0423\n",
      "Epoch 212/500\n",
      "768/768 [==============================] - 0s 216us/step - loss: 5188.0838 - gain_tf: -0.0554 - val_loss: 4698.6874 - val_gain_tf: -0.0417\n",
      "Epoch 213/500\n",
      "768/768 [==============================] - 0s 187us/step - loss: 5180.2052 - gain_tf: -0.0550 - val_loss: 4690.9302 - val_gain_tf: -0.0410\n",
      "Epoch 214/500\n",
      "768/768 [==============================] - 0s 230us/step - loss: 5172.2866 - gain_tf: -0.0545 - val_loss: 4683.2397 - val_gain_tf: -0.0403\n",
      "Epoch 215/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 216us/step - loss: 5164.3878 - gain_tf: -0.0541 - val_loss: 4675.5929 - val_gain_tf: -0.0396\n",
      "Epoch 216/500\n",
      "768/768 [==============================] - 0s 187us/step - loss: 5156.5463 - gain_tf: -0.0537 - val_loss: 4667.8836 - val_gain_tf: -0.0389\n",
      "Epoch 217/500\n",
      "768/768 [==============================] - 0s 198us/step - loss: 5148.5845 - gain_tf: -0.0533 - val_loss: 4660.4244 - val_gain_tf: -0.0382\n",
      "Epoch 218/500\n",
      "768/768 [==============================] - 0s 188us/step - loss: 5140.8508 - gain_tf: -0.0528 - val_loss: 4652.6796 - val_gain_tf: -0.0375\n",
      "Epoch 219/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 5132.9549 - gain_tf: -0.0524 - val_loss: 4645.0746 - val_gain_tf: -0.0369\n",
      "Epoch 220/500\n",
      "768/768 [==============================] - 0s 202us/step - loss: 5125.1587 - gain_tf: -0.0520 - val_loss: 4637.4044 - val_gain_tf: -0.0362\n",
      "Epoch 221/500\n",
      "768/768 [==============================] - 0s 203us/step - loss: 5117.2932 - gain_tf: -0.0516 - val_loss: 4629.8506 - val_gain_tf: -0.0355\n",
      "Epoch 222/500\n",
      "768/768 [==============================] - 0s 217us/step - loss: 5109.5022 - gain_tf: -0.0512 - val_loss: 4622.2773 - val_gain_tf: -0.0348\n",
      "Epoch 223/500\n",
      "768/768 [==============================] - 0s 151us/step - loss: 5101.7366 - gain_tf: -0.0507 - val_loss: 4614.6345 - val_gain_tf: -0.0341\n",
      "Epoch 224/500\n",
      "768/768 [==============================] - 0s 215us/step - loss: 5093.9050 - gain_tf: -0.0503 - val_loss: 4607.1105 - val_gain_tf: -0.0335\n",
      "Epoch 225/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 5086.1975 - gain_tf: -0.0499 - val_loss: 4599.4449 - val_gain_tf: -0.0328\n",
      "Epoch 226/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 5078.3750 - gain_tf: -0.0495 - val_loss: 4591.9340 - val_gain_tf: -0.0321\n",
      "Epoch 227/500\n",
      "768/768 [==============================] - 0s 208us/step - loss: 5070.6587 - gain_tf: -0.0491 - val_loss: 4584.3525 - val_gain_tf: -0.0314\n",
      "Epoch 228/500\n",
      "768/768 [==============================] - 0s 191us/step - loss: 5062.8856 - gain_tf: -0.0487 - val_loss: 4576.8599 - val_gain_tf: -0.0308\n",
      "Epoch 229/500\n",
      "768/768 [==============================] - 0s 182us/step - loss: 5055.1857 - gain_tf: -0.0483 - val_loss: 4569.3182 - val_gain_tf: -0.0301\n",
      "Epoch 230/500\n",
      "768/768 [==============================] - 0s 198us/step - loss: 5047.5021 - gain_tf: -0.0478 - val_loss: 4561.7236 - val_gain_tf: -0.0294\n",
      "Epoch 231/500\n",
      "768/768 [==============================] - 0s 197us/step - loss: 5039.6758 - gain_tf: -0.0474 - val_loss: 4554.4265 - val_gain_tf: -0.0288\n",
      "Epoch 232/500\n",
      "768/768 [==============================] - 0s 208us/step - loss: 5032.1103 - gain_tf: -0.0470 - val_loss: 4546.8338 - val_gain_tf: -0.0281\n",
      "Epoch 233/500\n",
      "768/768 [==============================] - 0s 195us/step - loss: 5024.3515 - gain_tf: -0.0466 - val_loss: 4539.4275 - val_gain_tf: -0.0274\n",
      "Epoch 234/500\n",
      "768/768 [==============================] - 0s 194us/step - loss: 5016.6740 - gain_tf: -0.0462 - val_loss: 4532.0449 - val_gain_tf: -0.0268\n",
      "Epoch 235/500\n",
      "768/768 [==============================] - 0s 213us/step - loss: 5009.1255 - gain_tf: -0.0458 - val_loss: 4524.4158 - val_gain_tf: -0.0261\n",
      "Epoch 236/500\n",
      "768/768 [==============================] - 0s 176us/step - loss: 5001.3925 - gain_tf: -0.0454 - val_loss: 4516.9911 - val_gain_tf: -0.0254\n",
      "Epoch 237/500\n",
      "768/768 [==============================] - 0s 205us/step - loss: 4993.7627 - gain_tf: -0.0450 - val_loss: 4509.5656 - val_gain_tf: -0.0248\n",
      "Epoch 238/500\n",
      "768/768 [==============================] - 0s 201us/step - loss: 4986.1316 - gain_tf: -0.0445 - val_loss: 4502.1634 - val_gain_tf: -0.0241\n",
      "Epoch 239/500\n",
      "768/768 [==============================] - 0s 206us/step - loss: 4978.5320 - gain_tf: -0.0441 - val_loss: 4494.7462 - val_gain_tf: -0.0234\n",
      "Epoch 240/500\n",
      "768/768 [==============================] - 0s 206us/step - loss: 4970.9403 - gain_tf: -0.0437 - val_loss: 4487.3199 - val_gain_tf: -0.0228\n",
      "Epoch 241/500\n",
      "768/768 [==============================] - 0s 223us/step - loss: 4963.2611 - gain_tf: -0.0433 - val_loss: 4480.1046 - val_gain_tf: -0.0221\n",
      "Epoch 242/500\n",
      "768/768 [==============================] - 0s 221us/step - loss: 4955.7715 - gain_tf: -0.0429 - val_loss: 4472.6831 - val_gain_tf: -0.0215\n",
      "Epoch 243/500\n",
      "768/768 [==============================] - 0s 183us/step - loss: 4948.1812 - gain_tf: -0.0425 - val_loss: 4465.3161 - val_gain_tf: -0.0208\n",
      "Epoch 244/500\n",
      "768/768 [==============================] - 0s 244us/step - loss: 4940.5937 - gain_tf: -0.0421 - val_loss: 4458.0294 - val_gain_tf: -0.0201\n",
      "Epoch 245/500\n",
      "768/768 [==============================] - 0s 222us/step - loss: 4933.1000 - gain_tf: -0.0417 - val_loss: 4450.6350 - val_gain_tf: -0.0195\n",
      "Epoch 246/500\n",
      "768/768 [==============================] - 0s 208us/step - loss: 4925.5147 - gain_tf: -0.0413 - val_loss: 4443.3535 - val_gain_tf: -0.0188\n",
      "Epoch 247/500\n",
      "768/768 [==============================] - 0s 194us/step - loss: 4918.0527 - gain_tf: -0.0409 - val_loss: 4435.9418 - val_gain_tf: -0.0182\n",
      "Epoch 248/500\n",
      "768/768 [==============================] - 0s 179us/step - loss: 4910.4957 - gain_tf: -0.0405 - val_loss: 4428.6446 - val_gain_tf: -0.0175\n",
      "Epoch 249/500\n",
      "768/768 [==============================] - 0s 164us/step - loss: 4902.9859 - gain_tf: -0.0401 - val_loss: 4421.3809 - val_gain_tf: -0.0169\n",
      "Epoch 250/500\n",
      "768/768 [==============================] - 0s 210us/step - loss: 4895.4831 - gain_tf: -0.0397 - val_loss: 4414.1534 - val_gain_tf: -0.0162\n",
      "Epoch 251/500\n",
      "768/768 [==============================] - 0s 218us/step - loss: 4888.0239 - gain_tf: -0.0393 - val_loss: 4406.8786 - val_gain_tf: -0.0156\n",
      "Epoch 252/500\n",
      "768/768 [==============================] - 0s 192us/step - loss: 4880.5237 - gain_tf: -0.0389 - val_loss: 4399.6862 - val_gain_tf: -0.0149\n",
      "Epoch 253/500\n",
      "768/768 [==============================] - 0s 230us/step - loss: 4873.1120 - gain_tf: -0.0385 - val_loss: 4392.3886 - val_gain_tf: -0.0143\n",
      "Epoch 254/500\n",
      "768/768 [==============================] - 0s 209us/step - loss: 4865.6506 - gain_tf: -0.0381 - val_loss: 4385.1291 - val_gain_tf: -0.0136\n",
      "Epoch 255/500\n",
      "768/768 [==============================] - 0s 224us/step - loss: 4858.1661 - gain_tf: -0.0377 - val_loss: 4377.9930 - val_gain_tf: -0.0130\n",
      "Epoch 256/500\n",
      "768/768 [==============================] - 0s 182us/step - loss: 4850.8392 - gain_tf: -0.0373 - val_loss: 4370.6334 - val_gain_tf: -0.0123\n",
      "Epoch 257/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 4843.3187 - gain_tf: -0.0369 - val_loss: 4363.5328 - val_gain_tf: -0.0117\n",
      "Epoch 258/500\n",
      "768/768 [==============================] - 0s 245us/step - loss: 4835.9705 - gain_tf: -0.0365 - val_loss: 4356.3033 - val_gain_tf: -0.0110\n",
      "Epoch 259/500\n",
      "768/768 [==============================] - 0s 201us/step - loss: 4828.5698 - gain_tf: -0.0361 - val_loss: 4349.1067 - val_gain_tf: -0.0104\n",
      "Epoch 260/500\n",
      "768/768 [==============================] - 0s 232us/step - loss: 4821.1629 - gain_tf: -0.0357 - val_loss: 4341.9735 - val_gain_tf: -0.0098\n",
      "Epoch 261/500\n",
      "768/768 [==============================] - 0s 196us/step - loss: 4813.8993 - gain_tf: -0.0353 - val_loss: 4334.6368 - val_gain_tf: -0.0091\n",
      "Epoch 262/500\n",
      "768/768 [==============================] - 0s 245us/step - loss: 4806.4084 - gain_tf: -0.0349 - val_loss: 4327.6005 - val_gain_tf: -0.0085\n",
      "Epoch 263/500\n",
      "768/768 [==============================] - 0s 211us/step - loss: 4799.0751 - gain_tf: -0.0345 - val_loss: 4320.5322 - val_gain_tf: -0.0079\n",
      "Epoch 264/500\n",
      "768/768 [==============================] - 0s 222us/step - loss: 4791.7799 - gain_tf: -0.0341 - val_loss: 4313.3739 - val_gain_tf: -0.0072\n",
      "Epoch 265/500\n",
      "768/768 [==============================] - 0s 262us/step - loss: 4784.4239 - gain_tf: -0.0337 - val_loss: 4306.2990 - val_gain_tf: -0.0066\n",
      "Epoch 266/500\n",
      "768/768 [==============================] - 0s 267us/step - loss: 4777.1569 - gain_tf: -0.0333 - val_loss: 4299.1247 - val_gain_tf: -0.0059\n",
      "Epoch 267/500\n",
      "768/768 [==============================] - 0s 272us/step - loss: 4769.7828 - gain_tf: -0.0329 - val_loss: 4292.1237 - val_gain_tf: -0.0053\n",
      "Epoch 268/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 273us/step - loss: 4762.5193 - gain_tf: -0.0325 - val_loss: 4285.0569 - val_gain_tf: -0.0047\n",
      "Epoch 269/500\n",
      "768/768 [==============================] - 0s 218us/step - loss: 4755.2385 - gain_tf: -0.0321 - val_loss: 4277.9975 - val_gain_tf: -0.0041\n",
      "Epoch 270/500\n",
      "768/768 [==============================] - 0s 195us/step - loss: 4748.0067 - gain_tf: -0.0318 - val_loss: 4270.8622 - val_gain_tf: -0.0034\n",
      "Epoch 271/500\n",
      "768/768 [==============================] - 0s 227us/step - loss: 4740.7234 - gain_tf: -0.0314 - val_loss: 4263.8026 - val_gain_tf: -0.0028\n",
      "Epoch 272/500\n",
      "768/768 [==============================] - 0s 229us/step - loss: 4733.4324 - gain_tf: -0.0310 - val_loss: 4256.8489 - val_gain_tf: -0.0022\n",
      "Epoch 273/500\n",
      "768/768 [==============================] - 0s 194us/step - loss: 4726.2406 - gain_tf: -0.0306 - val_loss: 4249.7959 - val_gain_tf: -0.0015\n",
      "Epoch 274/500\n",
      "768/768 [==============================] - 0s 253us/step - loss: 4719.0064 - gain_tf: -0.0302 - val_loss: 4242.7766 - val_gain_tf: -9.1280e-04\n",
      "Epoch 275/500\n",
      "768/768 [==============================] - 0s 219us/step - loss: 4711.7625 - gain_tf: -0.0298 - val_loss: 4235.8343 - val_gain_tf: -2.9376e-04\n",
      "Epoch 276/500\n",
      "768/768 [==============================] - 0s 212us/step - loss: 4704.5934 - gain_tf: -0.0294 - val_loss: 4228.8238 - val_gain_tf: 3.3177e-04\n",
      "Epoch 277/500\n",
      "768/768 [==============================] - 0s 233us/step - loss: 4697.3759 - gain_tf: -0.0291 - val_loss: 4221.8755 - val_gain_tf: 9.5120e-04\n",
      "Epoch 278/500\n",
      "768/768 [==============================] - 0s 240us/step - loss: 4690.2228 - gain_tf: -0.0287 - val_loss: 4214.8739 - val_gain_tf: 0.0016\n",
      "Epoch 279/500\n",
      "768/768 [==============================] - 0s 232us/step - loss: 4683.0868 - gain_tf: -0.0283 - val_loss: 4207.8111 - val_gain_tf: 0.0022\n",
      "Epoch 280/500\n",
      "768/768 [==============================] - 0s 235us/step - loss: 4675.8685 - gain_tf: -0.0279 - val_loss: 4200.8948 - val_gain_tf: 0.0028\n",
      "Epoch 281/500\n",
      "768/768 [==============================] - 0s 251us/step - loss: 4668.6638 - gain_tf: -0.0275 - val_loss: 4194.1282 - val_gain_tf: 0.0034\n",
      "Epoch 282/500\n",
      "768/768 [==============================] - 0s 211us/step - loss: 4661.6447 - gain_tf: -0.0271 - val_loss: 4187.0891 - val_gain_tf: 0.0041\n",
      "Epoch 283/500\n",
      "768/768 [==============================] - 0s 273us/step - loss: 4654.4025 - gain_tf: -0.0268 - val_loss: 4180.3298 - val_gain_tf: 0.0047\n",
      "Epoch 284/500\n",
      "768/768 [==============================] - 0s 207us/step - loss: 4647.3650 - gain_tf: -0.0264 - val_loss: 4173.3945 - val_gain_tf: 0.0053\n",
      "Epoch 285/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 4640.2168 - gain_tf: -0.0260 - val_loss: 4166.5676 - val_gain_tf: 0.0059\n",
      "Epoch 286/500\n",
      "768/768 [==============================] - 0s 233us/step - loss: 4633.1488 - gain_tf: -0.0256 - val_loss: 4159.6815 - val_gain_tf: 0.0065\n",
      "Epoch 287/500\n",
      "768/768 [==============================] - 0s 204us/step - loss: 4626.0935 - gain_tf: -0.0252 - val_loss: 4152.7336 - val_gain_tf: 0.0071\n",
      "Epoch 288/500\n",
      "768/768 [==============================] - 0s 224us/step - loss: 4619.0289 - gain_tf: -0.0249 - val_loss: 4145.7842 - val_gain_tf: 0.0077\n",
      "Epoch 289/500\n",
      "768/768 [==============================] - 0s 226us/step - loss: 4611.9052 - gain_tf: -0.0245 - val_loss: 4138.9898 - val_gain_tf: 0.0083\n",
      "Epoch 290/500\n",
      "768/768 [==============================] - 0s 223us/step - loss: 4604.8619 - gain_tf: -0.0241 - val_loss: 4132.1879 - val_gain_tf: 0.0089\n",
      "Epoch 291/500\n",
      "768/768 [==============================] - 0s 219us/step - loss: 4597.8287 - gain_tf: -0.0237 - val_loss: 4125.3806 - val_gain_tf: 0.0095\n",
      "Epoch 292/500\n",
      "768/768 [==============================] - 0s 216us/step - loss: 4590.8037 - gain_tf: -0.0233 - val_loss: 4118.5755 - val_gain_tf: 0.0102\n",
      "Epoch 293/500\n",
      "768/768 [==============================] - 0s 232us/step - loss: 4583.8140 - gain_tf: -0.0230 - val_loss: 4111.7159 - val_gain_tf: 0.0108\n",
      "Epoch 294/500\n",
      "768/768 [==============================] - 0s 222us/step - loss: 4576.7446 - gain_tf: -0.0226 - val_loss: 4105.0083 - val_gain_tf: 0.0114\n",
      "Epoch 295/500\n",
      "768/768 [==============================] - 0s 198us/step - loss: 4569.7516 - gain_tf: -0.0222 - val_loss: 4098.3026 - val_gain_tf: 0.0120\n",
      "Epoch 296/500\n",
      "768/768 [==============================] - 0s 186us/step - loss: 4562.8658 - gain_tf: -0.0219 - val_loss: 4091.3750 - val_gain_tf: 0.0126\n",
      "Epoch 297/500\n",
      "768/768 [==============================] - 0s 243us/step - loss: 4555.7809 - gain_tf: -0.0214 - val_loss: 4084.7122 - val_gain_tf: 0.0132\n",
      "Epoch 298/500\n",
      "768/768 [==============================] - 0s 219us/step - loss: 4548.8497 - gain_tf: -0.0211 - val_loss: 4077.9794 - val_gain_tf: 0.0138\n",
      "Epoch 299/500\n",
      "768/768 [==============================] - 0s 249us/step - loss: 4541.9213 - gain_tf: -0.0207 - val_loss: 4071.2007 - val_gain_tf: 0.0144\n",
      "Epoch 300/500\n",
      "768/768 [==============================] - 0s 210us/step - loss: 4534.9532 - gain_tf: -0.0203 - val_loss: 4064.4923 - val_gain_tf: 0.0150\n",
      "Epoch 301/500\n",
      "768/768 [==============================] - 0s 237us/step - loss: 4528.0460 - gain_tf: -0.0199 - val_loss: 4057.7420 - val_gain_tf: 0.0156\n",
      "Epoch 302/500\n",
      "768/768 [==============================] - 0s 189us/step - loss: 4521.1177 - gain_tf: -0.0196 - val_loss: 4051.0325 - val_gain_tf: 0.0162\n",
      "Epoch 303/500\n",
      "768/768 [==============================] - 0s 238us/step - loss: 4514.2203 - gain_tf: -0.0192 - val_loss: 4044.3093 - val_gain_tf: 0.0168\n",
      "Epoch 304/500\n",
      "768/768 [==============================] - 0s 236us/step - loss: 4507.2649 - gain_tf: -0.0188 - val_loss: 4037.7279 - val_gain_tf: 0.0173\n",
      "Epoch 305/500\n",
      "768/768 [==============================] - 0s 229us/step - loss: 4500.4524 - gain_tf: -0.0185 - val_loss: 4030.9870 - val_gain_tf: 0.0179\n",
      "Epoch 306/500\n",
      "768/768 [==============================] - 0s 261us/step - loss: 4493.4862 - gain_tf: -0.0181 - val_loss: 4024.4633 - val_gain_tf: 0.0185\n",
      "Epoch 307/500\n",
      "768/768 [==============================] - 0s 205us/step - loss: 4486.6917 - gain_tf: -0.0178 - val_loss: 4017.7823 - val_gain_tf: 0.0191\n",
      "Epoch 308/500\n",
      "768/768 [==============================] - 0s 208us/step - loss: 4479.8661 - gain_tf: -0.0174 - val_loss: 4011.0471 - val_gain_tf: 0.0197\n",
      "Epoch 309/500\n",
      "768/768 [==============================] - 0s 252us/step - loss: 4472.9462 - gain_tf: -0.0170 - val_loss: 4004.4986 - val_gain_tf: 0.0203\n",
      "Epoch 310/500\n",
      "768/768 [==============================] - 0s 223us/step - loss: 4466.1173 - gain_tf: -0.0166 - val_loss: 3997.9461 - val_gain_tf: 0.0209\n",
      "Epoch 311/500\n",
      "768/768 [==============================] - 0s 202us/step - loss: 4459.3642 - gain_tf: -0.0163 - val_loss: 3991.2436 - val_gain_tf: 0.0215\n",
      "Epoch 312/500\n",
      "768/768 [==============================] - 0s 227us/step - loss: 4452.4663 - gain_tf: -0.0159 - val_loss: 3984.7551 - val_gain_tf: 0.0220\n",
      "Epoch 313/500\n",
      "768/768 [==============================] - 0s 230us/step - loss: 4445.7169 - gain_tf: -0.0155 - val_loss: 3978.1579 - val_gain_tf: 0.0226\n",
      "Epoch 314/500\n",
      "768/768 [==============================] - 0s 224us/step - loss: 4438.9191 - gain_tf: -0.0151 - val_loss: 3971.5872 - val_gain_tf: 0.0232\n",
      "Epoch 315/500\n",
      "768/768 [==============================] - 0s 288us/step - loss: 4432.1247 - gain_tf: -0.0148 - val_loss: 3965.0619 - val_gain_tf: 0.0238\n",
      "Epoch 316/500\n",
      "768/768 [==============================] - 0s 240us/step - loss: 4425.3877 - gain_tf: -0.0144 - val_loss: 3958.4764 - val_gain_tf: 0.0244\n",
      "Epoch 317/500\n",
      "768/768 [==============================] - 0s 226us/step - loss: 4418.6266 - gain_tf: -0.0141 - val_loss: 3951.9070 - val_gain_tf: 0.0249\n",
      "Epoch 318/500\n",
      "768/768 [==============================] - 0s 244us/step - loss: 4411.8374 - gain_tf: -0.0137 - val_loss: 3945.4496 - val_gain_tf: 0.0255\n",
      "Epoch 319/500\n",
      "768/768 [==============================] - 0s 210us/step - loss: 4405.1688 - gain_tf: -0.0133 - val_loss: 3938.8513 - val_gain_tf: 0.0261\n",
      "Epoch 320/500\n",
      "768/768 [==============================] - 0s 242us/step - loss: 4398.3765 - gain_tf: -0.0130 - val_loss: 3932.4281 - val_gain_tf: 0.0267\n",
      "Epoch 321/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 230us/step - loss: 4391.7069 - gain_tf: -0.0126 - val_loss: 3925.9138 - val_gain_tf: 0.0272\n",
      "Epoch 322/500\n",
      "768/768 [==============================] - 0s 215us/step - loss: 4385.0298 - gain_tf: -0.0123 - val_loss: 3919.3667 - val_gain_tf: 0.0278\n",
      "Epoch 323/500\n",
      "768/768 [==============================] - 0s 229us/step - loss: 4378.2772 - gain_tf: -0.0119 - val_loss: 3912.9763 - val_gain_tf: 0.0284\n",
      "Epoch 324/500\n",
      "768/768 [==============================] - 0s 211us/step - loss: 4371.6531 - gain_tf: -0.0115 - val_loss: 3906.4764 - val_gain_tf: 0.0290\n",
      "Epoch 325/500\n",
      "768/768 [==============================] - 0s 216us/step - loss: 4364.9246 - gain_tf: -0.0111 - val_loss: 3900.1349 - val_gain_tf: 0.0295\n",
      "Epoch 326/500\n",
      "768/768 [==============================] - 0s 248us/step - loss: 4358.3454 - gain_tf: -0.0108 - val_loss: 3893.6252 - val_gain_tf: 0.0301\n",
      "Epoch 327/500\n",
      "768/768 [==============================] - 0s 205us/step - loss: 4351.6269 - gain_tf: -0.0105 - val_loss: 3887.2967 - val_gain_tf: 0.0307\n",
      "Epoch 328/500\n",
      "768/768 [==============================] - 0s 196us/step - loss: 4345.0935 - gain_tf: -0.0101 - val_loss: 3880.7531 - val_gain_tf: 0.0312\n",
      "Epoch 329/500\n",
      "768/768 [==============================] - 0s 232us/step - loss: 4338.3703 - gain_tf: -0.0098 - val_loss: 3874.4492 - val_gain_tf: 0.0318\n",
      "Epoch 330/500\n",
      "768/768 [==============================] - 0s 221us/step - loss: 4331.7869 - gain_tf: -0.0094 - val_loss: 3868.0867 - val_gain_tf: 0.0323\n",
      "Epoch 331/500\n",
      "768/768 [==============================] - 0s 224us/step - loss: 4325.1825 - gain_tf: -0.0090 - val_loss: 3861.7393 - val_gain_tf: 0.0329\n",
      "Epoch 332/500\n",
      "768/768 [==============================] - 0s 212us/step - loss: 4318.6249 - gain_tf: -0.0087 - val_loss: 3855.3202 - val_gain_tf: 0.0335\n",
      "Epoch 333/500\n",
      "768/768 [==============================] - 0s 228us/step - loss: 4312.0469 - gain_tf: -0.0083 - val_loss: 3848.9138 - val_gain_tf: 0.0340\n",
      "Epoch 334/500\n",
      "768/768 [==============================] - 0s 245us/step - loss: 4305.4746 - gain_tf: -0.0079 - val_loss: 3842.5356 - val_gain_tf: 0.0346\n",
      "Epoch 335/500\n",
      "768/768 [==============================] - 0s 221us/step - loss: 4298.8749 - gain_tf: -0.0076 - val_loss: 3836.2615 - val_gain_tf: 0.0352\n",
      "Epoch 336/500\n",
      "768/768 [==============================] - 0s 225us/step - loss: 4292.2970 - gain_tf: -0.0072 - val_loss: 3830.0695 - val_gain_tf: 0.0357\n",
      "Epoch 337/500\n",
      "768/768 [==============================] - 0s 213us/step - loss: 4285.8401 - gain_tf: -0.0069 - val_loss: 3823.6945 - val_gain_tf: 0.0363\n",
      "Epoch 338/500\n",
      "768/768 [==============================] - 0s 209us/step - loss: 4279.3203 - gain_tf: -0.0065 - val_loss: 3817.3246 - val_gain_tf: 0.0368\n",
      "Epoch 339/500\n",
      "768/768 [==============================] - 0s 191us/step - loss: 4272.7368 - gain_tf: -0.0062 - val_loss: 3811.1258 - val_gain_tf: 0.0374\n",
      "Epoch 340/500\n",
      "768/768 [==============================] - 0s 261us/step - loss: 4266.2550 - gain_tf: -0.0058 - val_loss: 3804.8798 - val_gain_tf: 0.0379\n",
      "Epoch 341/500\n",
      "768/768 [==============================] - 0s 224us/step - loss: 4259.7515 - gain_tf: -0.0055 - val_loss: 3798.6646 - val_gain_tf: 0.0385\n",
      "Epoch 342/500\n",
      "768/768 [==============================] - 0s 233us/step - loss: 4253.3474 - gain_tf: -0.0051 - val_loss: 3792.2769 - val_gain_tf: 0.0390\n",
      "Epoch 343/500\n",
      "768/768 [==============================] - 0s 198us/step - loss: 4246.8230 - gain_tf: -0.0048 - val_loss: 3786.0316 - val_gain_tf: 0.0396\n",
      "Epoch 344/500\n",
      "768/768 [==============================] - 0s 228us/step - loss: 4240.3612 - gain_tf: -0.0044 - val_loss: 3779.8029 - val_gain_tf: 0.0401\n",
      "Epoch 345/500\n",
      "768/768 [==============================] - 0s 217us/step - loss: 4233.9186 - gain_tf: -0.0041 - val_loss: 3773.5714 - val_gain_tf: 0.0407\n",
      "Epoch 346/500\n",
      "768/768 [==============================] - 0s 205us/step - loss: 4227.4650 - gain_tf: -0.0038 - val_loss: 3767.3907 - val_gain_tf: 0.0412\n",
      "Epoch 347/500\n",
      "768/768 [==============================] - 0s 259us/step - loss: 4221.0872 - gain_tf: -0.0034 - val_loss: 3761.1114 - val_gain_tf: 0.0418\n",
      "Epoch 348/500\n",
      "768/768 [==============================] - 0s 221us/step - loss: 4214.6721 - gain_tf: -0.0030 - val_loss: 3754.8582 - val_gain_tf: 0.0423\n",
      "Epoch 349/500\n",
      "768/768 [==============================] - 0s 275us/step - loss: 4208.1453 - gain_tf: -0.0027 - val_loss: 3748.9075 - val_gain_tf: 0.0428\n",
      "Epoch 350/500\n",
      "768/768 [==============================] - 0s 254us/step - loss: 4201.8730 - gain_tf: -0.0023 - val_loss: 3742.6617 - val_gain_tf: 0.0434\n",
      "Epoch 351/500\n",
      "768/768 [==============================] - 0s 218us/step - loss: 4195.4982 - gain_tf: -0.0020 - val_loss: 3736.4219 - val_gain_tf: 0.0439\n",
      "Epoch 352/500\n",
      "768/768 [==============================] - 0s 222us/step - loss: 4189.0495 - gain_tf: -0.0016 - val_loss: 3730.3621 - val_gain_tf: 0.0445\n",
      "Epoch 353/500\n",
      "768/768 [==============================] - 0s 250us/step - loss: 4182.7263 - gain_tf: -0.0013 - val_loss: 3724.2165 - val_gain_tf: 0.0450\n",
      "Epoch 354/500\n",
      "768/768 [==============================] - 0s 215us/step - loss: 4176.3760 - gain_tf: -9.3914e-04 - val_loss: 3718.0864 - val_gain_tf: 0.0455\n",
      "Epoch 355/500\n",
      "768/768 [==============================] - 0s 235us/step - loss: 4170.0368 - gain_tf: -5.8856e-04 - val_loss: 3711.9662 - val_gain_tf: 0.0461\n",
      "Epoch 356/500\n",
      "768/768 [==============================] - 0s 219us/step - loss: 4163.6812 - gain_tf: -2.6596e-04 - val_loss: 3705.9095 - val_gain_tf: 0.0466\n",
      "Epoch 357/500\n",
      "768/768 [==============================] - 0s 214us/step - loss: 4157.4393 - gain_tf: 1.0292e-04 - val_loss: 3699.6938 - val_gain_tf: 0.0472\n",
      "Epoch 358/500\n",
      "768/768 [==============================] - 0s 219us/step - loss: 4151.0460 - gain_tf: 4.4270e-04 - val_loss: 3693.6832 - val_gain_tf: 0.0477\n",
      "Epoch 359/500\n",
      "768/768 [==============================] - 0s 230us/step - loss: 4144.7276 - gain_tf: 7.5978e-04 - val_loss: 3687.7376 - val_gain_tf: 0.0482\n",
      "Epoch 360/500\n",
      "768/768 [==============================] - 0s 223us/step - loss: 4138.5223 - gain_tf: 0.0011 - val_loss: 3681.5996 - val_gain_tf: 0.0487\n",
      "Epoch 361/500\n",
      "768/768 [==============================] - 0s 257us/step - loss: 4132.2019 - gain_tf: 0.0015 - val_loss: 3675.5770 - val_gain_tf: 0.0493\n",
      "Epoch 362/500\n",
      "768/768 [==============================] - 0s 221us/step - loss: 4125.9553 - gain_tf: 0.0018 - val_loss: 3669.5248 - val_gain_tf: 0.0498\n",
      "Epoch 363/500\n",
      "768/768 [==============================] - 0s 221us/step - loss: 4119.6974 - gain_tf: 0.0022 - val_loss: 3663.4938 - val_gain_tf: 0.0503\n",
      "Epoch 364/500\n",
      "768/768 [==============================] - 0s 209us/step - loss: 4113.4512 - gain_tf: 0.0025 - val_loss: 3657.4773 - val_gain_tf: 0.0508\n",
      "Epoch 365/500\n",
      "768/768 [==============================] - 0s 227us/step - loss: 4107.2054 - gain_tf: 0.0028 - val_loss: 3651.5014 - val_gain_tf: 0.0514\n",
      "Epoch 366/500\n",
      "768/768 [==============================] - 0s 235us/step - loss: 4101.0297 - gain_tf: 0.0032 - val_loss: 3645.4355 - val_gain_tf: 0.0519\n",
      "Epoch 367/500\n",
      "768/768 [==============================] - 0s 266us/step - loss: 4094.7353 - gain_tf: 0.0035 - val_loss: 3639.5752 - val_gain_tf: 0.0524\n",
      "Epoch 368/500\n",
      "768/768 [==============================] - 0s 245us/step - loss: 4088.5895 - gain_tf: 0.0038 - val_loss: 3633.5895 - val_gain_tf: 0.0529\n",
      "Epoch 369/500\n",
      "768/768 [==============================] - 0s 237us/step - loss: 4082.4124 - gain_tf: 0.0042 - val_loss: 3627.5837 - val_gain_tf: 0.0535\n",
      "Epoch 370/500\n",
      "768/768 [==============================] - 0s 248us/step - loss: 4076.2037 - gain_tf: 0.0046 - val_loss: 3621.6573 - val_gain_tf: 0.0540\n",
      "Epoch 371/500\n",
      "768/768 [==============================] - 0s 193us/step - loss: 4070.0758 - gain_tf: 0.0049 - val_loss: 3615.6563 - val_gain_tf: 0.0545\n",
      "Epoch 372/500\n",
      "768/768 [==============================] - 0s 234us/step - loss: 4063.8553 - gain_tf: 0.0052 - val_loss: 3609.8086 - val_gain_tf: 0.0550\n",
      "Epoch 373/500\n",
      "768/768 [==============================] - 0s 220us/step - loss: 4057.7369 - gain_tf: 0.0056 - val_loss: 3603.8920 - val_gain_tf: 0.0555\n",
      "Epoch 374/500\n",
      "768/768 [==============================] - 0s 255us/step - loss: 4051.6336 - gain_tf: 0.0059 - val_loss: 3597.9142 - val_gain_tf: 0.0560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375/500\n",
      "768/768 [==============================] - 0s 209us/step - loss: 4045.4687 - gain_tf: 0.0062 - val_loss: 3592.0339 - val_gain_tf: 0.0566\n",
      "Epoch 376/500\n",
      "768/768 [==============================] - 0s 251us/step - loss: 4039.3414 - gain_tf: 0.0066 - val_loss: 3586.1966 - val_gain_tf: 0.0571\n",
      "Epoch 377/500\n",
      "768/768 [==============================] - 0s 219us/step - loss: 4033.2293 - gain_tf: 0.0069 - val_loss: 3580.3891 - val_gain_tf: 0.0576\n",
      "Epoch 378/500\n",
      "768/768 [==============================] - 0s 201us/step - loss: 4027.1890 - gain_tf: 0.0073 - val_loss: 3574.4634 - val_gain_tf: 0.0581\n",
      "Epoch 379/500\n",
      "768/768 [==============================] - 0s 205us/step - loss: 4021.0850 - gain_tf: 0.0076 - val_loss: 3568.5989 - val_gain_tf: 0.0586\n",
      "Epoch 380/500\n",
      "768/768 [==============================] - 0s 204us/step - loss: 4015.0215 - gain_tf: 0.0079 - val_loss: 3562.7271 - val_gain_tf: 0.0591\n",
      "Epoch 381/500\n",
      "768/768 [==============================] - 0s 212us/step - loss: 4008.9537 - gain_tf: 0.0082 - val_loss: 3556.8874 - val_gain_tf: 0.0596\n",
      "Epoch 382/500\n",
      "768/768 [==============================] - 0s 190us/step - loss: 4002.9103 - gain_tf: 0.0086 - val_loss: 3551.0438 - val_gain_tf: 0.0601\n",
      "Epoch 383/500\n",
      "768/768 [==============================] - 0s 181us/step - loss: 3996.8073 - gain_tf: 0.0089 - val_loss: 3545.3578 - val_gain_tf: 0.0606\n",
      "Epoch 384/500\n",
      "768/768 [==============================] - 0s 185us/step - loss: 3990.8716 - gain_tf: 0.0092 - val_loss: 3539.4700 - val_gain_tf: 0.0611\n",
      "Epoch 385/500\n",
      "768/768 [==============================] - 0s 196us/step - loss: 3984.7874 - gain_tf: 0.0096 - val_loss: 3533.7441 - val_gain_tf: 0.0616\n",
      "Epoch 386/500\n",
      "768/768 [==============================] - 0s 192us/step - loss: 3978.7985 - gain_tf: 0.0099 - val_loss: 3527.9858 - val_gain_tf: 0.0621\n",
      "Epoch 387/500\n",
      "768/768 [==============================] - 0s 217us/step - loss: 3972.8144 - gain_tf: 0.0102 - val_loss: 3522.2088 - val_gain_tf: 0.0626\n",
      "Epoch 388/500\n",
      "768/768 [==============================] - 0s 166us/step - loss: 3966.8066 - gain_tf: 0.0106 - val_loss: 3516.4959 - val_gain_tf: 0.0631\n",
      "Epoch 389/500\n",
      "768/768 [==============================] - 0s 170us/step - loss: 3960.8890 - gain_tf: 0.0109 - val_loss: 3510.6632 - val_gain_tf: 0.0636\n",
      "Epoch 390/500\n",
      "768/768 [==============================] - 0s 206us/step - loss: 3954.8990 - gain_tf: 0.0112 - val_loss: 3504.9134 - val_gain_tf: 0.0641\n",
      "Epoch 391/500\n",
      "768/768 [==============================] - 0s 183us/step - loss: 3948.9247 - gain_tf: 0.0115 - val_loss: 3499.2290 - val_gain_tf: 0.0646\n",
      "Epoch 392/500\n",
      "768/768 [==============================] - 0s 220us/step - loss: 3942.9888 - gain_tf: 0.0119 - val_loss: 3493.5565 - val_gain_tf: 0.0651\n",
      "Epoch 393/500\n",
      "768/768 [==============================] - 0s 207us/step - loss: 3937.0506 - gain_tf: 0.0122 - val_loss: 3487.9153 - val_gain_tf: 0.0656\n",
      "Epoch 394/500\n",
      "768/768 [==============================] - 0s 209us/step - loss: 3931.1466 - gain_tf: 0.0125 - val_loss: 3482.2544 - val_gain_tf: 0.0661\n",
      "Epoch 395/500\n",
      "768/768 [==============================] - 0s 214us/step - loss: 3925.2386 - gain_tf: 0.0129 - val_loss: 3476.5964 - val_gain_tf: 0.0666\n",
      "Epoch 396/500\n",
      "768/768 [==============================] - 0s 225us/step - loss: 3919.3328 - gain_tf: 0.0132 - val_loss: 3470.9781 - val_gain_tf: 0.0671\n",
      "Epoch 397/500\n",
      "768/768 [==============================] - 0s 200us/step - loss: 3913.4963 - gain_tf: 0.0135 - val_loss: 3465.2413 - val_gain_tf: 0.0676\n",
      "Epoch 398/500\n",
      "768/768 [==============================] - 0s 193us/step - loss: 3907.5983 - gain_tf: 0.0138 - val_loss: 3459.5778 - val_gain_tf: 0.0680\n",
      "Epoch 399/500\n",
      "768/768 [==============================] - 0s 215us/step - loss: 3901.7433 - gain_tf: 0.0142 - val_loss: 3453.9005 - val_gain_tf: 0.0685\n",
      "Epoch 400/500\n",
      "768/768 [==============================] - 0s 193us/step - loss: 3895.8416 - gain_tf: 0.0145 - val_loss: 3448.3463 - val_gain_tf: 0.0690\n",
      "Epoch 401/500\n",
      "768/768 [==============================] - 0s 192us/step - loss: 3890.0514 - gain_tf: 0.0148 - val_loss: 3442.6867 - val_gain_tf: 0.0695\n",
      "Epoch 402/500\n",
      "768/768 [==============================] - 0s 158us/step - loss: 3884.1624 - gain_tf: 0.0152 - val_loss: 3437.1722 - val_gain_tf: 0.0700\n",
      "Epoch 403/500\n",
      "768/768 [==============================] - 0s 225us/step - loss: 3878.4072 - gain_tf: 0.0155 - val_loss: 3431.5100 - val_gain_tf: 0.0705\n",
      "Epoch 404/500\n",
      "768/768 [==============================] - 0s 189us/step - loss: 3872.5944 - gain_tf: 0.0158 - val_loss: 3425.8823 - val_gain_tf: 0.0709\n",
      "Epoch 405/500\n",
      "768/768 [==============================] - 0s 196us/step - loss: 3866.7675 - gain_tf: 0.0162 - val_loss: 3420.3336 - val_gain_tf: 0.0714\n",
      "Epoch 406/500\n",
      "768/768 [==============================] - 0s 213us/step - loss: 3860.9834 - gain_tf: 0.0164 - val_loss: 3414.7933 - val_gain_tf: 0.0719\n",
      "Epoch 407/500\n",
      "768/768 [==============================] - 0s 174us/step - loss: 3855.1690 - gain_tf: 0.0168 - val_loss: 3409.3521 - val_gain_tf: 0.0724\n",
      "Epoch 408/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 3849.4984 - gain_tf: 0.0171 - val_loss: 3403.7131 - val_gain_tf: 0.0729\n",
      "Epoch 409/500\n",
      "768/768 [==============================] - 0s 273us/step - loss: 3843.6593 - gain_tf: 0.0174 - val_loss: 3398.2793 - val_gain_tf: 0.0733\n",
      "Epoch 410/500\n",
      "768/768 [==============================] - 0s 167us/step - loss: 3837.9117 - gain_tf: 0.0177 - val_loss: 3392.8620 - val_gain_tf: 0.0738\n",
      "Epoch 411/500\n",
      "768/768 [==============================] - 0s 190us/step - loss: 3832.2754 - gain_tf: 0.0181 - val_loss: 3387.2324 - val_gain_tf: 0.0743\n",
      "Epoch 412/500\n",
      "768/768 [==============================] - 0s 175us/step - loss: 3826.4457 - gain_tf: 0.0184 - val_loss: 3381.8659 - val_gain_tf: 0.0747\n",
      "Epoch 413/500\n",
      "768/768 [==============================] - 0s 201us/step - loss: 3820.7982 - gain_tf: 0.0187 - val_loss: 3376.3564 - val_gain_tf: 0.0752\n",
      "Epoch 414/500\n",
      "768/768 [==============================] - 0s 184us/step - loss: 3815.1206 - gain_tf: 0.0190 - val_loss: 3370.8135 - val_gain_tf: 0.0757\n",
      "Epoch 415/500\n",
      "768/768 [==============================] - 0s 214us/step - loss: 3809.3828 - gain_tf: 0.0194 - val_loss: 3365.3963 - val_gain_tf: 0.0761\n",
      "Epoch 416/500\n",
      "768/768 [==============================] - 0s 198us/step - loss: 3803.7142 - gain_tf: 0.0197 - val_loss: 3359.9703 - val_gain_tf: 0.0766\n",
      "Epoch 417/500\n",
      "768/768 [==============================] - 0s 198us/step - loss: 3798.0460 - gain_tf: 0.0200 - val_loss: 3354.5507 - val_gain_tf: 0.0771\n",
      "Epoch 418/500\n",
      "768/768 [==============================] - 0s 206us/step - loss: 3792.4225 - gain_tf: 0.0203 - val_loss: 3349.0703 - val_gain_tf: 0.0775\n",
      "Epoch 419/500\n",
      "768/768 [==============================] - 0s 207us/step - loss: 3786.7687 - gain_tf: 0.0206 - val_loss: 3343.6249 - val_gain_tf: 0.0780\n",
      "Epoch 420/500\n",
      "768/768 [==============================] - 0s 160us/step - loss: 3781.0925 - gain_tf: 0.0209 - val_loss: 3338.2896 - val_gain_tf: 0.0785\n",
      "Epoch 421/500\n",
      "768/768 [==============================] - 0s 195us/step - loss: 3775.4710 - gain_tf: 0.0213 - val_loss: 3332.9540 - val_gain_tf: 0.0789\n",
      "Epoch 422/500\n",
      "768/768 [==============================] - 0s 209us/step - loss: 3769.8788 - gain_tf: 0.0216 - val_loss: 3327.5781 - val_gain_tf: 0.0794\n",
      "Epoch 423/500\n",
      "768/768 [==============================] - 0s 201us/step - loss: 3764.2521 - gain_tf: 0.0219 - val_loss: 3322.2626 - val_gain_tf: 0.0798\n",
      "Epoch 424/500\n",
      "768/768 [==============================] - 0s 215us/step - loss: 3758.7255 - gain_tf: 0.0222 - val_loss: 3316.8064 - val_gain_tf: 0.0803\n",
      "Epoch 425/500\n",
      "768/768 [==============================] - 0s 203us/step - loss: 3753.0892 - gain_tf: 0.0225 - val_loss: 3311.4860 - val_gain_tf: 0.0808\n",
      "Epoch 426/500\n",
      "768/768 [==============================] - 0s 238us/step - loss: 3747.5473 - gain_tf: 0.0228 - val_loss: 3306.1102 - val_gain_tf: 0.0812\n",
      "Epoch 427/500\n",
      "768/768 [==============================] - 0s 207us/step - loss: 3741.9757 - gain_tf: 0.0232 - val_loss: 3300.7725 - val_gain_tf: 0.0817\n",
      "Epoch 428/500\n",
      "768/768 [==============================] - 0s 158us/step - loss: 3736.3820 - gain_tf: 0.0235 - val_loss: 3295.5545 - val_gain_tf: 0.0821\n",
      "Epoch 429/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 207us/step - loss: 3730.9007 - gain_tf: 0.0238 - val_loss: 3290.2070 - val_gain_tf: 0.0826\n",
      "Epoch 430/500\n",
      "768/768 [==============================] - 0s 223us/step - loss: 3725.3520 - gain_tf: 0.0241 - val_loss: 3284.9292 - val_gain_tf: 0.0830\n",
      "Epoch 431/500\n",
      "768/768 [==============================] - 0s 210us/step - loss: 3719.8700 - gain_tf: 0.0244 - val_loss: 3279.5844 - val_gain_tf: 0.0835\n",
      "Epoch 432/500\n",
      "768/768 [==============================] - 0s 219us/step - loss: 3714.3089 - gain_tf: 0.0247 - val_loss: 3274.3719 - val_gain_tf: 0.0839\n",
      "Epoch 433/500\n",
      "768/768 [==============================] - 0s 191us/step - loss: 3708.8247 - gain_tf: 0.0251 - val_loss: 3269.1465 - val_gain_tf: 0.0844\n",
      "Epoch 434/500\n",
      "768/768 [==============================] - 0s 201us/step - loss: 3703.3824 - gain_tf: 0.0254 - val_loss: 3263.8296 - val_gain_tf: 0.0848\n",
      "Epoch 435/500\n",
      "768/768 [==============================] - 0s 204us/step - loss: 3697.8657 - gain_tf: 0.0257 - val_loss: 3258.6199 - val_gain_tf: 0.0853\n",
      "Epoch 436/500\n",
      "768/768 [==============================] - 0s 152us/step - loss: 3692.4091 - gain_tf: 0.0260 - val_loss: 3253.4015 - val_gain_tf: 0.0857\n",
      "Epoch 437/500\n",
      "768/768 [==============================] - 0s 172us/step - loss: 3687.0006 - gain_tf: 0.0263 - val_loss: 3248.1074 - val_gain_tf: 0.0862\n",
      "Epoch 438/500\n",
      "768/768 [==============================] - 0s 197us/step - loss: 3681.4683 - gain_tf: 0.0266 - val_loss: 3243.0160 - val_gain_tf: 0.0866\n",
      "Epoch 439/500\n",
      "768/768 [==============================] - 0s 209us/step - loss: 3676.0629 - gain_tf: 0.0269 - val_loss: 3237.8708 - val_gain_tf: 0.0870\n",
      "Epoch 440/500\n",
      "768/768 [==============================] - 0s 216us/step - loss: 3670.7118 - gain_tf: 0.0272 - val_loss: 3232.5794 - val_gain_tf: 0.0875\n",
      "Epoch 441/500\n",
      "768/768 [==============================] - 0s 203us/step - loss: 3665.2149 - gain_tf: 0.0276 - val_loss: 3227.4877 - val_gain_tf: 0.0879\n",
      "Epoch 442/500\n",
      "768/768 [==============================] - 0s 211us/step - loss: 3659.8225 - gain_tf: 0.0279 - val_loss: 3222.3795 - val_gain_tf: 0.0883\n",
      "Epoch 443/500\n",
      "768/768 [==============================] - 0s 206us/step - loss: 3654.4659 - gain_tf: 0.0282 - val_loss: 3217.2020 - val_gain_tf: 0.0888\n",
      "Epoch 444/500\n",
      "768/768 [==============================] - 0s 230us/step - loss: 3649.0947 - gain_tf: 0.0285 - val_loss: 3212.0078 - val_gain_tf: 0.0892\n",
      "Epoch 445/500\n",
      "768/768 [==============================] - 0s 202us/step - loss: 3643.7006 - gain_tf: 0.0288 - val_loss: 3206.8840 - val_gain_tf: 0.0897\n",
      "Epoch 446/500\n",
      "768/768 [==============================] - 0s 209us/step - loss: 3638.3518 - gain_tf: 0.0291 - val_loss: 3201.7499 - val_gain_tf: 0.0901\n",
      "Epoch 447/500\n",
      "768/768 [==============================] - 0s 196us/step - loss: 3633.0324 - gain_tf: 0.0294 - val_loss: 3196.5720 - val_gain_tf: 0.0905\n",
      "Epoch 448/500\n",
      "768/768 [==============================] - 0s 212us/step - loss: 3627.6546 - gain_tf: 0.0297 - val_loss: 3191.5063 - val_gain_tf: 0.0910\n",
      "Epoch 449/500\n",
      "768/768 [==============================] - 0s 216us/step - loss: 3622.3174 - gain_tf: 0.0300 - val_loss: 3186.4741 - val_gain_tf: 0.0914\n",
      "Epoch 450/500\n",
      "768/768 [==============================] - 0s 215us/step - loss: 3616.9994 - gain_tf: 0.0304 - val_loss: 3181.4655 - val_gain_tf: 0.0918\n",
      "Epoch 451/500\n",
      "768/768 [==============================] - 0s 224us/step - loss: 3611.7683 - gain_tf: 0.0306 - val_loss: 3176.3042 - val_gain_tf: 0.0922\n",
      "Epoch 452/500\n",
      "768/768 [==============================] - 0s 198us/step - loss: 3606.3672 - gain_tf: 0.0310 - val_loss: 3171.4007 - val_gain_tf: 0.0927\n",
      "Epoch 453/500\n",
      "768/768 [==============================] - 0s 163us/step - loss: 3601.1855 - gain_tf: 0.0313 - val_loss: 3166.2725 - val_gain_tf: 0.0931\n",
      "Epoch 454/500\n",
      "768/768 [==============================] - 0s 199us/step - loss: 3595.8434 - gain_tf: 0.0316 - val_loss: 3161.3160 - val_gain_tf: 0.0935\n",
      "Epoch 455/500\n",
      "768/768 [==============================] - 0s 201us/step - loss: 3590.6367 - gain_tf: 0.0319 - val_loss: 3156.2377 - val_gain_tf: 0.0939\n",
      "Epoch 456/500\n",
      "768/768 [==============================] - 0s 194us/step - loss: 3585.3811 - gain_tf: 0.0322 - val_loss: 3151.1879 - val_gain_tf: 0.0944\n",
      "Epoch 457/500\n",
      "768/768 [==============================] - 0s 233us/step - loss: 3580.1204 - gain_tf: 0.0325 - val_loss: 3146.1978 - val_gain_tf: 0.0948\n",
      "Epoch 458/500\n",
      "768/768 [==============================] - 0s 162us/step - loss: 3574.9025 - gain_tf: 0.0328 - val_loss: 3141.1998 - val_gain_tf: 0.0952\n",
      "Epoch 459/500\n",
      "768/768 [==============================] - 0s 218us/step - loss: 3569.7099 - gain_tf: 0.0331 - val_loss: 3136.1699 - val_gain_tf: 0.0956\n",
      "Epoch 460/500\n",
      "768/768 [==============================] - 0s 161us/step - loss: 3564.4383 - gain_tf: 0.0334 - val_loss: 3131.2895 - val_gain_tf: 0.0960\n",
      "Epoch 461/500\n",
      "768/768 [==============================] - 0s 220us/step - loss: 3559.2693 - gain_tf: 0.0337 - val_loss: 3126.3598 - val_gain_tf: 0.0965\n",
      "Epoch 462/500\n",
      "768/768 [==============================] - 0s 207us/step - loss: 3554.1653 - gain_tf: 0.0340 - val_loss: 3121.2665 - val_gain_tf: 0.0969\n",
      "Epoch 463/500\n",
      "768/768 [==============================] - 0s 220us/step - loss: 3548.8519 - gain_tf: 0.0343 - val_loss: 3116.4907 - val_gain_tf: 0.0973\n",
      "Epoch 464/500\n",
      "768/768 [==============================] - 0s 202us/step - loss: 3543.7499 - gain_tf: 0.0346 - val_loss: 3111.5674 - val_gain_tf: 0.0977\n",
      "Epoch 465/500\n",
      "768/768 [==============================] - 0s 172us/step - loss: 3538.5709 - gain_tf: 0.0349 - val_loss: 3106.7029 - val_gain_tf: 0.0981\n",
      "Epoch 466/500\n",
      "768/768 [==============================] - 0s 192us/step - loss: 3533.4279 - gain_tf: 0.0352 - val_loss: 3101.8367 - val_gain_tf: 0.0985\n",
      "Epoch 467/500\n",
      "768/768 [==============================] - 0s 205us/step - loss: 3528.3438 - gain_tf: 0.0356 - val_loss: 3096.8526 - val_gain_tf: 0.0989\n",
      "Epoch 468/500\n",
      "768/768 [==============================] - 0s 228us/step - loss: 3523.1959 - gain_tf: 0.0358 - val_loss: 3091.9340 - val_gain_tf: 0.0993\n",
      "Epoch 469/500\n",
      "768/768 [==============================] - 0s 219us/step - loss: 3518.0187 - gain_tf: 0.0361 - val_loss: 3087.1667 - val_gain_tf: 0.0997\n",
      "Epoch 470/500\n",
      "768/768 [==============================] - 0s 192us/step - loss: 3513.0134 - gain_tf: 0.0364 - val_loss: 3082.1847 - val_gain_tf: 0.1002\n",
      "Epoch 471/500\n",
      "768/768 [==============================] - 0s 240us/step - loss: 3507.8489 - gain_tf: 0.0367 - val_loss: 3077.3680 - val_gain_tf: 0.1006\n",
      "Epoch 472/500\n",
      "768/768 [==============================] - 0s 225us/step - loss: 3502.8053 - gain_tf: 0.0371 - val_loss: 3072.4720 - val_gain_tf: 0.1010\n",
      "Epoch 473/500\n",
      "768/768 [==============================] - 0s 187us/step - loss: 3497.6889 - gain_tf: 0.0373 - val_loss: 3067.6899 - val_gain_tf: 0.1014\n",
      "Epoch 474/500\n",
      "768/768 [==============================] - 0s 198us/step - loss: 3492.6306 - gain_tf: 0.0377 - val_loss: 3062.9067 - val_gain_tf: 0.1018\n",
      "Epoch 475/500\n",
      "768/768 [==============================] - 0s 223us/step - loss: 3487.6061 - gain_tf: 0.0380 - val_loss: 3058.0722 - val_gain_tf: 0.1022\n",
      "Epoch 476/500\n",
      "768/768 [==============================] - 0s 196us/step - loss: 3482.5286 - gain_tf: 0.0383 - val_loss: 3053.3409 - val_gain_tf: 0.1026\n",
      "Epoch 477/500\n",
      "768/768 [==============================] - 0s 193us/step - loss: 3477.5568 - gain_tf: 0.0385 - val_loss: 3048.4790 - val_gain_tf: 0.1030\n",
      "Epoch 478/500\n",
      "768/768 [==============================] - 0s 211us/step - loss: 3472.5257 - gain_tf: 0.0388 - val_loss: 3043.6644 - val_gain_tf: 0.1034\n",
      "Epoch 479/500\n",
      "768/768 [==============================] - 0s 209us/step - loss: 3467.4522 - gain_tf: 0.0391 - val_loss: 3039.0148 - val_gain_tf: 0.1037\n",
      "Epoch 480/500\n",
      "768/768 [==============================] - 0s 185us/step - loss: 3462.4936 - gain_tf: 0.0394 - val_loss: 3034.2794 - val_gain_tf: 0.1041\n",
      "Epoch 481/500\n",
      "768/768 [==============================] - 0s 241us/step - loss: 3457.5605 - gain_tf: 0.0397 - val_loss: 3029.4380 - val_gain_tf: 0.1045\n",
      "Epoch 482/500\n",
      "768/768 [==============================] - 0s 216us/step - loss: 3452.5019 - gain_tf: 0.0400 - val_loss: 3024.8046 - val_gain_tf: 0.1049\n",
      "Epoch 483/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 202us/step - loss: 3447.6038 - gain_tf: 0.0403 - val_loss: 3020.0201 - val_gain_tf: 0.1053\n",
      "Epoch 484/500\n",
      "768/768 [==============================] - 0s 215us/step - loss: 3442.6628 - gain_tf: 0.0406 - val_loss: 3015.2310 - val_gain_tf: 0.1057\n",
      "Epoch 485/500\n",
      "768/768 [==============================] - 0s 209us/step - loss: 3437.6633 - gain_tf: 0.0409 - val_loss: 3010.5814 - val_gain_tf: 0.1061\n",
      "Epoch 486/500\n",
      "768/768 [==============================] - 0s 175us/step - loss: 3432.7406 - gain_tf: 0.0412 - val_loss: 3005.9216 - val_gain_tf: 0.1065\n",
      "Epoch 487/500\n",
      "768/768 [==============================] - 0s 210us/step - loss: 3427.8450 - gain_tf: 0.0415 - val_loss: 3001.2154 - val_gain_tf: 0.1069\n",
      "Epoch 488/500\n",
      "768/768 [==============================] - 0s 194us/step - loss: 3422.8951 - gain_tf: 0.0418 - val_loss: 2996.6100 - val_gain_tf: 0.1073\n",
      "Epoch 489/500\n",
      "768/768 [==============================] - 0s 233us/step - loss: 3418.0019 - gain_tf: 0.0421 - val_loss: 2991.9973 - val_gain_tf: 0.1076\n",
      "Epoch 490/500\n",
      "768/768 [==============================] - 0s 163us/step - loss: 3413.1412 - gain_tf: 0.0424 - val_loss: 2987.3217 - val_gain_tf: 0.1080\n",
      "Epoch 491/500\n",
      "768/768 [==============================] - 0s 224us/step - loss: 3408.2288 - gain_tf: 0.0427 - val_loss: 2982.7285 - val_gain_tf: 0.1084\n",
      "Epoch 492/500\n",
      "768/768 [==============================] - 0s 204us/step - loss: 3403.4439 - gain_tf: 0.0429 - val_loss: 2977.9635 - val_gain_tf: 0.1088\n",
      "Epoch 493/500\n",
      "768/768 [==============================] - 0s 220us/step - loss: 3398.5095 - gain_tf: 0.0433 - val_loss: 2973.3712 - val_gain_tf: 0.1092\n",
      "Epoch 494/500\n",
      "768/768 [==============================] - 0s 191us/step - loss: 3393.6575 - gain_tf: 0.0436 - val_loss: 2968.7946 - val_gain_tf: 0.1096\n",
      "Epoch 495/500\n",
      "768/768 [==============================] - 0s 171us/step - loss: 3388.8332 - gain_tf: 0.0439 - val_loss: 2964.1992 - val_gain_tf: 0.1099\n",
      "Epoch 496/500\n",
      "768/768 [==============================] - 0s 197us/step - loss: 3383.9429 - gain_tf: 0.0441 - val_loss: 2959.7505 - val_gain_tf: 0.1103\n",
      "Epoch 497/500\n",
      "768/768 [==============================] - 0s 220us/step - loss: 3379.2173 - gain_tf: 0.0444 - val_loss: 2955.0870 - val_gain_tf: 0.1107\n",
      "Epoch 498/500\n",
      "768/768 [==============================] - 0s 211us/step - loss: 3374.3427 - gain_tf: 0.0447 - val_loss: 2950.5897 - val_gain_tf: 0.1111\n",
      "Epoch 499/500\n",
      "768/768 [==============================] - 0s 197us/step - loss: 3369.5698 - gain_tf: 0.0450 - val_loss: 2946.0272 - val_gain_tf: 0.1114\n",
      "Epoch 500/500\n",
      "768/768 [==============================] - 0s 208us/step - loss: 3364.7853 - gain_tf: 0.0453 - val_loss: 2941.4615 - val_gain_tf: 0.1118\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import L1L2\n",
    "\n",
    "reg = L1L2(l1=0.01, l2=0.01)\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='relu', input_dim=x.shape[1]),)# W_regularizer=reg,)\n",
    "model.compile(optimizer='adam', loss=loss2_tf, metrics=[gain_tf])\n",
    "xTrain_a, yTrain_a = DACombine().fit_predict(xTrain, yTrain, size=1024)\n",
    "history = model.fit(xTrain_a, yTrain_a, nb_epoch=500, validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred = model.predict(xTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 66., 119.,  58., 115., 165.,  74., 118.,  83.,  68.,  84., 164.,\n",
       "       200.,  26., 110., 113.,  67.,  85., 109.,  88.,  89.,  75.,  61.,\n",
       "        50.,  63.,  40., 111.,  41., 100.,  94.,  96.,  41.,  68.,  80.,\n",
       "       103.,  31.,  95.,  83.,  66., 111.,  88.,  79., 102.,  74., 116.,\n",
       "        77., 106.,  87., 103., 115.,  87.,  93., 108., 117., 113.,  67.,\n",
       "        21.,  65., 143., 117.,  62., 126.,  81., 136., 113., 106.,  94.,\n",
       "        67., 100.,  60.,  60., 119.,   0., 108.,  78., 111.,  60., 116.,\n",
       "       116.,  86.,  81., 103.,  96., 104., 107.,  79.,  77., 115.,  90.,\n",
       "        61.,  65., 111.,  89.,  63., 107., 109., 114.,  21.,  98., 100.,\n",
       "       103.,  78., 174., 106., 112., 111., 105., 116., 116., 116.,  88.,\n",
       "       110.,  75.,  83.,  52.,  54.,  80., 101.,  79., 124.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, yy = DACombine().retarget(xTrain, yTrain.ravel(), 20)\n",
    "#yy - yTrain.ravel()\n",
    "yy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
