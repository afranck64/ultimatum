{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sb\n",
    "import imblearn\n",
    "\n",
    "# Read and sanitize the data\n",
    "df = pd.read_excel(\"../data/UG_HH_NEW_continuous_no200.xls\")\n",
    "#df = pd.read_excel(\"./UG_HH_NEW_categorical_no200.xls\")\n",
    "df = df.dropna()\n",
    "\n",
    "df_effort = df[['time_spent_prop', 'count_effort']]\n",
    "df_effort = (df_effort - df_effort.min()) / (df_effort.max() - df_effort.min())\n",
    "\n",
    "df['effort'] = df_effort['time_spent_prop'] * df_effort['count_effort']\n",
    "df = df[['time_spent_risk', 'cells', 'selfish', 'effort',\n",
    "         'Honesty_Humility','Extraversion', 'Agreeableness', 'min_offer']]\n",
    "\n",
    "df = df[['effort', 'selfish','Honesty_Humility','Extraversion', 'Agreeableness', 'min_offer']]\n",
    "\n",
    "MAX_ACCEPTABLE_MIN_OFFER = 150\n",
    "df = df[df['min_offer'] <= MAX_ACCEPTABLE_MIN_OFFER]\n",
    "\n",
    "\n",
    "NORMALISE_DATA = True\n",
    "\n",
    "\n",
    "x = df.values[:, :-1]\n",
    "y = df.values[:, -1:]\n",
    "\n",
    "if NORMALISE_DATA:\n",
    "    x_min = x.min(axis=0)\n",
    "    x_max = x.max(axis=0)\n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    \n",
    "NB_FEATURES = x.shape[1]\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 1/3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (continuous dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy / Loss - For model comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.metrics import avg_loss, avg_loss_ratio, avg_win_loss, loss_sum, mse, rejection_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_functions = [avg_loss, mse, rejection_ratio, avg_win_loss, avg_loss_ratio, loss_sum]\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def process_model(model, xTrain, yTrain, xTest, yTest, fit_kwargs=None, predict_kwargs=None):\n",
    "    fit_kwargs = {} if fit_kwargs is None else fit_kwargs\n",
    "    predict_kwargs = {} if predict_kwargs is None else predict_kwargs\n",
    "    model.fit(xTrain, yTrain, **fit_kwargs)\n",
    "    yPredict = model.predict(xTest, **predict_kwargs)\n",
    "    results = {func.__name__: func(yTest, yPredict) for func in benchmark_functions}\n",
    "    return results\n",
    "    \n",
    "def process_benchmark_cv(model, X, y, cv=5, metrics=None, fit_kwargs=None, predict_kwargs=None, augment_kwargs=None):\n",
    "    # We make sure original values aren't modified, even by mistake\n",
    "    X = np.copy(X)\n",
    "    y = np.copy(y)\n",
    "    \n",
    "    kf = KFold(n_splits=cv)\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        xTrain, yTrain = X[train_index], y[train_index]\n",
    "        if augment_kwargs:\n",
    "            xTrain, yTrain = DACombine().fit_predict(xTrain, yTrain, **augment_kwargs)\n",
    "        xTest, yTest = X[test_index], y[test_index]\n",
    "        benchmark_result = process_model(model, xTrain, yTrain, xTest, yTest, fit_kwargs, predict_kwargs)\n",
    "        results.append(benchmark_result)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Data augmentation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_augmentation import DACombine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #keras\n",
    "# import math\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import multiply\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# import keras.backend as K\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# import tensorflow as tf\n",
    "# import sys\n",
    "\n",
    "\n",
    "# def sigmoid1024_tf(x):\n",
    "#     return (1024**x) / (1024**x + 1)\n",
    "\n",
    "# def sigmoid_tf(x):\n",
    "#     return K.sigmoid(x)\n",
    "\n",
    "# def gain_tf(y_true, y_pred):\n",
    "#     math_pi = tf.constant(math.pi)\n",
    "#     one = tf.constant(1.0)\n",
    "#     ten = tf.constant(10.0)\n",
    "#     x = tf.math.subtract(y_true, y_pred)\n",
    "#     x = tf.math.truediv(x, ten)\n",
    "#     left_mul = sigmoid_tf(x)\n",
    "#     right_mul = tf.math.cos(tf.math.divide(x, math_pi))\n",
    "#     return tf.math.multiply(left_mul, right_mul)\n",
    "\n",
    "\n",
    "# def loss_tf(y_true, y_pred):\n",
    "#     math_pi = tf.constant(math.pi)\n",
    "#     one = tf.constant(1.0)\n",
    "#     ten = tf.constant(10.0)\n",
    "#     x0 = tf.math.subtract(y_true, y_pred)\n",
    "#     x = tf.math.truediv(x0, ten)\n",
    "#     left_mul = sigmoid_tf(x)\n",
    "#     right_mul = tf.math.cos(tf.math.divide(x, math_pi))\n",
    "#     return tf.math.subtract(one*2, tf.math.multiply(left_mul, right_mul))\n",
    "\n",
    "# def _keras_model(loss=None, metrics=None):\n",
    "#     \"\"\"\n",
    "#     build a simple regression model\n",
    "#     :param loss: (str|callable, default: loss_tf)\n",
    "#     \"\"\"\n",
    "#     if loss is None:\n",
    "#         loss = loss_tf\n",
    "#     if metrics is None:\n",
    "#         metrics = [\"mse\"]\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(8, input_dim=NB_FEATURES, kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(Dense(8, activation=\"relu\"))\n",
    "#     model.add(Dense(8, activation=\"relu\"))\n",
    "#     model.add(Dense(1, kernel_initializer='normal'))\n",
    "#     model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
    "#     return model\n",
    "\n",
    "# def _keras_linear_regression(loss=None, metrics=None):\n",
    "#     if loss is None:\n",
    "#         loss = \"mse\"\n",
    "#     if metrics is None:\n",
    "#         metrics = [\"mse\"]\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(1, input_dim=NB_FEATURES, kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(Dense(1, kernel_initializer='normal'))\n",
    "#     model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
    "#     return model\n",
    "\n",
    "# def keras_linear_regression(loss=None, metrics=None, nb_epoch=100, batch_size=32, verbose=False):\n",
    "#     build_fn = lambda : _keras_linear_regression(loss, metrics)\n",
    "#     return KerasRegressor(build_fn=build_fn, epochs=nb_epoch, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "# def keras_model(loss=None, metrics=None, nb_epoch=100, batch_size=32, verbose=False):\n",
    "#     build_fn = lambda : _keras_model(loss, metrics)\n",
    "#     return KerasRegressor(build_fn=build_fn, epochs=nb_epoch, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log_regression_base</th>\n",
       "      <td>27.017460</td>\n",
       "      <td>0.214933</td>\n",
       "      <td>23.401070</td>\n",
       "      <td>962.0</td>\n",
       "      <td>1550.428571</td>\n",
       "      <td>0.067302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_retarget</th>\n",
       "      <td>36.496825</td>\n",
       "      <td>0.292325</td>\n",
       "      <td>33.400688</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>2137.063492</td>\n",
       "      <td>0.067143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_x16</th>\n",
       "      <td>80.688889</td>\n",
       "      <td>0.689162</td>\n",
       "      <td>39.660516</td>\n",
       "      <td>2872.0</td>\n",
       "      <td>8719.285714</td>\n",
       "      <td>0.561746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_x16-up</th>\n",
       "      <td>85.338095</td>\n",
       "      <td>0.727573</td>\n",
       "      <td>37.340909</td>\n",
       "      <td>3037.0</td>\n",
       "      <td>9449.452381</td>\n",
       "      <td>0.623651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_x16_combine</th>\n",
       "      <td>36.496825</td>\n",
       "      <td>0.292325</td>\n",
       "      <td>33.400688</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>2137.063492</td>\n",
       "      <td>0.067143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_x16_dist</th>\n",
       "      <td>39.296825</td>\n",
       "      <td>0.330512</td>\n",
       "      <td>22.103498</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>3256.650794</td>\n",
       "      <td>0.213651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_base</th>\n",
       "      <td>27.001587</td>\n",
       "      <td>0.213637</td>\n",
       "      <td>24.000891</td>\n",
       "      <td>962.0</td>\n",
       "      <td>1517.492063</td>\n",
       "      <td>0.061587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_retarget</th>\n",
       "      <td>34.871429</td>\n",
       "      <td>0.276041</td>\n",
       "      <td>33.447645</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1915.333333</td>\n",
       "      <td>0.044762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_x16</th>\n",
       "      <td>82.511111</td>\n",
       "      <td>0.700871</td>\n",
       "      <td>44.128409</td>\n",
       "      <td>2937.0</td>\n",
       "      <td>8861.960317</td>\n",
       "      <td>0.556032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_x16-up</th>\n",
       "      <td>82.026190</td>\n",
       "      <td>0.693758</td>\n",
       "      <td>42.727326</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>8961.710317</td>\n",
       "      <td>0.560635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_x16_combine</th>\n",
       "      <td>34.871429</td>\n",
       "      <td>0.276041</td>\n",
       "      <td>33.447645</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1915.333333</td>\n",
       "      <td>0.044762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_x16_dist</th>\n",
       "      <td>31.517460</td>\n",
       "      <td>0.257050</td>\n",
       "      <td>23.477141</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>2152.968254</td>\n",
       "      <td>0.118095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             avg_loss  avg_loss_ratio  avg_win_loss  loss_sum  \\\n",
       "log_regression_base         27.017460        0.214933     23.401070     962.0   \n",
       "log_regression_retarget     36.496825        0.292325     33.400688    1300.0   \n",
       "log_regression_x16          80.688889        0.689162     39.660516    2872.0   \n",
       "log_regression_x16-up       85.338095        0.727573     37.340909    3037.0   \n",
       "log_regression_x16_combine  36.496825        0.292325     33.400688    1300.0   \n",
       "log_regression_x16_dist     39.296825        0.330512     22.103498    1398.0   \n",
       "svc_base                    27.001587        0.213637     24.000891     962.0   \n",
       "svc_retarget                34.871429        0.276041     33.447645    1242.0   \n",
       "svc_x16                     82.511111        0.700871     44.128409    2937.0   \n",
       "svc_x16-up                  82.026190        0.693758     42.727326    2923.0   \n",
       "svc_x16_combine             34.871429        0.276041     33.447645    1242.0   \n",
       "svc_x16_dist                31.517460        0.257050     23.477141    1122.0   \n",
       "\n",
       "                                    mse  rejection_ratio  \n",
       "log_regression_base         1550.428571         0.067302  \n",
       "log_regression_retarget     2137.063492         0.067143  \n",
       "log_regression_x16          8719.285714         0.561746  \n",
       "log_regression_x16-up       9449.452381         0.623651  \n",
       "log_regression_x16_combine  2137.063492         0.067143  \n",
       "log_regression_x16_dist     3256.650794         0.213651  \n",
       "svc_base                    1517.492063         0.061587  \n",
       "svc_retarget                1915.333333         0.044762  \n",
       "svc_x16                     8861.960317         0.556032  \n",
       "svc_x16-up                  8961.710317         0.560635  \n",
       "svc_x16_combine             1915.333333         0.044762  \n",
       "svc_x16_dist                2152.968254         0.118095  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression, PassiveAggressiveRegressor, \\\n",
    "                                 ElasticNet, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble.bagging import BaggingRegressor, DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "benchmark_models = {\n",
    "    #'linear_regression': LinearRegression(),\n",
    "    'svc': SVC(gamma='auto'),\n",
    "    'log_regression': LogisticRegression(penalty='l1', solver='liblinear', multi_class='auto'),\n",
    "}\n",
    "    \n",
    "augment_params = {\n",
    "    'base': {},\n",
    "    'retarget': {'retarget': True, 'distance': 10},\n",
    "#     'x2': {'size':len(xTrain)*2},\n",
    "#     'x2-up': {'size':len(xTrain)*2, 'upsample': True},\n",
    "#     'x2+xy': {'size':len(xTrain)*2, 'include_xy':True},\n",
    "#     'x4': {'size': len(xTrain)*4},\n",
    "#     'x4+xy-up': {'size': len(xTrain)*4, 'include_xy':True, 'upsample':True},\n",
    "    'x16': {'size': len(xTrain)*16},\n",
    "    'x16-up': {'size': len(xTrain)*16, 'upsample': True},\n",
    "    'x16_dist': {'size': len(xTrain)*16, 'distribution': True},\n",
    "    'x16_combine': {'size': len(xTrain)*16, 'retarget': True, 'distribution': True, 'upsample': True},\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for key, model in benchmark_models.items():\n",
    "    for aug_key, aug_params in augment_params.items():\n",
    "        results[key+\"_\" + aug_key] = process_benchmark_cv(model=model, X=x, y=y.ravel(), augment_kwargs=aug_params)\n",
    "\n",
    "results_mean = {key: item.mean() for key, item in results.items()}\n",
    "results_std = {key: item.std() for key, item in results.items()}\n",
    "pd.DataFrame(results_mean).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Actual best model:**\n",
    "- LogisticRegression (penalty='l1')\n",
    "\n",
    "** Data Augmentation improve following models:**\n",
    "- Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bag_base</th>\n",
       "      <td>69.827460</td>\n",
       "      <td>0.638250</td>\n",
       "      <td>25.492863</td>\n",
       "      <td>2484.400000</td>\n",
       "      <td>6733.068810</td>\n",
       "      <td>0.567778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_retarget</th>\n",
       "      <td>54.296032</td>\n",
       "      <td>0.494210</td>\n",
       "      <td>29.185635</td>\n",
       "      <td>1931.800000</td>\n",
       "      <td>4449.807778</td>\n",
       "      <td>0.371111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_x16</th>\n",
       "      <td>73.938071</td>\n",
       "      <td>0.667098</td>\n",
       "      <td>25.757054</td>\n",
       "      <td>2631.161181</td>\n",
       "      <td>7444.870623</td>\n",
       "      <td>0.601270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_x16-up</th>\n",
       "      <td>72.786860</td>\n",
       "      <td>0.656440</td>\n",
       "      <td>26.388152</td>\n",
       "      <td>2592.356125</td>\n",
       "      <td>7214.341737</td>\n",
       "      <td>0.583968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_x16_combine</th>\n",
       "      <td>57.571746</td>\n",
       "      <td>0.522713</td>\n",
       "      <td>27.098168</td>\n",
       "      <td>2048.600000</td>\n",
       "      <td>4991.937143</td>\n",
       "      <td>0.415873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag_x16_dist</th>\n",
       "      <td>65.237143</td>\n",
       "      <td>0.599816</td>\n",
       "      <td>27.772738</td>\n",
       "      <td>2323.400000</td>\n",
       "      <td>5981.488571</td>\n",
       "      <td>0.510952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_base</th>\n",
       "      <td>67.235492</td>\n",
       "      <td>0.620754</td>\n",
       "      <td>24.652825</td>\n",
       "      <td>2393.280000</td>\n",
       "      <td>6333.033479</td>\n",
       "      <td>0.550635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_retarget</th>\n",
       "      <td>55.908381</td>\n",
       "      <td>0.510751</td>\n",
       "      <td>27.811127</td>\n",
       "      <td>1990.440000</td>\n",
       "      <td>4712.607797</td>\n",
       "      <td>0.398889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_x16</th>\n",
       "      <td>75.590134</td>\n",
       "      <td>0.682251</td>\n",
       "      <td>26.299587</td>\n",
       "      <td>2690.776663</td>\n",
       "      <td>7642.162737</td>\n",
       "      <td>0.617937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_x16-up</th>\n",
       "      <td>68.276288</td>\n",
       "      <td>0.625286</td>\n",
       "      <td>24.172165</td>\n",
       "      <td>2431.321487</td>\n",
       "      <td>6592.166564</td>\n",
       "      <td>0.555873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_x16_combine</th>\n",
       "      <td>57.805302</td>\n",
       "      <td>0.531196</td>\n",
       "      <td>28.612505</td>\n",
       "      <td>2058.040000</td>\n",
       "      <td>4889.580451</td>\n",
       "      <td>0.421270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_x16_dist</th>\n",
       "      <td>70.305238</td>\n",
       "      <td>0.641228</td>\n",
       "      <td>28.046777</td>\n",
       "      <td>2503.080000</td>\n",
       "      <td>6698.584578</td>\n",
       "      <td>0.561746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     avg_loss  avg_loss_ratio  avg_win_loss     loss_sum  \\\n",
       "bag_base            69.827460        0.638250     25.492863  2484.400000   \n",
       "bag_retarget        54.296032        0.494210     29.185635  1931.800000   \n",
       "bag_x16             73.938071        0.667098     25.757054  2631.161181   \n",
       "bag_x16-up          72.786860        0.656440     26.388152  2592.356125   \n",
       "bag_x16_combine     57.571746        0.522713     27.098168  2048.600000   \n",
       "bag_x16_dist        65.237143        0.599816     27.772738  2323.400000   \n",
       "forest_base         67.235492        0.620754     24.652825  2393.280000   \n",
       "forest_retarget     55.908381        0.510751     27.811127  1990.440000   \n",
       "forest_x16          75.590134        0.682251     26.299587  2690.776663   \n",
       "forest_x16-up       68.276288        0.625286     24.172165  2431.321487   \n",
       "forest_x16_combine  57.805302        0.531196     28.612505  2058.040000   \n",
       "forest_x16_dist     70.305238        0.641228     28.046777  2503.080000   \n",
       "\n",
       "                            mse  rejection_ratio  \n",
       "bag_base            6733.068810         0.567778  \n",
       "bag_retarget        4449.807778         0.371111  \n",
       "bag_x16             7444.870623         0.601270  \n",
       "bag_x16-up          7214.341737         0.583968  \n",
       "bag_x16_combine     4991.937143         0.415873  \n",
       "bag_x16_dist        5981.488571         0.510952  \n",
       "forest_base         6333.033479         0.550635  \n",
       "forest_retarget     4712.607797         0.398889  \n",
       "forest_x16          7642.162737         0.617937  \n",
       "forest_x16-up       6592.166564         0.555873  \n",
       "forest_x16_combine  4889.580451         0.421270  \n",
       "forest_x16_dist     6698.584578         0.561746  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "benchmark_models = {\n",
    "    'bag': BaggingRegressor(),\n",
    "    'forest': RandomForestRegressor(n_estimators=50),\n",
    "    #keras_linear_regression(nb_epoch=100, batch_size=60),\n",
    "}\n",
    "    \n",
    "augment_params = {\n",
    "    'base': {},\n",
    "    'retarget': {'retarget': True, 'distance': 10},\n",
    "    'x16': {'size': len(xTrain)*16},\n",
    "    'x16-up': {'size': len(xTrain)*16, 'upsample': True},\n",
    "    'x16_dist': {'size': len(xTrain)*16, 'distribution': True},\n",
    "    'x16_combine': {'size': len(xTrain)*16, 'retarget': True, 'distribution': True},\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for key, model in benchmark_models.items():\n",
    "    for aug_key, aug_params in augment_params.items():\n",
    "        results[key+\"_\" + aug_key] = process_benchmark_cv(model=model, X=x, y=y.ravel(), augment_kwargs=aug_params)\n",
    "\n",
    "results_mean = {key: item.mean() for key, item in results.items()}\n",
    "results_std = {key: item.std() for key, item in results.items()}\n",
    "pd.DataFrame(results_mean).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.regularizers import L1L2\n",
    "\n",
    "# reg = L1L2(l1=0.01, l2=0.01)\n",
    "# model = Sequential()\n",
    "# model.add(Dense(1, activation='relu', input_dim=x.shape[1]),)# W_regularizer=reg,)\n",
    "# model.compile(optimizer='adam', loss=\"mse\", metrics=[\"mse\"])\n",
    "# xTrain_a, yTrain_a = DACombine().fit_predict(xTrain, yTrain, size=1024)\n",
    "# history = model.fit(xTrain_a, yTrain_a, nb_epoch=500, validation_split=0.25)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
