{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sb\n",
    "import imblearn\n",
    "\n",
    "# Read and sanitize the data\n",
    "df = pd.read_excel(\"../data/UG_HH_NEW_continuous_no200.xls\")\n",
    "#df = pd.read_excel(\"./UG_HH_NEW_categorical_no200.xls\")\n",
    "\n",
    "df_effort = df[['time_spent_prop', 'count_effort']]\n",
    "df_effort = (df_effort - df_effort.min()) / (df_effort.max() - df_effort.min())\n",
    "\n",
    "df['effort'] = df_effort['time_spent_prop'] * df_effort['count_effort']\n",
    "df = df[['time_spent_risk', 'cells', 'selfish', 'effort',\n",
    "         'Honesty_Humility','Extraversion', 'Agreeableness', 'min_offer']]\n",
    "\n",
    "df = df[['selfish','Honesty_Humility','Extraversion', 'Agreeableness', 'min_offer']]\n",
    "df = df.dropna()\n",
    "\n",
    "NORMALISE_DATA = True\n",
    "\n",
    "\n",
    "x = df.values[:, :-1]\n",
    "y = df.values[:, -1:]\n",
    "\n",
    "if NORMALISE_DATA:\n",
    "    x_min = x.min(axis=0)\n",
    "    x_max = x.max(axis=0)\n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    \n",
    "NB_FEATURES = x.shape[1]\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 1/3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (continuous dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy / Loss - For model comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GAIN = 200\n",
    "\n",
    "def loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute loss for the ultimatum game,\n",
    "    as the difference between the possible gain and the actual one\n",
    "    \"\"\"\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    rejected = min_offer > predicted\n",
    "    res = predicted - min_offer\n",
    "    if rejected.sum() != 0:\n",
    "        res[rejected] = MAX_GAIN - min_offer[rejected]\n",
    "    bad_predictions = (predicted < 0) | (predicted > MAX_GAIN)\n",
    "    if bad_predictions.sum() != 0:\n",
    "        res[bad_predictions] = MAX_GAIN - min_offer[bad_predictions]\n",
    "    return res\n",
    "\n",
    "def loss_sum(min_offer, predicted):\n",
    "    return loss(min_offer, predicted).sum()\n",
    "\n",
    "def avg_loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute avg loss for the ultimatum game\n",
    "    \"\"\"\n",
    "    return np.mean(loss(min_offer, predicted))\n",
    "\n",
    "def mse(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute mse using the loss as error\n",
    "    \"\"\"\n",
    "    return np.mean(np.square(loss(min_offer, predicted)))\n",
    "\n",
    "def rejection_ratio(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute ratio of rejected proposals without consideration of values\n",
    "    \"\"\"\n",
    "    accepted = (min_offer <= predicted)\n",
    "    return 1 - np.mean(accepted)\n",
    "\n",
    "def avg_win_loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute avg_loss of accepted proposals\n",
    "    \"\"\"\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    accepted = (min_offer <= predicted)\n",
    "    if accepted.sum() == 0:\n",
    "        return 0\n",
    "    return avg_loss(min_offer[accepted], predicted[accepted])\n",
    "\n",
    "\n",
    "def gain(min_offer, predicted):\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()    \n",
    "    res = MAX_GAIN - predicted\n",
    "    res[predicted < min_offer] = 0\n",
    "    return res\n",
    "\n",
    "def avg_loss_ratio(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute the avg gain ratio in relation to the maximal gain\n",
    "    \"\"\"\n",
    "    return 1 - np.mean(gain(min_offer, predicted) / gain(min_offer, min_offer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_functions = [avg_loss, mse, rejection_ratio, avg_win_loss, avg_loss_ratio, loss_sum]\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def process_model(model, xTrain, yTrain, xTest, yTest, fit_kwargs=None, predict_kwargs=None):\n",
    "    fit_kwargs = {} if fit_kwargs is None else fit_kwargs\n",
    "    predict_kwargs = {} if predict_kwargs is None else predict_kwargs\n",
    "    model.fit(xTrain, yTrain, **fit_kwargs)\n",
    "    yPredict = model.predict(xTest, **predict_kwargs)\n",
    "    results = {func.__name__: func(yTest, yPredict) for func in benchmark_functions}\n",
    "    return results\n",
    "    \n",
    "def process_benchmark_cv(model, X, y, cv=5, metrics=None, fit_kwargs=None, predict_kwargs=None, augment_kwargs=None):\n",
    "    # We make sure original values aren't modified, even by mistake\n",
    "    X = np.copy(X)\n",
    "    y = np.copy(y)\n",
    "    \n",
    "    kf = KFold(n_splits=cv)\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        xTrain, yTrain = X[train_index], y[train_index]\n",
    "        if augment_kwargs:\n",
    "            xTrain, yTrain = DACombine().fit_predict(xTrain, yTrain, **augment_kwargs)\n",
    "        xTest, yTest = X[test_index], y[test_index]\n",
    "        benchmark_result = process_model(model, xTrain, yTrain, xTest, yTest, fit_kwargs, predict_kwargs)\n",
    "        results.append(benchmark_result)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Data augmentation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DACombine(object):\n",
    "    def __init__(self, size=None, nb_features=NB_FEATURES, max_gain=MAX_GAIN):\n",
    "        self.size = size\n",
    "        self.nb_features = nb_features\n",
    "        self.max_gain = max_gain\n",
    "    \n",
    "    def fit_predict(self, xTrain, yTrain, size=None, distance=10, upsample=True, include_xy=False, retarget=False):\n",
    "        \"\"\"\n",
    "        :param size: (int) size of the new generated dataset\n",
    "        :param distance: (int) distance between parents or similar items\n",
    "        :param upsample: (bool) if True, try balance the dataset\n",
    "        :param include_xy: (bool) if True, include xTrain and yTrain to the data (on top of size items)\n",
    "        :param retarget: (bool) if True, set all targets to the nearest higher multiple of distance without generating new samples\n",
    "        \"\"\"\n",
    "        if retarget:\n",
    "            return self.retarget(xTrain, yTrain, distance)\n",
    "        size = size or self.size or len(xTrain) * 4\n",
    "        indices = np.arange(self.nb_features)\n",
    "        np.random.shuffle(indices)\n",
    "        targets = yTrain.ravel()\n",
    "        if upsample:\n",
    "            targets, counts = np.unique(yTrain, return_counts=True)\n",
    "            #NOTE: minimize selection of target with only one sample\n",
    "            probs = (1 - counts/counts.sum())**2\n",
    "            probs[counts==1] = probs.min()\n",
    "            probs /= probs.sum()\n",
    "        else:\n",
    "            targets = yTrain.ravel()\n",
    "            probs = None\n",
    "        xRes = []\n",
    "        yRes = []\n",
    "        if include_xy:\n",
    "            xRes.extend(xTrain)\n",
    "            yRes.extend(yTrain)\n",
    "        for _ in range(size):\n",
    "            target = np.random.choice(targets, p=probs)\n",
    "            target_mask = (yTrain.ravel()<target+distance) & (yTrain.ravel()>=(target))\n",
    "            xTrain_target = xTrain[target_mask]\n",
    "            i = np.random.randint(xTrain_target.shape[0])\n",
    "            j = np.random.randint(xTrain_target.shape[0])\n",
    "            x = np.zeros_like(xTrain_target[0])\n",
    "            np.random.shuffle(indices)\n",
    "            split = np.random.randint(self.nb_features)\n",
    "            mask_i = indices[:split]\n",
    "            mask_j = indices[split:]\n",
    "            x[mask_i] = xTrain_target[i, mask_i]\n",
    "            x[mask_j] = xTrain_target[j, mask_j]\n",
    "            xRes.append(x)\n",
    "            yRes.append(target)\n",
    "        return np.array(xRes), np.array(yRes)\n",
    "\n",
    "    def retarget(self, xTrain, yTrain, distance=10):\n",
    "        yNew = np.zeros(yTrain.shape[0])\n",
    "        for y in np.arange(self.max_gain, 0, -distance):\n",
    "            mask = (yTrain <= y) & (yTrain > y-distance)\n",
    "            yNew[mask] = y + distance\n",
    "        yNew = np.array(yNew)\n",
    "        yNew[yNew > self.max_gain] = self.max_gain\n",
    "        return xTrain, yNew\n",
    "\n",
    "    def fit_resample(self, xTrain, yTrain, size=None, distance=5, include_xy=True):\n",
    "        return self.fit_predict(xTrain, yTrain, size=size, distance=distance, include_xy=include_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import multiply\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "\n",
    "def sigmoid1024_tf(x):\n",
    "    return (1024**x) / (1024**x + 1)\n",
    "\n",
    "def sigmoid_tf(x):\n",
    "    return K.sigmoid(x)\n",
    "\n",
    "def gain_tf(y_true, y_pred):\n",
    "    math_pi = tf.constant(math.pi)\n",
    "    one = tf.constant(1.0)\n",
    "    ten = tf.constant(10.0)\n",
    "    x = tf.math.subtract(y_true, y_pred)\n",
    "    x = tf.math.truediv(x, ten)\n",
    "    left_mul = sigmoid_tf(x)\n",
    "    right_mul = tf.math.cos(tf.math.divide(x, math_pi))\n",
    "    return tf.math.multiply(left_mul, right_mul)\n",
    "\n",
    "\n",
    "def loss_tf(y_true, y_pred):\n",
    "    math_pi = tf.constant(math.pi)\n",
    "    one = tf.constant(1.0)\n",
    "    ten = tf.constant(10.0)\n",
    "    x0 = tf.math.subtract(y_true, y_pred)\n",
    "    x = tf.math.truediv(x0, ten)\n",
    "    left_mul = sigmoid_tf(x)\n",
    "    right_mul = tf.math.cos(tf.math.divide(x, math_pi))\n",
    "    return tf.math.subtract(one*2, tf.math.multiply(left_mul, right_mul))\n",
    "\n",
    "def _keras_model(loss=None, metrics=None):\n",
    "    \"\"\"\n",
    "    build a simple regression model\n",
    "    :param loss: (str|callable, default: loss_tf)\n",
    "    \"\"\"\n",
    "    if loss is None:\n",
    "        loss = loss_tf\n",
    "    if metrics is None:\n",
    "        metrics = [\"mse\"]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=NB_FEATURES, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def _keras_linear_regression(loss=None, metrics=None):\n",
    "    if loss is None:\n",
    "        loss = \"mse\"\n",
    "    if metrics is None:\n",
    "        metrics = [\"mse\"]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=NB_FEATURES, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def keras_linear_regression(loss=None, metrics=None, nb_epoch=100, batch_size=32, verbose=False):\n",
    "    build_fn = lambda : _keras_linear_regression(loss, metrics)\n",
    "    return KerasRegressor(build_fn=build_fn, epochs=nb_epoch, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "def keras_model(loss=None, metrics=None, nb_epoch=100, batch_size=32, verbose=False):\n",
    "    build_fn = lambda : _keras_model(loss, metrics)\n",
    "    return KerasRegressor(build_fn=build_fn, epochs=nb_epoch, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4,  5, 28, 13, 26, 38,  1,  3,  0,  1]),\n",
       " array([  0. ,  19.5,  39. ,  58.5,  78. ,  97.5, 117. , 136.5, 156. ,\n",
       "        175.5, 195. ]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imblearn\n",
    "import imblearn.over_sampling\n",
    "o_s = imblearn.over_sampling.RandomOverSampler()\n",
    "xTrain_a, yTrain_a = o_s.fit_resample(xTrain, yTrain.ravel(), )\n",
    "pd.DataFrame(xTrain).hist()\n",
    "pd.DataFrame(xTrain_a).hist()\n",
    "np.histogram(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_model2_base</th>\n",
       "      <td>26.913492</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>23.429033</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1543.257937</td>\n",
       "      <td>0.072540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model2_retarget</th>\n",
       "      <td>36.340476</td>\n",
       "      <td>0.296365</td>\n",
       "      <td>33.422078</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>2127.146825</td>\n",
       "      <td>0.072381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model2_x0.5</th>\n",
       "      <td>84.617460</td>\n",
       "      <td>0.737879</td>\n",
       "      <td>43.130749</td>\n",
       "      <td>3028.0</td>\n",
       "      <td>9159.571429</td>\n",
       "      <td>0.615079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model2_x0.5-up</th>\n",
       "      <td>75.934127</td>\n",
       "      <td>0.650801</td>\n",
       "      <td>50.541558</td>\n",
       "      <td>2712.0</td>\n",
       "      <td>7767.250000</td>\n",
       "      <td>0.426190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model2_x16</th>\n",
       "      <td>81.806349</td>\n",
       "      <td>0.711884</td>\n",
       "      <td>49.539825</td>\n",
       "      <td>2929.0</td>\n",
       "      <td>8704.404762</td>\n",
       "      <td>0.535873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model2_x2</th>\n",
       "      <td>82.365873</td>\n",
       "      <td>0.713664</td>\n",
       "      <td>50.362710</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>8780.059524</td>\n",
       "      <td>0.546984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model2_x2+xy</th>\n",
       "      <td>44.838095</td>\n",
       "      <td>0.379353</td>\n",
       "      <td>24.663884</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>4143.555556</td>\n",
       "      <td>0.251270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model2_x2-up</th>\n",
       "      <td>77.103175</td>\n",
       "      <td>0.680803</td>\n",
       "      <td>40.756089</td>\n",
       "      <td>2759.0</td>\n",
       "      <td>7920.682540</td>\n",
       "      <td>0.530476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model2_x4</th>\n",
       "      <td>83.088889</td>\n",
       "      <td>0.703676</td>\n",
       "      <td>50.606380</td>\n",
       "      <td>2972.0</td>\n",
       "      <td>9004.984127</td>\n",
       "      <td>0.503016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model2_x4+xy-up</th>\n",
       "      <td>62.719048</td>\n",
       "      <td>0.542197</td>\n",
       "      <td>33.616445</td>\n",
       "      <td>2246.0</td>\n",
       "      <td>6242.436508</td>\n",
       "      <td>0.384762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model_base</th>\n",
       "      <td>26.897619</td>\n",
       "      <td>0.218127</td>\n",
       "      <td>24.028855</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1510.321429</td>\n",
       "      <td>0.066825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model_retarget</th>\n",
       "      <td>34.715079</td>\n",
       "      <td>0.280082</td>\n",
       "      <td>33.469035</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>1905.416667</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model_x0.5</th>\n",
       "      <td>77.576190</td>\n",
       "      <td>0.667207</td>\n",
       "      <td>43.277579</td>\n",
       "      <td>2784.0</td>\n",
       "      <td>7705.134921</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model_x0.5-up</th>\n",
       "      <td>80.623016</td>\n",
       "      <td>0.717495</td>\n",
       "      <td>28.104762</td>\n",
       "      <td>2881.0</td>\n",
       "      <td>8427.543651</td>\n",
       "      <td>0.626984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model_x16</th>\n",
       "      <td>81.057143</td>\n",
       "      <td>0.700292</td>\n",
       "      <td>46.539683</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>8667.611111</td>\n",
       "      <td>0.524603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model_x2</th>\n",
       "      <td>88.079365</td>\n",
       "      <td>0.748108</td>\n",
       "      <td>47.175350</td>\n",
       "      <td>3149.0</td>\n",
       "      <td>9563.396825</td>\n",
       "      <td>0.582698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model_x2+xy</th>\n",
       "      <td>33.342063</td>\n",
       "      <td>0.280759</td>\n",
       "      <td>21.626355</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>2499.765873</td>\n",
       "      <td>0.155714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model_x2-up</th>\n",
       "      <td>75.105556</td>\n",
       "      <td>0.651409</td>\n",
       "      <td>49.157998</td>\n",
       "      <td>2690.0</td>\n",
       "      <td>7319.297619</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model_x4</th>\n",
       "      <td>74.356349</td>\n",
       "      <td>0.643202</td>\n",
       "      <td>37.770553</td>\n",
       "      <td>2662.0</td>\n",
       "      <td>7658.456349</td>\n",
       "      <td>0.503175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model_x4+xy-up</th>\n",
       "      <td>38.998413</td>\n",
       "      <td>0.329058</td>\n",
       "      <td>25.550649</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>3111.674603</td>\n",
       "      <td>0.178254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       avg_loss  avg_loss_ratio  avg_win_loss  loss_sum  \\\n",
       "base_model2_base      26.913492        0.219422     23.429033     963.0   \n",
       "base_model2_retarget  36.340476        0.296365     33.422078    1301.0   \n",
       "base_model2_x0.5      84.617460        0.737879     43.130749    3028.0   \n",
       "base_model2_x0.5-up   75.934127        0.650801     50.541558    2712.0   \n",
       "base_model2_x16       81.806349        0.711884     49.539825    2929.0   \n",
       "base_model2_x2        82.365873        0.713664     50.362710    2950.0   \n",
       "base_model2_x2+xy     44.838095        0.379353     24.663884    1605.0   \n",
       "base_model2_x2-up     77.103175        0.680803     40.756089    2759.0   \n",
       "base_model2_x4        83.088889        0.703676     50.606380    2972.0   \n",
       "base_model2_x4+xy-up  62.719048        0.542197     33.616445    2246.0   \n",
       "base_model_base       26.897619        0.218127     24.028855     963.0   \n",
       "base_model_retarget   34.715079        0.280082     33.469035    1243.0   \n",
       "base_model_x0.5       77.576190        0.667207     43.277579    2784.0   \n",
       "base_model_x0.5-up    80.623016        0.717495     28.104762    2881.0   \n",
       "base_model_x16        81.057143        0.700292     46.539683    2902.0   \n",
       "base_model_x2         88.079365        0.748108     47.175350    3149.0   \n",
       "base_model_x2+xy      33.342063        0.280759     21.626355    1195.0   \n",
       "base_model_x2-up      75.105556        0.651409     49.157998    2690.0   \n",
       "base_model_x4         74.356349        0.643202     37.770553    2662.0   \n",
       "base_model_x4+xy-up   38.998413        0.329058     25.550649    1398.0   \n",
       "\n",
       "                              mse  rejection_ratio  \n",
       "base_model2_base      1543.257937         0.072540  \n",
       "base_model2_retarget  2127.146825         0.072381  \n",
       "base_model2_x0.5      9159.571429         0.615079  \n",
       "base_model2_x0.5-up   7767.250000         0.426190  \n",
       "base_model2_x16       8704.404762         0.535873  \n",
       "base_model2_x2        8780.059524         0.546984  \n",
       "base_model2_x2+xy     4143.555556         0.251270  \n",
       "base_model2_x2-up     7920.682540         0.530476  \n",
       "base_model2_x4        9004.984127         0.503016  \n",
       "base_model2_x4+xy-up  6242.436508         0.384762  \n",
       "base_model_base       1510.321429         0.066825  \n",
       "base_model_retarget   1905.416667         0.050000  \n",
       "base_model_x0.5       7705.134921         0.450000  \n",
       "base_model_x0.5-up    8427.543651         0.626984  \n",
       "base_model_x16        8667.611111         0.524603  \n",
       "base_model_x2         9563.396825         0.582698  \n",
       "base_model_x2+xy      2499.765873         0.155714  \n",
       "base_model_x2-up      7319.297619         0.416667  \n",
       "base_model_x4         7658.456349         0.503175  \n",
       "base_model_x4+xy-up   3111.674603         0.178254  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression, PassiveAggressiveRegressor, \\\n",
    "                                 ElasticNet, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble.bagging import BaggingRegressor, DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "benchmark_models = {\n",
    "    'base_model': SVC(gamma='auto'), #LogisticRegression(penalty='l1', solver='liblinear', multi_class='auto'), #keras_linear_regression(nb_epoch=100, batch_size=60)\n",
    "    'base_model2': LogisticRegression(penalty='l1', solver='liblinear', multi_class='auto'),\n",
    "}\n",
    "    \n",
    "augment_params = {\n",
    "    'base': {},\n",
    "    'retarget': {'retarget': True, 'distance': 10},\n",
    "    'x0.5': {'size':len(xTrain//2)},\n",
    "    'x0.5-up': {'size':len(xTrain//2), 'upsample': True},\n",
    "    'x2': {'size':len(xTrain)*2},\n",
    "    'x2-up': {'size':len(xTrain)*2, 'upsample': True},\n",
    "    'x2+xy': {'size':len(xTrain)*2, 'include_xy':True},\n",
    "    'x4': {'size': len(xTrain)*4},\n",
    "    'x4+xy-up': {'size': len(xTrain)*4, 'include_xy':True, 'upsample':True},\n",
    "    'x16': {'size': len(xTrain)*16},\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for key, model in benchmark_models.items():\n",
    "    for aug_key, aug_params in augment_params.items():\n",
    "        results[key+\"_\" + aug_key] = process_benchmark_cv(model=model, X=x, y=y.ravel(), augment_kwargs=aug_params)\n",
    "\n",
    "results_mean = {key: item.mean() for key, item in results.items()}\n",
    "results_std = {key: item.std() for key, item in results.items()}\n",
    "pd.DataFrame(results_mean).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Actual best model:**\n",
    "- LogisticRegression (penalty='l1')\n",
    "\n",
    "** Data Augmentation improve following models:**\n",
    "- BaggingRegression\n",
    "- MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36276570410968645"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = benchmark_models['base_model2']\n",
    "\n",
    "xx = model.predict(xTrain)\n",
    "avg_loss_ratio(yTrain, xx)\n",
    "#xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franck/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples, validate on 256 samples\n",
      "Epoch 1/500\n",
      "768/768 [==============================] - 10s 12ms/step - loss: 7135.0353 - gain_tf: -0.2213 - val_loss: 6919.0018 - val_gain_tf: -0.1427\n",
      "Epoch 2/500\n",
      "768/768 [==============================] - 0s 341us/step - loss: 7125.8420 - gain_tf: -0.2209 - val_loss: 6909.2886 - val_gain_tf: -0.1421\n",
      "Epoch 3/500\n",
      "768/768 [==============================] - 0s 347us/step - loss: 7116.1673 - gain_tf: -0.2204 - val_loss: 6899.1671 - val_gain_tf: -0.1415\n",
      "Epoch 4/500\n",
      "768/768 [==============================] - 0s 334us/step - loss: 7105.7088 - gain_tf: -0.2198 - val_loss: 6888.3478 - val_gain_tf: -0.1409\n",
      "Epoch 5/500\n",
      "768/768 [==============================] - 0s 345us/step - loss: 7094.6940 - gain_tf: -0.2194 - val_loss: 6877.2191 - val_gain_tf: -0.1402\n",
      "Epoch 6/500\n",
      "768/768 [==============================] - 0s 328us/step - loss: 7083.2792 - gain_tf: -0.2189 - val_loss: 6865.9434 - val_gain_tf: -0.1396\n",
      "Epoch 7/500\n",
      "768/768 [==============================] - 0s 319us/step - loss: 7071.7602 - gain_tf: -0.2184 - val_loss: 6854.8359 - val_gain_tf: -0.1390\n",
      "Epoch 8/500\n",
      "768/768 [==============================] - 0s 328us/step - loss: 7060.4173 - gain_tf: -0.2180 - val_loss: 6843.8126 - val_gain_tf: -0.1384\n",
      "Epoch 9/500\n",
      "768/768 [==============================] - 0s 318us/step - loss: 7049.2020 - gain_tf: -0.2175 - val_loss: 6832.8279 - val_gain_tf: -0.1379\n",
      "Epoch 10/500\n",
      "768/768 [==============================] - 0s 323us/step - loss: 7038.0822 - gain_tf: -0.2170 - val_loss: 6821.9172 - val_gain_tf: -0.1373\n",
      "Epoch 11/500\n",
      "768/768 [==============================] - 0s 334us/step - loss: 7026.9914 - gain_tf: -0.2166 - val_loss: 6811.1313 - val_gain_tf: -0.1367\n",
      "Epoch 12/500\n",
      "768/768 [==============================] - 0s 291us/step - loss: 7016.0004 - gain_tf: -0.2161 - val_loss: 6800.3902 - val_gain_tf: -0.1361\n",
      "Epoch 13/500\n",
      "768/768 [==============================] - 0s 315us/step - loss: 7005.0933 - gain_tf: -0.2157 - val_loss: 6789.6400 - val_gain_tf: -0.1356\n",
      "Epoch 14/500\n",
      "768/768 [==============================] - 0s 337us/step - loss: 6994.1247 - gain_tf: -0.2153 - val_loss: 6779.1089 - val_gain_tf: -0.1350\n",
      "Epoch 15/500\n",
      "768/768 [==============================] - 0s 319us/step - loss: 6983.3248 - gain_tf: -0.2148 - val_loss: 6768.5041 - val_gain_tf: -0.1345\n",
      "Epoch 16/500\n",
      "768/768 [==============================] - 0s 313us/step - loss: 6972.4991 - gain_tf: -0.2143 - val_loss: 6757.9874 - val_gain_tf: -0.1339\n",
      "Epoch 17/500\n",
      "768/768 [==============================] - 0s 343us/step - loss: 6961.7743 - gain_tf: -0.2139 - val_loss: 6747.3929 - val_gain_tf: -0.1333\n",
      "Epoch 18/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 6951.0086 - gain_tf: -0.2134 - val_loss: 6736.9197 - val_gain_tf: -0.1328\n",
      "Epoch 19/500\n",
      "768/768 [==============================] - 0s 351us/step - loss: 6940.2756 - gain_tf: -0.2130 - val_loss: 6726.5284 - val_gain_tf: -0.1322\n",
      "Epoch 20/500\n",
      "768/768 [==============================] - 0s 326us/step - loss: 6929.6979 - gain_tf: -0.2125 - val_loss: 6715.9594 - val_gain_tf: -0.1317\n",
      "Epoch 21/500\n",
      "768/768 [==============================] - 0s 328us/step - loss: 6919.0030 - gain_tf: -0.2121 - val_loss: 6705.5499 - val_gain_tf: -0.1311\n",
      "Epoch 22/500\n",
      "768/768 [==============================] - 0s 300us/step - loss: 6908.4114 - gain_tf: -0.2116 - val_loss: 6695.1462 - val_gain_tf: -0.1305\n",
      "Epoch 23/500\n",
      "768/768 [==============================] - 0s 330us/step - loss: 6897.8019 - gain_tf: -0.2112 - val_loss: 6684.8300 - val_gain_tf: -0.1300\n",
      "Epoch 24/500\n",
      "768/768 [==============================] - 0s 330us/step - loss: 6887.2525 - gain_tf: -0.2108 - val_loss: 6674.5303 - val_gain_tf: -0.1294\n",
      "Epoch 25/500\n",
      "768/768 [==============================] - 0s 331us/step - loss: 6876.7502 - gain_tf: -0.2103 - val_loss: 6664.1946 - val_gain_tf: -0.1289\n",
      "Epoch 26/500\n",
      "768/768 [==============================] - 0s 350us/step - loss: 6866.2266 - gain_tf: -0.2099 - val_loss: 6653.9142 - val_gain_tf: -0.1283\n",
      "Epoch 27/500\n",
      "768/768 [==============================] - 0s 347us/step - loss: 6855.7745 - gain_tf: -0.2094 - val_loss: 6643.5925 - val_gain_tf: -0.1278\n",
      "Epoch 28/500\n",
      "768/768 [==============================] - 0s 322us/step - loss: 6845.2472 - gain_tf: -0.2090 - val_loss: 6633.4440 - val_gain_tf: -0.1273\n",
      "Epoch 29/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 6834.8507 - gain_tf: -0.2085 - val_loss: 6623.2215 - val_gain_tf: -0.1267\n",
      "Epoch 30/500\n",
      "768/768 [==============================] - 0s 335us/step - loss: 6824.3991 - gain_tf: -0.2081 - val_loss: 6613.0981 - val_gain_tf: -0.1262\n",
      "Epoch 31/500\n",
      "768/768 [==============================] - 0s 331us/step - loss: 6814.0448 - gain_tf: -0.2077 - val_loss: 6602.8911 - val_gain_tf: -0.1256\n",
      "Epoch 32/500\n",
      "768/768 [==============================] - 0s 354us/step - loss: 6803.6778 - gain_tf: -0.2072 - val_loss: 6592.6920 - val_gain_tf: -0.1251\n",
      "Epoch 33/500\n",
      "768/768 [==============================] - 0s 330us/step - loss: 6793.2756 - gain_tf: -0.2068 - val_loss: 6582.6462 - val_gain_tf: -0.1245\n",
      "Epoch 34/500\n",
      "768/768 [==============================] - 0s 361us/step - loss: 6782.9347 - gain_tf: -0.2063 - val_loss: 6572.6142 - val_gain_tf: -0.1240\n",
      "Epoch 35/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 6772.7107 - gain_tf: -0.2059 - val_loss: 6562.3876 - val_gain_tf: -0.1234\n",
      "Epoch 36/500\n",
      "768/768 [==============================] - 0s 318us/step - loss: 6762.3844 - gain_tf: -0.2054 - val_loss: 6552.2675 - val_gain_tf: -0.1229\n",
      "Epoch 37/500\n",
      "768/768 [==============================] - 0s 298us/step - loss: 6752.0465 - gain_tf: -0.2050 - val_loss: 6542.3107 - val_gain_tf: -0.1224\n",
      "Epoch 38/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 6741.8864 - gain_tf: -0.2046 - val_loss: 6532.1616 - val_gain_tf: -0.1218\n",
      "Epoch 39/500\n",
      "768/768 [==============================] - 0s 311us/step - loss: 6731.5587 - gain_tf: -0.2041 - val_loss: 6522.2351 - val_gain_tf: -0.1213\n",
      "Epoch 40/500\n",
      "768/768 [==============================] - 0s 297us/step - loss: 6721.3694 - gain_tf: -0.2036 - val_loss: 6512.2490 - val_gain_tf: -0.1208\n",
      "Epoch 41/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 6711.1417 - gain_tf: -0.2032 - val_loss: 6502.3325 - val_gain_tf: -0.1202\n",
      "Epoch 42/500\n",
      "768/768 [==============================] - 0s 364us/step - loss: 6701.0122 - gain_tf: -0.2028 - val_loss: 6492.2985 - val_gain_tf: -0.1197\n",
      "Epoch 43/500\n",
      "768/768 [==============================] - 0s 376us/step - loss: 6690.8223 - gain_tf: -0.2023 - val_loss: 6482.3280 - val_gain_tf: -0.1191\n",
      "Epoch 44/500\n",
      "768/768 [==============================] - 0s 378us/step - loss: 6680.6725 - gain_tf: -0.2019 - val_loss: 6472.3792 - val_gain_tf: -0.1186\n",
      "Epoch 45/500\n",
      "768/768 [==============================] - 0s 341us/step - loss: 6670.5093 - gain_tf: -0.2014 - val_loss: 6462.5170 - val_gain_tf: -0.1181\n",
      "Epoch 46/500\n",
      "768/768 [==============================] - 0s 367us/step - loss: 6660.4407 - gain_tf: -0.2010 - val_loss: 6452.5760 - val_gain_tf: -0.1175\n",
      "Epoch 47/500\n",
      "768/768 [==============================] - 0s 323us/step - loss: 6650.3046 - gain_tf: -0.2006 - val_loss: 6442.7354 - val_gain_tf: -0.1170\n",
      "Epoch 48/500\n",
      "768/768 [==============================] - 0s 328us/step - loss: 6640.1888 - gain_tf: -0.2001 - val_loss: 6432.9774 - val_gain_tf: -0.1165\n",
      "Epoch 49/500\n",
      "768/768 [==============================] - 0s 324us/step - loss: 6630.1216 - gain_tf: -0.1997 - val_loss: 6423.2319 - val_gain_tf: -0.1160\n",
      "Epoch 50/500\n",
      "768/768 [==============================] - 0s 325us/step - loss: 6620.1347 - gain_tf: -0.1992 - val_loss: 6413.3398 - val_gain_tf: -0.1154\n",
      "Epoch 51/500\n",
      "768/768 [==============================] - 0s 303us/step - loss: 6610.1119 - gain_tf: -0.1988 - val_loss: 6403.4366 - val_gain_tf: -0.1149\n",
      "Epoch 52/500\n",
      "768/768 [==============================] - 0s 340us/step - loss: 6600.0200 - gain_tf: -0.1983 - val_loss: 6393.7177 - val_gain_tf: -0.1144\n",
      "Epoch 53/500\n",
      "768/768 [==============================] - 0s 358us/step - loss: 6590.0926 - gain_tf: -0.1979 - val_loss: 6383.8392 - val_gain_tf: -0.1138\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 304us/step - loss: 6580.0421 - gain_tf: -0.1975 - val_loss: 6374.1206 - val_gain_tf: -0.1133\n",
      "Epoch 55/500\n",
      "768/768 [==============================] - 0s 357us/step - loss: 6570.0798 - gain_tf: -0.1970 - val_loss: 6364.3969 - val_gain_tf: -0.1128\n",
      "Epoch 56/500\n",
      "768/768 [==============================] - 0s 332us/step - loss: 6560.1179 - gain_tf: -0.1966 - val_loss: 6354.6959 - val_gain_tf: -0.1123\n",
      "Epoch 57/500\n",
      "768/768 [==============================] - 0s 288us/step - loss: 6550.2072 - gain_tf: -0.1961 - val_loss: 6344.9468 - val_gain_tf: -0.1117\n",
      "Epoch 58/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 6540.2926 - gain_tf: -0.1957 - val_loss: 6335.1924 - val_gain_tf: -0.1112\n",
      "Epoch 59/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 6530.3428 - gain_tf: -0.1953 - val_loss: 6325.5583 - val_gain_tf: -0.1107\n",
      "Epoch 60/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 6520.4615 - gain_tf: -0.1948 - val_loss: 6315.9010 - val_gain_tf: -0.1102\n",
      "Epoch 61/500\n",
      "768/768 [==============================] - 0s 308us/step - loss: 6510.6235 - gain_tf: -0.1944 - val_loss: 6306.1798 - val_gain_tf: -0.1096\n",
      "Epoch 62/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 6500.6888 - gain_tf: -0.1939 - val_loss: 6296.6318 - val_gain_tf: -0.1091\n",
      "Epoch 63/500\n",
      "768/768 [==============================] - 0s 320us/step - loss: 6490.8383 - gain_tf: -0.1935 - val_loss: 6287.0980 - val_gain_tf: -0.1086\n",
      "Epoch 64/500\n",
      "768/768 [==============================] - 0s 303us/step - loss: 6481.0367 - gain_tf: -0.1931 - val_loss: 6277.4941 - val_gain_tf: -0.1081\n",
      "Epoch 65/500\n",
      "768/768 [==============================] - 0s 324us/step - loss: 6471.2280 - gain_tf: -0.1926 - val_loss: 6267.8775 - val_gain_tf: -0.1076\n",
      "Epoch 66/500\n",
      "768/768 [==============================] - 0s 311us/step - loss: 6461.4727 - gain_tf: -0.1922 - val_loss: 6258.1624 - val_gain_tf: -0.1070\n",
      "Epoch 67/500\n",
      "768/768 [==============================] - 0s 320us/step - loss: 6451.5844 - gain_tf: -0.1917 - val_loss: 6248.7018 - val_gain_tf: -0.1065\n",
      "Epoch 68/500\n",
      "768/768 [==============================] - 0s 322us/step - loss: 6441.8759 - gain_tf: -0.1913 - val_loss: 6239.0994 - val_gain_tf: -0.1060\n",
      "Epoch 69/500\n",
      "768/768 [==============================] - 0s 298us/step - loss: 6432.1003 - gain_tf: -0.1909 - val_loss: 6229.5522 - val_gain_tf: -0.1055\n",
      "Epoch 70/500\n",
      "768/768 [==============================] - 0s 316us/step - loss: 6422.3108 - gain_tf: -0.1904 - val_loss: 6220.1191 - val_gain_tf: -0.1050\n",
      "Epoch 71/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 6412.6267 - gain_tf: -0.1900 - val_loss: 6210.5963 - val_gain_tf: -0.1045\n",
      "Epoch 72/500\n",
      "768/768 [==============================] - 0s 340us/step - loss: 6402.9156 - gain_tf: -0.1896 - val_loss: 6201.0658 - val_gain_tf: -0.1040\n",
      "Epoch 73/500\n",
      "768/768 [==============================] - 0s 336us/step - loss: 6393.1923 - gain_tf: -0.1891 - val_loss: 6191.6063 - val_gain_tf: -0.1034\n",
      "Epoch 74/500\n",
      "768/768 [==============================] - 0s 292us/step - loss: 6383.4482 - gain_tf: -0.1887 - val_loss: 6182.2861 - val_gain_tf: -0.1029\n",
      "Epoch 75/500\n",
      "768/768 [==============================] - 0s 325us/step - loss: 6373.8987 - gain_tf: -0.1882 - val_loss: 6172.6807 - val_gain_tf: -0.1024\n",
      "Epoch 76/500\n",
      "768/768 [==============================] - 0s 338us/step - loss: 6364.1926 - gain_tf: -0.1878 - val_loss: 6163.2031 - val_gain_tf: -0.1019\n",
      "Epoch 77/500\n",
      "768/768 [==============================] - 0s 308us/step - loss: 6354.4787 - gain_tf: -0.1874 - val_loss: 6153.8952 - val_gain_tf: -0.1014\n",
      "Epoch 78/500\n",
      "768/768 [==============================] - 0s 319us/step - loss: 6344.8912 - gain_tf: -0.1869 - val_loss: 6144.4898 - val_gain_tf: -0.1009\n",
      "Epoch 79/500\n",
      "768/768 [==============================] - 0s 338us/step - loss: 6335.3065 - gain_tf: -0.1865 - val_loss: 6135.0206 - val_gain_tf: -0.1004\n",
      "Epoch 80/500\n",
      "768/768 [==============================] - 0s 324us/step - loss: 6325.6429 - gain_tf: -0.1860 - val_loss: 6125.7016 - val_gain_tf: -0.0999\n",
      "Epoch 81/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 6316.0790 - gain_tf: -0.1856 - val_loss: 6116.3301 - val_gain_tf: -0.0994\n",
      "Epoch 82/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 6306.4927 - gain_tf: -0.1851 - val_loss: 6106.9963 - val_gain_tf: -0.0989\n",
      "Epoch 83/500\n",
      "768/768 [==============================] - 0s 315us/step - loss: 6297.0012 - gain_tf: -0.1847 - val_loss: 6097.5143 - val_gain_tf: -0.0983\n",
      "Epoch 84/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 6287.3080 - gain_tf: -0.1842 - val_loss: 6088.3792 - val_gain_tf: -0.0978\n",
      "Epoch 85/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 6277.8291 - gain_tf: -0.1838 - val_loss: 6079.1164 - val_gain_tf: -0.0973\n",
      "Epoch 86/500\n",
      "768/768 [==============================] - 0s 295us/step - loss: 6268.3637 - gain_tf: -0.1834 - val_loss: 6069.7342 - val_gain_tf: -0.0968\n",
      "Epoch 87/500\n",
      "768/768 [==============================] - 0s 295us/step - loss: 6258.8015 - gain_tf: -0.1829 - val_loss: 6060.4954 - val_gain_tf: -0.0963\n",
      "Epoch 88/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 6249.3132 - gain_tf: -0.1825 - val_loss: 6051.2534 - val_gain_tf: -0.0958\n",
      "Epoch 89/500\n",
      "768/768 [==============================] - 0s 320us/step - loss: 6239.8479 - gain_tf: -0.1820 - val_loss: 6041.9893 - val_gain_tf: -0.0953\n",
      "Epoch 90/500\n",
      "768/768 [==============================] - 0s 292us/step - loss: 6230.3704 - gain_tf: -0.1816 - val_loss: 6032.7556 - val_gain_tf: -0.0948\n",
      "Epoch 91/500\n",
      "768/768 [==============================] - 0s 309us/step - loss: 6220.9563 - gain_tf: -0.1812 - val_loss: 6023.4472 - val_gain_tf: -0.0943\n",
      "Epoch 92/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 6211.4817 - gain_tf: -0.1807 - val_loss: 6014.2405 - val_gain_tf: -0.0938\n",
      "Epoch 93/500\n",
      "768/768 [==============================] - 0s 353us/step - loss: 6202.0553 - gain_tf: -0.1803 - val_loss: 6005.0470 - val_gain_tf: -0.0933\n",
      "Epoch 94/500\n",
      "768/768 [==============================] - 0s 295us/step - loss: 6192.6013 - gain_tf: -0.1799 - val_loss: 5995.9682 - val_gain_tf: -0.0928\n",
      "Epoch 95/500\n",
      "768/768 [==============================] - 0s 347us/step - loss: 6183.2937 - gain_tf: -0.1794 - val_loss: 5986.6844 - val_gain_tf: -0.0923\n",
      "Epoch 96/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 6173.8198 - gain_tf: -0.1790 - val_loss: 5977.6324 - val_gain_tf: -0.0918\n",
      "Epoch 97/500\n",
      "768/768 [==============================] - 0s 331us/step - loss: 6164.4998 - gain_tf: -0.1786 - val_loss: 5968.4567 - val_gain_tf: -0.0913\n",
      "Epoch 98/500\n",
      "768/768 [==============================] - 0s 322us/step - loss: 6155.1043 - gain_tf: -0.1781 - val_loss: 5959.3788 - val_gain_tf: -0.0908\n",
      "Epoch 99/500\n",
      "768/768 [==============================] - 0s 323us/step - loss: 6145.8444 - gain_tf: -0.1777 - val_loss: 5950.1279 - val_gain_tf: -0.0903\n",
      "Epoch 100/500\n",
      "768/768 [==============================] - 0s 317us/step - loss: 6136.4249 - gain_tf: -0.1772 - val_loss: 5941.0820 - val_gain_tf: -0.0898\n",
      "Epoch 101/500\n",
      "768/768 [==============================] - 0s 299us/step - loss: 6127.1121 - gain_tf: -0.1768 - val_loss: 5932.0372 - val_gain_tf: -0.0894\n",
      "Epoch 102/500\n",
      "768/768 [==============================] - 0s 374us/step - loss: 6117.8112 - gain_tf: -0.1763 - val_loss: 5922.9814 - val_gain_tf: -0.0889\n",
      "Epoch 103/500\n",
      "768/768 [==============================] - 0s 307us/step - loss: 6108.5676 - gain_tf: -0.1759 - val_loss: 5913.8271 - val_gain_tf: -0.0884\n",
      "Epoch 104/500\n",
      "768/768 [==============================] - 0s 298us/step - loss: 6099.2046 - gain_tf: -0.1755 - val_loss: 5904.8749 - val_gain_tf: -0.0879\n",
      "Epoch 105/500\n",
      "768/768 [==============================] - 0s 341us/step - loss: 6090.0198 - gain_tf: -0.1750 - val_loss: 5895.7431 - val_gain_tf: -0.0874\n",
      "Epoch 106/500\n",
      "768/768 [==============================] - 0s 340us/step - loss: 6080.6844 - gain_tf: -0.1746 - val_loss: 5886.8175 - val_gain_tf: -0.0869\n",
      "Epoch 107/500\n",
      "768/768 [==============================] - 0s 356us/step - loss: 6071.4981 - gain_tf: -0.1741 - val_loss: 5877.7723 - val_gain_tf: -0.0864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/500\n",
      "768/768 [==============================] - 0s 308us/step - loss: 6062.2378 - gain_tf: -0.1737 - val_loss: 5868.8024 - val_gain_tf: -0.0859\n",
      "Epoch 109/500\n",
      "768/768 [==============================] - 0s 316us/step - loss: 6053.0388 - gain_tf: -0.1733 - val_loss: 5859.8146 - val_gain_tf: -0.0854\n",
      "Epoch 110/500\n",
      "768/768 [==============================] - 0s 319us/step - loss: 6043.8062 - gain_tf: -0.1728 - val_loss: 5850.8944 - val_gain_tf: -0.0849\n",
      "Epoch 111/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 6034.6642 - gain_tf: -0.1724 - val_loss: 5841.8707 - val_gain_tf: -0.0845\n",
      "Epoch 112/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 6025.4873 - gain_tf: -0.1719 - val_loss: 5832.8612 - val_gain_tf: -0.0840\n",
      "Epoch 113/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 6016.2280 - gain_tf: -0.1715 - val_loss: 5824.0809 - val_gain_tf: -0.0835\n",
      "Epoch 114/500\n",
      "768/768 [==============================] - 0s 331us/step - loss: 6007.1307 - gain_tf: -0.1711 - val_loss: 5815.1674 - val_gain_tf: -0.0830\n",
      "Epoch 115/500\n",
      "768/768 [==============================] - 0s 291us/step - loss: 5998.0400 - gain_tf: -0.1706 - val_loss: 5806.1483 - val_gain_tf: -0.0825\n",
      "Epoch 116/500\n",
      "768/768 [==============================] - 0s 334us/step - loss: 5988.8248 - gain_tf: -0.1702 - val_loss: 5797.3416 - val_gain_tf: -0.0820\n",
      "Epoch 117/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 5979.7633 - gain_tf: -0.1698 - val_loss: 5788.4189 - val_gain_tf: -0.0815\n",
      "Epoch 118/500\n",
      "768/768 [==============================] - 0s 338us/step - loss: 5970.5814 - gain_tf: -0.1693 - val_loss: 5779.6943 - val_gain_tf: -0.0811\n",
      "Epoch 119/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 5961.6417 - gain_tf: -0.1689 - val_loss: 5770.6270 - val_gain_tf: -0.0806\n",
      "Epoch 120/500\n",
      "768/768 [==============================] - 0s 312us/step - loss: 5952.4438 - gain_tf: -0.1684 - val_loss: 5761.8480 - val_gain_tf: -0.0801\n",
      "Epoch 121/500\n",
      "768/768 [==============================] - 0s 291us/step - loss: 5943.4282 - gain_tf: -0.1680 - val_loss: 5752.9708 - val_gain_tf: -0.0796\n",
      "Epoch 122/500\n",
      "768/768 [==============================] - 0s 312us/step - loss: 5934.3451 - gain_tf: -0.1676 - val_loss: 5744.1815 - val_gain_tf: -0.0791\n",
      "Epoch 123/500\n",
      "768/768 [==============================] - 0s 346us/step - loss: 5925.3276 - gain_tf: -0.1671 - val_loss: 5735.3475 - val_gain_tf: -0.0787\n",
      "Epoch 124/500\n",
      "768/768 [==============================] - 0s 324us/step - loss: 5916.2435 - gain_tf: -0.1667 - val_loss: 5726.6505 - val_gain_tf: -0.0782\n",
      "Epoch 125/500\n",
      "768/768 [==============================] - 0s 317us/step - loss: 5907.2764 - gain_tf: -0.1663 - val_loss: 5717.8494 - val_gain_tf: -0.0777\n",
      "Epoch 126/500\n",
      "768/768 [==============================] - 0s 318us/step - loss: 5898.2465 - gain_tf: -0.1658 - val_loss: 5709.1187 - val_gain_tf: -0.0772\n",
      "Epoch 127/500\n",
      "768/768 [==============================] - 0s 311us/step - loss: 5889.3268 - gain_tf: -0.1653 - val_loss: 5700.2371 - val_gain_tf: -0.0768\n",
      "Epoch 128/500\n",
      "768/768 [==============================] - 0s 305us/step - loss: 5880.2899 - gain_tf: -0.1649 - val_loss: 5691.5026 - val_gain_tf: -0.0763\n",
      "Epoch 129/500\n",
      "768/768 [==============================] - 0s 331us/step - loss: 5871.2929 - gain_tf: -0.1645 - val_loss: 5682.8484 - val_gain_tf: -0.0758\n",
      "Epoch 130/500\n",
      "768/768 [==============================] - 0s 319us/step - loss: 5862.3681 - gain_tf: -0.1640 - val_loss: 5674.1242 - val_gain_tf: -0.0753\n",
      "Epoch 131/500\n",
      "768/768 [==============================] - 0s 308us/step - loss: 5853.4227 - gain_tf: -0.1636 - val_loss: 5665.4221 - val_gain_tf: -0.0749\n",
      "Epoch 132/500\n",
      "768/768 [==============================] - 0s 298us/step - loss: 5844.4438 - gain_tf: -0.1631 - val_loss: 5656.8413 - val_gain_tf: -0.0744\n",
      "Epoch 133/500\n",
      "768/768 [==============================] - 0s 347us/step - loss: 5835.6467 - gain_tf: -0.1627 - val_loss: 5647.9836 - val_gain_tf: -0.0739\n",
      "Epoch 134/500\n",
      "768/768 [==============================] - 0s 316us/step - loss: 5826.6437 - gain_tf: -0.1623 - val_loss: 5639.3591 - val_gain_tf: -0.0735\n",
      "Epoch 135/500\n",
      "768/768 [==============================] - 0s 346us/step - loss: 5817.7441 - gain_tf: -0.1618 - val_loss: 5630.7514 - val_gain_tf: -0.0730\n",
      "Epoch 136/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 5808.8618 - gain_tf: -0.1614 - val_loss: 5622.1464 - val_gain_tf: -0.0725\n",
      "Epoch 137/500\n",
      "768/768 [==============================] - 0s 317us/step - loss: 5799.9979 - gain_tf: -0.1610 - val_loss: 5613.5316 - val_gain_tf: -0.0721\n",
      "Epoch 138/500\n",
      "768/768 [==============================] - 0s 332us/step - loss: 5791.1827 - gain_tf: -0.1605 - val_loss: 5604.8188 - val_gain_tf: -0.0716\n",
      "Epoch 139/500\n",
      "768/768 [==============================] - 0s 336us/step - loss: 5782.3129 - gain_tf: -0.1601 - val_loss: 5596.1728 - val_gain_tf: -0.0711\n",
      "Epoch 140/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 5773.3847 - gain_tf: -0.1597 - val_loss: 5587.7603 - val_gain_tf: -0.0707\n",
      "Epoch 141/500\n",
      "768/768 [==============================] - 0s 332us/step - loss: 5764.6796 - gain_tf: -0.1592 - val_loss: 5579.0622 - val_gain_tf: -0.0702\n",
      "Epoch 142/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 5755.8059 - gain_tf: -0.1588 - val_loss: 5570.5172 - val_gain_tf: -0.0697\n",
      "Epoch 143/500\n",
      "768/768 [==============================] - 0s 326us/step - loss: 5747.0161 - gain_tf: -0.1583 - val_loss: 5561.9512 - val_gain_tf: -0.0693\n",
      "Epoch 144/500\n",
      "768/768 [==============================] - 0s 299us/step - loss: 5738.2564 - gain_tf: -0.1579 - val_loss: 5553.3365 - val_gain_tf: -0.0688\n",
      "Epoch 145/500\n",
      "768/768 [==============================] - 0s 341us/step - loss: 5729.3950 - gain_tf: -0.1575 - val_loss: 5544.9304 - val_gain_tf: -0.0683\n",
      "Epoch 146/500\n",
      "768/768 [==============================] - 0s 336us/step - loss: 5720.7132 - gain_tf: -0.1570 - val_loss: 5536.3313 - val_gain_tf: -0.0679\n",
      "Epoch 147/500\n",
      "768/768 [==============================] - 0s 323us/step - loss: 5711.9770 - gain_tf: -0.1566 - val_loss: 5527.7181 - val_gain_tf: -0.0674\n",
      "Epoch 148/500\n",
      "768/768 [==============================] - 0s 326us/step - loss: 5703.1311 - gain_tf: -0.1561 - val_loss: 5519.3594 - val_gain_tf: -0.0670\n",
      "Epoch 149/500\n",
      "768/768 [==============================] - 0s 335us/step - loss: 5694.4948 - gain_tf: -0.1557 - val_loss: 5510.7875 - val_gain_tf: -0.0665\n",
      "Epoch 150/500\n",
      "768/768 [==============================] - 0s 305us/step - loss: 5685.7548 - gain_tf: -0.1553 - val_loss: 5502.2884 - val_gain_tf: -0.0660\n",
      "Epoch 151/500\n",
      "768/768 [==============================] - 0s 309us/step - loss: 5676.9955 - gain_tf: -0.1548 - val_loss: 5493.9295 - val_gain_tf: -0.0656\n",
      "Epoch 152/500\n",
      "768/768 [==============================] - 0s 293us/step - loss: 5668.3501 - gain_tf: -0.1544 - val_loss: 5485.4583 - val_gain_tf: -0.0651\n",
      "Epoch 153/500\n",
      "768/768 [==============================] - 0s 365us/step - loss: 5659.6683 - gain_tf: -0.1539 - val_loss: 5476.9945 - val_gain_tf: -0.0647\n",
      "Epoch 154/500\n",
      "768/768 [==============================] - 0s 284us/step - loss: 5651.0078 - gain_tf: -0.1535 - val_loss: 5468.5276 - val_gain_tf: -0.0642\n",
      "Epoch 155/500\n",
      "768/768 [==============================] - 0s 331us/step - loss: 5642.2748 - gain_tf: -0.1531 - val_loss: 5460.2538 - val_gain_tf: -0.0638\n",
      "Epoch 156/500\n",
      "768/768 [==============================] - 0s 326us/step - loss: 5633.7599 - gain_tf: -0.1526 - val_loss: 5451.6895 - val_gain_tf: -0.0633\n",
      "Epoch 157/500\n",
      "768/768 [==============================] - 0s 317us/step - loss: 5625.0337 - gain_tf: -0.1522 - val_loss: 5443.3446 - val_gain_tf: -0.0628\n",
      "Epoch 158/500\n",
      "768/768 [==============================] - 0s 324us/step - loss: 5616.3814 - gain_tf: -0.1517 - val_loss: 5435.0820 - val_gain_tf: -0.0624\n",
      "Epoch 159/500\n",
      "768/768 [==============================] - 0s 343us/step - loss: 5607.8325 - gain_tf: -0.1513 - val_loss: 5426.6755 - val_gain_tf: -0.0619\n",
      "Epoch 160/500\n",
      "768/768 [==============================] - 0s 337us/step - loss: 5599.2208 - gain_tf: -0.1509 - val_loss: 5418.3169 - val_gain_tf: -0.0615\n",
      "Epoch 161/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 325us/step - loss: 5590.6254 - gain_tf: -0.1504 - val_loss: 5409.9719 - val_gain_tf: -0.0610\n",
      "Epoch 162/500\n",
      "768/768 [==============================] - 0s 334us/step - loss: 5582.0972 - gain_tf: -0.1500 - val_loss: 5401.5405 - val_gain_tf: -0.0606\n",
      "Epoch 163/500\n",
      "768/768 [==============================] - 0s 325us/step - loss: 5573.4474 - gain_tf: -0.1495 - val_loss: 5393.3109 - val_gain_tf: -0.0601\n",
      "Epoch 164/500\n",
      "768/768 [==============================] - 0s 309us/step - loss: 5564.9068 - gain_tf: -0.1491 - val_loss: 5385.0633 - val_gain_tf: -0.0597\n",
      "Epoch 165/500\n",
      "768/768 [==============================] - 0s 372us/step - loss: 5556.4336 - gain_tf: -0.1487 - val_loss: 5376.6657 - val_gain_tf: -0.0592\n",
      "Epoch 166/500\n",
      "768/768 [==============================] - 0s 313us/step - loss: 5547.8584 - gain_tf: -0.1482 - val_loss: 5368.3785 - val_gain_tf: -0.0588\n",
      "Epoch 167/500\n",
      "768/768 [==============================] - 0s 290us/step - loss: 5539.3455 - gain_tf: -0.1478 - val_loss: 5360.0973 - val_gain_tf: -0.0584\n",
      "Epoch 168/500\n",
      "768/768 [==============================] - 0s 322us/step - loss: 5530.8184 - gain_tf: -0.1474 - val_loss: 5351.8750 - val_gain_tf: -0.0579\n",
      "Epoch 169/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 5522.3287 - gain_tf: -0.1469 - val_loss: 5343.6528 - val_gain_tf: -0.0575\n",
      "Epoch 170/500\n",
      "768/768 [==============================] - 0s 314us/step - loss: 5513.9265 - gain_tf: -0.1465 - val_loss: 5335.2712 - val_gain_tf: -0.0570\n",
      "Epoch 171/500\n",
      "768/768 [==============================] - 0s 350us/step - loss: 5505.3191 - gain_tf: -0.1460 - val_loss: 5327.2035 - val_gain_tf: -0.0566\n",
      "Epoch 172/500\n",
      "768/768 [==============================] - 0s 320us/step - loss: 5496.9276 - gain_tf: -0.1456 - val_loss: 5318.9824 - val_gain_tf: -0.0561\n",
      "Epoch 173/500\n",
      "768/768 [==============================] - 0s 322us/step - loss: 5488.4884 - gain_tf: -0.1451 - val_loss: 5310.7484 - val_gain_tf: -0.0557\n",
      "Epoch 174/500\n",
      "768/768 [==============================] - 0s 323us/step - loss: 5479.9956 - gain_tf: -0.1447 - val_loss: 5302.6617 - val_gain_tf: -0.0553\n",
      "Epoch 175/500\n",
      "768/768 [==============================] - 0s 338us/step - loss: 5471.6190 - gain_tf: -0.1443 - val_loss: 5294.4609 - val_gain_tf: -0.0548\n",
      "Epoch 176/500\n",
      "768/768 [==============================] - 0s 325us/step - loss: 5463.1985 - gain_tf: -0.1438 - val_loss: 5286.2894 - val_gain_tf: -0.0544\n",
      "Epoch 177/500\n",
      "768/768 [==============================] - 0s 379us/step - loss: 5454.8109 - gain_tf: -0.1434 - val_loss: 5278.0878 - val_gain_tf: -0.0539\n",
      "Epoch 178/500\n",
      "768/768 [==============================] - 0s 313us/step - loss: 5446.3913 - gain_tf: -0.1430 - val_loss: 5269.9652 - val_gain_tf: -0.0535\n",
      "Epoch 179/500\n",
      "768/768 [==============================] - 0s 325us/step - loss: 5438.0596 - gain_tf: -0.1426 - val_loss: 5261.7465 - val_gain_tf: -0.0531\n",
      "Epoch 180/500\n",
      "768/768 [==============================] - 0s 328us/step - loss: 5429.5843 - gain_tf: -0.1421 - val_loss: 5253.7890 - val_gain_tf: -0.0526\n",
      "Epoch 181/500\n",
      "768/768 [==============================] - 0s 346us/step - loss: 5421.3063 - gain_tf: -0.1417 - val_loss: 5245.6510 - val_gain_tf: -0.0522\n",
      "Epoch 182/500\n",
      "768/768 [==============================] - 0s 357us/step - loss: 5412.9618 - gain_tf: -0.1413 - val_loss: 5237.5182 - val_gain_tf: -0.0518\n",
      "Epoch 183/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 5404.5895 - gain_tf: -0.1408 - val_loss: 5229.4796 - val_gain_tf: -0.0513\n",
      "Epoch 184/500\n",
      "768/768 [==============================] - 0s 320us/step - loss: 5396.2584 - gain_tf: -0.1403 - val_loss: 5221.4752 - val_gain_tf: -0.0509\n",
      "Epoch 185/500\n",
      "768/768 [==============================] - 0s 320us/step - loss: 5388.0101 - gain_tf: -0.1399 - val_loss: 5213.3188 - val_gain_tf: -0.0505\n",
      "Epoch 186/500\n",
      "768/768 [==============================] - 0s 334us/step - loss: 5379.6306 - gain_tf: -0.1395 - val_loss: 5205.3581 - val_gain_tf: -0.0500\n",
      "Epoch 187/500\n",
      "768/768 [==============================] - 0s 286us/step - loss: 5371.4394 - gain_tf: -0.1391 - val_loss: 5197.1814 - val_gain_tf: -0.0496\n",
      "Epoch 188/500\n",
      "768/768 [==============================] - 0s 361us/step - loss: 5363.0992 - gain_tf: -0.1386 - val_loss: 5189.1613 - val_gain_tf: -0.0492\n",
      "Epoch 189/500\n",
      "768/768 [==============================] - 0s 313us/step - loss: 5354.8094 - gain_tf: -0.1382 - val_loss: 5181.2021 - val_gain_tf: -0.0487\n",
      "Epoch 190/500\n",
      "768/768 [==============================] - 0s 340us/step - loss: 5346.6354 - gain_tf: -0.1377 - val_loss: 5173.0738 - val_gain_tf: -0.0483\n",
      "Epoch 191/500\n",
      "768/768 [==============================] - 0s 303us/step - loss: 5338.3039 - gain_tf: -0.1373 - val_loss: 5165.1600 - val_gain_tf: -0.0479\n",
      "Epoch 192/500\n",
      "768/768 [==============================] - 0s 315us/step - loss: 5330.0642 - gain_tf: -0.1369 - val_loss: 5157.2722 - val_gain_tf: -0.0475\n",
      "Epoch 193/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 5321.9373 - gain_tf: -0.1364 - val_loss: 5149.1687 - val_gain_tf: -0.0470\n",
      "Epoch 194/500\n",
      "768/768 [==============================] - 0s 318us/step - loss: 5313.6567 - gain_tf: -0.1360 - val_loss: 5141.2443 - val_gain_tf: -0.0466\n",
      "Epoch 195/500\n",
      "768/768 [==============================] - 0s 291us/step - loss: 5305.4784 - gain_tf: -0.1356 - val_loss: 5133.2874 - val_gain_tf: -0.0462\n",
      "Epoch 196/500\n",
      "768/768 [==============================] - 0s 313us/step - loss: 5297.2456 - gain_tf: -0.1351 - val_loss: 5125.4426 - val_gain_tf: -0.0458\n",
      "Epoch 197/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 5289.1301 - gain_tf: -0.1347 - val_loss: 5117.4637 - val_gain_tf: -0.0453\n",
      "Epoch 198/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 5280.9551 - gain_tf: -0.1342 - val_loss: 5109.5310 - val_gain_tf: -0.0449\n",
      "Epoch 199/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 5272.7588 - gain_tf: -0.1338 - val_loss: 5101.7006 - val_gain_tf: -0.0445\n",
      "Epoch 200/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 5264.6597 - gain_tf: -0.1334 - val_loss: 5093.7828 - val_gain_tf: -0.0441\n",
      "Epoch 201/500\n",
      "768/768 [==============================] - 0s 342us/step - loss: 5256.4883 - gain_tf: -0.1330 - val_loss: 5085.9672 - val_gain_tf: -0.0436\n",
      "Epoch 202/500\n",
      "768/768 [==============================] - 0s 331us/step - loss: 5248.4467 - gain_tf: -0.1325 - val_loss: 5077.9926 - val_gain_tf: -0.0432\n",
      "Epoch 203/500\n",
      "768/768 [==============================] - 0s 336us/step - loss: 5240.2493 - gain_tf: -0.1320 - val_loss: 5070.2316 - val_gain_tf: -0.0428\n",
      "Epoch 204/500\n",
      "768/768 [==============================] - 0s 332us/step - loss: 5232.2021 - gain_tf: -0.1316 - val_loss: 5062.3648 - val_gain_tf: -0.0424\n",
      "Epoch 205/500\n",
      "768/768 [==============================] - 0s 344us/step - loss: 5224.1490 - gain_tf: -0.1312 - val_loss: 5054.4376 - val_gain_tf: -0.0420\n",
      "Epoch 206/500\n",
      "768/768 [==============================] - 0s 318us/step - loss: 5216.0394 - gain_tf: -0.1307 - val_loss: 5046.6083 - val_gain_tf: -0.0415\n",
      "Epoch 207/500\n",
      "768/768 [==============================] - 0s 326us/step - loss: 5207.8958 - gain_tf: -0.1303 - val_loss: 5038.9725 - val_gain_tf: -0.0411\n",
      "Epoch 208/500\n",
      "768/768 [==============================] - 0s 293us/step - loss: 5199.8890 - gain_tf: -0.1299 - val_loss: 5031.2341 - val_gain_tf: -0.0407\n",
      "Epoch 209/500\n",
      "768/768 [==============================] - 0s 322us/step - loss: 5191.9462 - gain_tf: -0.1295 - val_loss: 5023.2707 - val_gain_tf: -0.0403\n",
      "Epoch 210/500\n",
      "768/768 [==============================] - 0s 320us/step - loss: 5183.8284 - gain_tf: -0.1290 - val_loss: 5015.5211 - val_gain_tf: -0.0399\n",
      "Epoch 211/500\n",
      "768/768 [==============================] - 0s 371us/step - loss: 5175.8474 - gain_tf: -0.1286 - val_loss: 5007.6989 - val_gain_tf: -0.0395\n",
      "Epoch 212/500\n",
      "768/768 [==============================] - 0s 347us/step - loss: 5167.7741 - gain_tf: -0.1282 - val_loss: 5000.0422 - val_gain_tf: -0.0391\n",
      "Epoch 213/500\n",
      "768/768 [==============================] - 0s 342us/step - loss: 5159.8201 - gain_tf: -0.1277 - val_loss: 4992.2914 - val_gain_tf: -0.0387\n",
      "Epoch 214/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 299us/step - loss: 5151.7983 - gain_tf: -0.1273 - val_loss: 4984.6339 - val_gain_tf: -0.0383\n",
      "Epoch 215/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 5143.8589 - gain_tf: -0.1268 - val_loss: 4976.9041 - val_gain_tf: -0.0378\n",
      "Epoch 216/500\n",
      "768/768 [==============================] - 0s 328us/step - loss: 5135.9124 - gain_tf: -0.1264 - val_loss: 4969.1449 - val_gain_tf: -0.0374\n",
      "Epoch 217/500\n",
      "768/768 [==============================] - 0s 346us/step - loss: 5127.9196 - gain_tf: -0.1259 - val_loss: 4961.4834 - val_gain_tf: -0.0370\n",
      "Epoch 218/500\n",
      "768/768 [==============================] - 0s 337us/step - loss: 5120.0191 - gain_tf: -0.1255 - val_loss: 4953.7378 - val_gain_tf: -0.0366\n",
      "Epoch 219/500\n",
      "768/768 [==============================] - 0s 343us/step - loss: 5112.0186 - gain_tf: -0.1251 - val_loss: 4946.1627 - val_gain_tf: -0.0362\n",
      "Epoch 220/500\n",
      "768/768 [==============================] - 0s 325us/step - loss: 5104.1161 - gain_tf: -0.1247 - val_loss: 4938.5549 - val_gain_tf: -0.0358\n",
      "Epoch 221/500\n",
      "768/768 [==============================] - 0s 331us/step - loss: 5096.2915 - gain_tf: -0.1242 - val_loss: 4930.7674 - val_gain_tf: -0.0354\n",
      "Epoch 222/500\n",
      "768/768 [==============================] - 0s 316us/step - loss: 5088.3439 - gain_tf: -0.1238 - val_loss: 4923.1004 - val_gain_tf: -0.0350\n",
      "Epoch 223/500\n",
      "768/768 [==============================] - 0s 303us/step - loss: 5080.4314 - gain_tf: -0.1233 - val_loss: 4915.5000 - val_gain_tf: -0.0346\n",
      "Epoch 224/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 5072.5253 - gain_tf: -0.1229 - val_loss: 4907.9802 - val_gain_tf: -0.0342\n",
      "Epoch 225/500\n",
      "768/768 [==============================] - 0s 349us/step - loss: 5064.7384 - gain_tf: -0.1224 - val_loss: 4900.2793 - val_gain_tf: -0.0338\n",
      "Epoch 226/500\n",
      "768/768 [==============================] - 0s 330us/step - loss: 5056.8334 - gain_tf: -0.1220 - val_loss: 4892.7121 - val_gain_tf: -0.0334\n",
      "Epoch 227/500\n",
      "768/768 [==============================] - 0s 327us/step - loss: 5048.9861 - gain_tf: -0.1216 - val_loss: 4885.1567 - val_gain_tf: -0.0330\n",
      "Epoch 228/500\n",
      "768/768 [==============================] - 0s 340us/step - loss: 5041.2266 - gain_tf: -0.1212 - val_loss: 4877.4568 - val_gain_tf: -0.0326\n",
      "Epoch 229/500\n",
      "768/768 [==============================] - 0s 314us/step - loss: 5033.3061 - gain_tf: -0.1207 - val_loss: 4869.9901 - val_gain_tf: -0.0322\n",
      "Epoch 230/500\n",
      "768/768 [==============================] - 0s 349us/step - loss: 5025.5447 - gain_tf: -0.1203 - val_loss: 4862.4269 - val_gain_tf: -0.0318\n",
      "Epoch 231/500\n",
      "768/768 [==============================] - 0s 338us/step - loss: 5017.7235 - gain_tf: -0.1199 - val_loss: 4854.9249 - val_gain_tf: -0.0314\n",
      "Epoch 232/500\n",
      "768/768 [==============================] - 0s 390us/step - loss: 5009.9462 - gain_tf: -0.1194 - val_loss: 4847.4089 - val_gain_tf: -0.0310\n",
      "Epoch 233/500\n",
      "768/768 [==============================] - 0s 319us/step - loss: 5002.1739 - gain_tf: -0.1190 - val_loss: 4839.8909 - val_gain_tf: -0.0306\n",
      "Epoch 234/500\n",
      "768/768 [==============================] - 0s 354us/step - loss: 4994.4070 - gain_tf: -0.1186 - val_loss: 4832.3841 - val_gain_tf: -0.0302\n",
      "Epoch 235/500\n",
      "768/768 [==============================] - 0s 311us/step - loss: 4986.6035 - gain_tf: -0.1181 - val_loss: 4825.0035 - val_gain_tf: -0.0298\n",
      "Epoch 236/500\n",
      "768/768 [==============================] - 0s 327us/step - loss: 4978.9240 - gain_tf: -0.1177 - val_loss: 4817.4877 - val_gain_tf: -0.0294\n",
      "Epoch 237/500\n",
      "768/768 [==============================] - 0s 323us/step - loss: 4971.2218 - gain_tf: -0.1172 - val_loss: 4809.8979 - val_gain_tf: -0.0290\n",
      "Epoch 238/500\n",
      "768/768 [==============================] - 0s 336us/step - loss: 4963.4529 - gain_tf: -0.1168 - val_loss: 4802.4383 - val_gain_tf: -0.0286\n",
      "Epoch 239/500\n",
      "768/768 [==============================] - 0s 298us/step - loss: 4955.7742 - gain_tf: -0.1164 - val_loss: 4794.9262 - val_gain_tf: -0.0282\n",
      "Epoch 240/500\n",
      "768/768 [==============================] - 0s 335us/step - loss: 4948.0217 - gain_tf: -0.1159 - val_loss: 4787.5527 - val_gain_tf: -0.0278\n",
      "Epoch 241/500\n",
      "768/768 [==============================] - 0s 300us/step - loss: 4940.3557 - gain_tf: -0.1155 - val_loss: 4780.1421 - val_gain_tf: -0.0274\n",
      "Epoch 242/500\n",
      "768/768 [==============================] - 0s 316us/step - loss: 4932.6636 - gain_tf: -0.1151 - val_loss: 4772.7823 - val_gain_tf: -0.0270\n",
      "Epoch 243/500\n",
      "768/768 [==============================] - 0s 324us/step - loss: 4925.0381 - gain_tf: -0.1147 - val_loss: 4765.3499 - val_gain_tf: -0.0267\n",
      "Epoch 244/500\n",
      "768/768 [==============================] - 0s 308us/step - loss: 4917.3401 - gain_tf: -0.1142 - val_loss: 4758.0271 - val_gain_tf: -0.0263\n",
      "Epoch 245/500\n",
      "768/768 [==============================] - 0s 344us/step - loss: 4909.7708 - gain_tf: -0.1138 - val_loss: 4750.5512 - val_gain_tf: -0.0259\n",
      "Epoch 246/500\n",
      "768/768 [==============================] - 0s 334us/step - loss: 4902.0571 - gain_tf: -0.1133 - val_loss: 4743.2696 - val_gain_tf: -0.0255\n",
      "Epoch 247/500\n",
      "768/768 [==============================] - 0s 372us/step - loss: 4894.5183 - gain_tf: -0.1129 - val_loss: 4735.8162 - val_gain_tf: -0.0251\n",
      "Epoch 248/500\n",
      "768/768 [==============================] - 0s 332us/step - loss: 4886.8224 - gain_tf: -0.1124 - val_loss: 4728.5678 - val_gain_tf: -0.0247\n",
      "Epoch 249/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 4879.2929 - gain_tf: -0.1120 - val_loss: 4721.1727 - val_gain_tf: -0.0243\n",
      "Epoch 250/500\n",
      "768/768 [==============================] - 0s 283us/step - loss: 4871.6609 - gain_tf: -0.1116 - val_loss: 4713.8860 - val_gain_tf: -0.0239\n",
      "Epoch 251/500\n",
      "768/768 [==============================] - 0s 354us/step - loss: 4864.1097 - gain_tf: -0.1112 - val_loss: 4706.5543 - val_gain_tf: -0.0236\n",
      "Epoch 252/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 4856.4701 - gain_tf: -0.1107 - val_loss: 4699.4035 - val_gain_tf: -0.0232\n",
      "Epoch 253/500\n",
      "768/768 [==============================] - 0s 373us/step - loss: 4849.0421 - gain_tf: -0.1103 - val_loss: 4691.9662 - val_gain_tf: -0.0228\n",
      "Epoch 254/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 4841.4160 - gain_tf: -0.1098 - val_loss: 4684.7278 - val_gain_tf: -0.0224\n",
      "Epoch 255/500\n",
      "768/768 [==============================] - 0s 307us/step - loss: 4833.9138 - gain_tf: -0.1094 - val_loss: 4677.4311 - val_gain_tf: -0.0220\n",
      "Epoch 256/500\n",
      "768/768 [==============================] - 0s 320us/step - loss: 4826.3283 - gain_tf: -0.1090 - val_loss: 4670.2909 - val_gain_tf: -0.0217\n",
      "Epoch 257/500\n",
      "768/768 [==============================] - 0s 345us/step - loss: 4818.8681 - gain_tf: -0.1085 - val_loss: 4663.0327 - val_gain_tf: -0.0213\n",
      "Epoch 258/500\n",
      "768/768 [==============================] - 0s 358us/step - loss: 4811.3648 - gain_tf: -0.1081 - val_loss: 4655.7895 - val_gain_tf: -0.0209\n",
      "Epoch 259/500\n",
      "768/768 [==============================] - 0s 361us/step - loss: 4803.9142 - gain_tf: -0.1076 - val_loss: 4648.4698 - val_gain_tf: -0.0205\n",
      "Epoch 260/500\n",
      "768/768 [==============================] - 0s 303us/step - loss: 4796.3693 - gain_tf: -0.1072 - val_loss: 4641.3091 - val_gain_tf: -0.0201\n",
      "Epoch 261/500\n",
      "768/768 [==============================] - 0s 330us/step - loss: 4788.9134 - gain_tf: -0.1068 - val_loss: 4634.1240 - val_gain_tf: -0.0198\n",
      "Epoch 262/500\n",
      "768/768 [==============================] - 0s 371us/step - loss: 4781.4717 - gain_tf: -0.1064 - val_loss: 4626.9117 - val_gain_tf: -0.0194\n",
      "Epoch 263/500\n",
      "768/768 [==============================] - 0s 317us/step - loss: 4774.0094 - gain_tf: -0.1059 - val_loss: 4619.7506 - val_gain_tf: -0.0190\n",
      "Epoch 264/500\n",
      "768/768 [==============================] - 0s 310us/step - loss: 4766.5604 - gain_tf: -0.1055 - val_loss: 4612.6238 - val_gain_tf: -0.0186\n",
      "Epoch 265/500\n",
      "768/768 [==============================] - 0s 330us/step - loss: 4759.1829 - gain_tf: -0.1051 - val_loss: 4605.3978 - val_gain_tf: -0.0183\n",
      "Epoch 266/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 4751.7697 - gain_tf: -0.1047 - val_loss: 4598.1920 - val_gain_tf: -0.0179\n",
      "Epoch 267/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 324us/step - loss: 4744.3269 - gain_tf: -0.1042 - val_loss: 4591.0930 - val_gain_tf: -0.0175\n",
      "Epoch 268/500\n",
      "768/768 [==============================] - 0s 326us/step - loss: 4736.9400 - gain_tf: -0.1038 - val_loss: 4583.9961 - val_gain_tf: -0.0171\n",
      "Epoch 269/500\n",
      "768/768 [==============================] - 0s 325us/step - loss: 4729.5605 - gain_tf: -0.1033 - val_loss: 4576.9044 - val_gain_tf: -0.0168\n",
      "Epoch 270/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 4722.1684 - gain_tf: -0.1029 - val_loss: 4569.8767 - val_gain_tf: -0.0164\n",
      "Epoch 271/500\n",
      "768/768 [==============================] - 0s 351us/step - loss: 4714.8413 - gain_tf: -0.1025 - val_loss: 4562.7879 - val_gain_tf: -0.0160\n",
      "Epoch 272/500\n",
      "768/768 [==============================] - 0s 361us/step - loss: 4707.5060 - gain_tf: -0.1020 - val_loss: 4555.6753 - val_gain_tf: -0.0157\n",
      "Epoch 273/500\n",
      "768/768 [==============================] - 0s 331us/step - loss: 4700.1558 - gain_tf: -0.1016 - val_loss: 4548.6002 - val_gain_tf: -0.0153\n",
      "Epoch 274/500\n",
      "768/768 [==============================] - 0s 312us/step - loss: 4692.8353 - gain_tf: -0.1012 - val_loss: 4541.5249 - val_gain_tf: -0.0149\n",
      "Epoch 275/500\n",
      "768/768 [==============================] - 0s 345us/step - loss: 4685.5189 - gain_tf: -0.1007 - val_loss: 4534.4618 - val_gain_tf: -0.0146\n",
      "Epoch 276/500\n",
      "768/768 [==============================] - 0s 376us/step - loss: 4678.1969 - gain_tf: -0.1003 - val_loss: 4527.4531 - val_gain_tf: -0.0142\n",
      "Epoch 277/500\n",
      "768/768 [==============================] - 0s 317us/step - loss: 4670.9180 - gain_tf: -0.0999 - val_loss: 4520.4243 - val_gain_tf: -0.0138\n",
      "Epoch 278/500\n",
      "768/768 [==============================] - 0s 342us/step - loss: 4663.5890 - gain_tf: -0.0994 - val_loss: 4513.5044 - val_gain_tf: -0.0135\n",
      "Epoch 279/500\n",
      "768/768 [==============================] - 0s 315us/step - loss: 4656.3780 - gain_tf: -0.0990 - val_loss: 4506.4539 - val_gain_tf: -0.0131\n",
      "Epoch 280/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 4649.0827 - gain_tf: -0.0986 - val_loss: 4499.4915 - val_gain_tf: -0.0127\n",
      "Epoch 281/500\n",
      "768/768 [==============================] - 0s 301us/step - loss: 4641.8141 - gain_tf: -0.0981 - val_loss: 4492.5817 - val_gain_tf: -0.0124\n",
      "Epoch 282/500\n",
      "768/768 [==============================] - 0s 376us/step - loss: 4634.6481 - gain_tf: -0.0977 - val_loss: 4485.5106 - val_gain_tf: -0.0120\n",
      "Epoch 283/500\n",
      "768/768 [==============================] - 0s 346us/step - loss: 4627.3567 - gain_tf: -0.0973 - val_loss: 4478.5985 - val_gain_tf: -0.0116\n",
      "Epoch 284/500\n",
      "768/768 [==============================] - 0s 309us/step - loss: 4620.1858 - gain_tf: -0.0968 - val_loss: 4471.5898 - val_gain_tf: -0.0113\n",
      "Epoch 285/500\n",
      "768/768 [==============================] - 0s 322us/step - loss: 4612.9588 - gain_tf: -0.0964 - val_loss: 4464.6455 - val_gain_tf: -0.0109\n",
      "Epoch 286/500\n",
      "768/768 [==============================] - 0s 317us/step - loss: 4605.6820 - gain_tf: -0.0960 - val_loss: 4457.8965 - val_gain_tf: -0.0106\n",
      "Epoch 287/500\n",
      "768/768 [==============================] - 0s 308us/step - loss: 4598.6179 - gain_tf: -0.0955 - val_loss: 4450.8706 - val_gain_tf: -0.0102\n",
      "Epoch 288/500\n",
      "768/768 [==============================] - 0s 358us/step - loss: 4591.3701 - gain_tf: -0.0951 - val_loss: 4444.0222 - val_gain_tf: -0.0098\n",
      "Epoch 289/500\n",
      "768/768 [==============================] - 0s 332us/step - loss: 4584.2766 - gain_tf: -0.0946 - val_loss: 4437.0372 - val_gain_tf: -0.0095\n",
      "Epoch 290/500\n",
      "768/768 [==============================] - 0s 308us/step - loss: 4577.0716 - gain_tf: -0.0942 - val_loss: 4430.1764 - val_gain_tf: -0.0091\n",
      "Epoch 291/500\n",
      "768/768 [==============================] - 0s 334us/step - loss: 4569.9406 - gain_tf: -0.0938 - val_loss: 4423.3099 - val_gain_tf: -0.0088\n",
      "Epoch 292/500\n",
      "768/768 [==============================] - 0s 312us/step - loss: 4562.7934 - gain_tf: -0.0934 - val_loss: 4416.5020 - val_gain_tf: -0.0084\n",
      "Epoch 293/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 4555.7094 - gain_tf: -0.0929 - val_loss: 4409.6219 - val_gain_tf: -0.0080\n",
      "Epoch 294/500\n",
      "768/768 [==============================] - 0s 355us/step - loss: 4548.5338 - gain_tf: -0.0925 - val_loss: 4402.9176 - val_gain_tf: -0.0077\n",
      "Epoch 295/500\n",
      "768/768 [==============================] - 0s 305us/step - loss: 4541.5350 - gain_tf: -0.0921 - val_loss: 4395.9853 - val_gain_tf: -0.0073\n",
      "Epoch 296/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 4534.4051 - gain_tf: -0.0916 - val_loss: 4389.1778 - val_gain_tf: -0.0070\n",
      "Epoch 297/500\n",
      "768/768 [==============================] - 0s 358us/step - loss: 4527.3544 - gain_tf: -0.0912 - val_loss: 4382.3279 - val_gain_tf: -0.0066\n",
      "Epoch 298/500\n",
      "768/768 [==============================] - 0s 309us/step - loss: 4520.2330 - gain_tf: -0.0908 - val_loss: 4375.6184 - val_gain_tf: -0.0063\n",
      "Epoch 299/500\n",
      "768/768 [==============================] - 0s 311us/step - loss: 4513.1628 - gain_tf: -0.0903 - val_loss: 4368.9678 - val_gain_tf: -0.0059\n",
      "Epoch 300/500\n",
      "768/768 [==============================] - 0s 342us/step - loss: 4506.2028 - gain_tf: -0.0899 - val_loss: 4362.1296 - val_gain_tf: -0.0056\n",
      "Epoch 301/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 4499.1678 - gain_tf: -0.0895 - val_loss: 4355.3109 - val_gain_tf: -0.0052\n",
      "Epoch 302/500\n",
      "768/768 [==============================] - 0s 338us/step - loss: 4492.1559 - gain_tf: -0.0890 - val_loss: 4348.4944 - val_gain_tf: -0.0048\n",
      "Epoch 303/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 4485.0610 - gain_tf: -0.0886 - val_loss: 4341.8863 - val_gain_tf: -0.0045\n",
      "Epoch 304/500\n",
      "768/768 [==============================] - 0s 341us/step - loss: 4478.1052 - gain_tf: -0.0882 - val_loss: 4335.1791 - val_gain_tf: -0.0042\n",
      "Epoch 305/500\n",
      "768/768 [==============================] - 0s 338us/step - loss: 4471.1107 - gain_tf: -0.0877 - val_loss: 4328.5126 - val_gain_tf: -0.0038\n",
      "Epoch 306/500\n",
      "768/768 [==============================] - 0s 331us/step - loss: 4464.1347 - gain_tf: -0.0873 - val_loss: 4321.8391 - val_gain_tf: -0.0035\n",
      "Epoch 307/500\n",
      "768/768 [==============================] - 0s 320us/step - loss: 4457.2619 - gain_tf: -0.0868 - val_loss: 4314.9656 - val_gain_tf: -0.0031\n",
      "Epoch 308/500\n",
      "768/768 [==============================] - 0s 335us/step - loss: 4450.2198 - gain_tf: -0.0864 - val_loss: 4308.3021 - val_gain_tf: -0.0028\n",
      "Epoch 309/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 4443.2266 - gain_tf: -0.0860 - val_loss: 4301.7629 - val_gain_tf: -0.0024\n",
      "Epoch 310/500\n",
      "768/768 [==============================] - 0s 326us/step - loss: 4436.3680 - gain_tf: -0.0856 - val_loss: 4295.0606 - val_gain_tf: -0.0021\n",
      "Epoch 311/500\n",
      "768/768 [==============================] - 0s 334us/step - loss: 4429.4115 - gain_tf: -0.0851 - val_loss: 4288.4452 - val_gain_tf: -0.0017\n",
      "Epoch 312/500\n",
      "768/768 [==============================] - 0s 368us/step - loss: 4422.4979 - gain_tf: -0.0847 - val_loss: 4281.8428 - val_gain_tf: -0.0014\n",
      "Epoch 313/500\n",
      "768/768 [==============================] - 0s 322us/step - loss: 4415.6249 - gain_tf: -0.0842 - val_loss: 4275.1813 - val_gain_tf: -0.0010\n",
      "Epoch 314/500\n",
      "768/768 [==============================] - 0s 303us/step - loss: 4408.7222 - gain_tf: -0.0838 - val_loss: 4268.5566 - val_gain_tf: -6.8054e-04\n",
      "Epoch 315/500\n",
      "768/768 [==============================] - 0s 373us/step - loss: 4401.8272 - gain_tf: -0.0834 - val_loss: 4261.9789 - val_gain_tf: -3.3730e-04\n",
      "Epoch 316/500\n",
      "768/768 [==============================] - 0s 367us/step - loss: 4394.9658 - gain_tf: -0.0829 - val_loss: 4255.3899 - val_gain_tf: 6.5593e-06\n",
      "Epoch 317/500\n",
      "768/768 [==============================] - 0s 345us/step - loss: 4388.0924 - gain_tf: -0.0825 - val_loss: 4248.8457 - val_gain_tf: 3.4831e-04\n",
      "Epoch 318/500\n",
      "768/768 [==============================] - 0s 289us/step - loss: 4381.2570 - gain_tf: -0.0821 - val_loss: 4242.2783 - val_gain_tf: 6.9133e-04\n",
      "Epoch 319/500\n",
      "768/768 [==============================] - 0s 335us/step - loss: 4374.4050 - gain_tf: -0.0817 - val_loss: 4235.7529 - val_gain_tf: 0.0010\n",
      "Epoch 320/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 281us/step - loss: 4367.6036 - gain_tf: -0.0812 - val_loss: 4229.1744 - val_gain_tf: 0.0014\n",
      "Epoch 321/500\n",
      "768/768 [==============================] - 0s 325us/step - loss: 4360.7838 - gain_tf: -0.0808 - val_loss: 4222.6181 - val_gain_tf: 0.0017\n",
      "Epoch 322/500\n",
      "768/768 [==============================] - 0s 310us/step - loss: 4353.9449 - gain_tf: -0.0804 - val_loss: 4216.1500 - val_gain_tf: 0.0021\n",
      "Epoch 323/500\n",
      "768/768 [==============================] - 0s 364us/step - loss: 4347.2022 - gain_tf: -0.0799 - val_loss: 4209.5743 - val_gain_tf: 0.0024\n",
      "Epoch 324/500\n",
      "768/768 [==============================] - 0s 304us/step - loss: 4340.3847 - gain_tf: -0.0795 - val_loss: 4203.0872 - val_gain_tf: 0.0027\n",
      "Epoch 325/500\n",
      "768/768 [==============================] - 0s 334us/step - loss: 4333.6011 - gain_tf: -0.0790 - val_loss: 4196.6281 - val_gain_tf: 0.0031\n",
      "Epoch 326/500\n",
      "768/768 [==============================] - 0s 328us/step - loss: 4326.8425 - gain_tf: -0.0786 - val_loss: 4190.1793 - val_gain_tf: 0.0034\n",
      "Epoch 327/500\n",
      "768/768 [==============================] - 0s 332us/step - loss: 4320.0762 - gain_tf: -0.0782 - val_loss: 4183.7642 - val_gain_tf: 0.0037\n",
      "Epoch 328/500\n",
      "768/768 [==============================] - 0s 335us/step - loss: 4313.4264 - gain_tf: -0.0777 - val_loss: 4177.1721 - val_gain_tf: 0.0041\n",
      "Epoch 329/500\n",
      "768/768 [==============================] - 0s 343us/step - loss: 4306.6042 - gain_tf: -0.0773 - val_loss: 4170.7976 - val_gain_tf: 0.0044\n",
      "Epoch 330/500\n",
      "768/768 [==============================] - 0s 350us/step - loss: 4299.9128 - gain_tf: -0.0769 - val_loss: 4164.3765 - val_gain_tf: 0.0048\n",
      "Epoch 331/500\n",
      "768/768 [==============================] - 0s 334us/step - loss: 4293.2381 - gain_tf: -0.0765 - val_loss: 4157.8961 - val_gain_tf: 0.0051\n",
      "Epoch 332/500\n",
      "768/768 [==============================] - 0s 313us/step - loss: 4286.5335 - gain_tf: -0.0761 - val_loss: 4151.4489 - val_gain_tf: 0.0054\n",
      "Epoch 333/500\n",
      "768/768 [==============================] - 0s 323us/step - loss: 4279.8197 - gain_tf: -0.0756 - val_loss: 4145.0824 - val_gain_tf: 0.0058\n",
      "Epoch 334/500\n",
      "768/768 [==============================] - 0s 367us/step - loss: 4273.1227 - gain_tf: -0.0751 - val_loss: 4138.7815 - val_gain_tf: 0.0061\n",
      "Epoch 335/500\n",
      "768/768 [==============================] - 0s 307us/step - loss: 4266.5764 - gain_tf: -0.0747 - val_loss: 4132.2422 - val_gain_tf: 0.0064\n",
      "Epoch 336/500\n",
      "768/768 [==============================] - 0s 340us/step - loss: 4259.8702 - gain_tf: -0.0743 - val_loss: 4125.8443 - val_gain_tf: 0.0068\n",
      "Epoch 337/500\n",
      "768/768 [==============================] - 0s 295us/step - loss: 4253.1373 - gain_tf: -0.0738 - val_loss: 4119.6532 - val_gain_tf: 0.0071\n",
      "Epoch 338/500\n",
      "768/768 [==============================] - 0s 298us/step - loss: 4246.6111 - gain_tf: -0.0734 - val_loss: 4113.2345 - val_gain_tf: 0.0074\n",
      "Epoch 339/500\n",
      "768/768 [==============================] - 0s 318us/step - loss: 4239.9423 - gain_tf: -0.0730 - val_loss: 4106.9455 - val_gain_tf: 0.0078\n",
      "Epoch 340/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 4233.3582 - gain_tf: -0.0725 - val_loss: 4100.6001 - val_gain_tf: 0.0081\n",
      "Epoch 341/500\n",
      "768/768 [==============================] - 0s 324us/step - loss: 4226.7704 - gain_tf: -0.0721 - val_loss: 4094.2557 - val_gain_tf: 0.0084\n",
      "Epoch 342/500\n",
      "768/768 [==============================] - 0s 335us/step - loss: 4220.1299 - gain_tf: -0.0716 - val_loss: 4088.0398 - val_gain_tf: 0.0088\n",
      "Epoch 343/500\n",
      "768/768 [==============================] - 0s 313us/step - loss: 4213.5930 - gain_tf: -0.0712 - val_loss: 4081.7302 - val_gain_tf: 0.0091\n",
      "Epoch 344/500\n",
      "768/768 [==============================] - 0s 323us/step - loss: 4207.0521 - gain_tf: -0.0708 - val_loss: 4075.3802 - val_gain_tf: 0.0094\n",
      "Epoch 345/500\n",
      "768/768 [==============================] - 0s 309us/step - loss: 4200.4291 - gain_tf: -0.0704 - val_loss: 4069.1886 - val_gain_tf: 0.0098\n",
      "Epoch 346/500\n",
      "768/768 [==============================] - 0s 318us/step - loss: 4193.9473 - gain_tf: -0.0699 - val_loss: 4062.8623 - val_gain_tf: 0.0101\n",
      "Epoch 347/500\n",
      "768/768 [==============================] - 0s 325us/step - loss: 4187.3781 - gain_tf: -0.0695 - val_loss: 4056.6332 - val_gain_tf: 0.0104\n",
      "Epoch 348/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 4180.8232 - gain_tf: -0.0691 - val_loss: 4050.4749 - val_gain_tf: 0.0108\n",
      "Epoch 349/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 4174.3390 - gain_tf: -0.0686 - val_loss: 4044.2650 - val_gain_tf: 0.0111\n",
      "Epoch 350/500\n",
      "768/768 [==============================] - 0s 307us/step - loss: 4167.8672 - gain_tf: -0.0682 - val_loss: 4037.9854 - val_gain_tf: 0.0114\n",
      "Epoch 351/500\n",
      "768/768 [==============================] - 0s 330us/step - loss: 4161.3586 - gain_tf: -0.0678 - val_loss: 4031.7564 - val_gain_tf: 0.0117\n",
      "Epoch 352/500\n",
      "768/768 [==============================] - 0s 335us/step - loss: 4154.8545 - gain_tf: -0.0673 - val_loss: 4025.5903 - val_gain_tf: 0.0121\n",
      "Epoch 353/500\n",
      "768/768 [==============================] - 0s 323us/step - loss: 4148.4197 - gain_tf: -0.0669 - val_loss: 4019.3558 - val_gain_tf: 0.0124\n",
      "Epoch 354/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 4141.9018 - gain_tf: -0.0665 - val_loss: 4013.2551 - val_gain_tf: 0.0127\n",
      "Epoch 355/500\n",
      "768/768 [==============================] - 0s 356us/step - loss: 4135.4269 - gain_tf: -0.0660 - val_loss: 4007.2253 - val_gain_tf: 0.0130\n",
      "Epoch 356/500\n",
      "768/768 [==============================] - 0s 307us/step - loss: 4129.1236 - gain_tf: -0.0656 - val_loss: 4000.8933 - val_gain_tf: 0.0134\n",
      "Epoch 357/500\n",
      "768/768 [==============================] - 0s 347us/step - loss: 4122.6015 - gain_tf: -0.0651 - val_loss: 3994.7851 - val_gain_tf: 0.0137\n",
      "Epoch 358/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 4116.1809 - gain_tf: -0.0647 - val_loss: 3988.6919 - val_gain_tf: 0.0140\n",
      "Epoch 359/500\n",
      "768/768 [==============================] - 0s 356us/step - loss: 4109.7891 - gain_tf: -0.0643 - val_loss: 3982.5734 - val_gain_tf: 0.0143\n",
      "Epoch 360/500\n",
      "768/768 [==============================] - 0s 319us/step - loss: 4103.3814 - gain_tf: -0.0639 - val_loss: 3976.4839 - val_gain_tf: 0.0147\n",
      "Epoch 361/500\n",
      "768/768 [==============================] - 0s 309us/step - loss: 4097.0545 - gain_tf: -0.0634 - val_loss: 3970.2976 - val_gain_tf: 0.0150\n",
      "Epoch 362/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 4090.5728 - gain_tf: -0.0630 - val_loss: 3964.3547 - val_gain_tf: 0.0153\n",
      "Epoch 363/500\n",
      "768/768 [==============================] - 0s 350us/step - loss: 4084.2787 - gain_tf: -0.0625 - val_loss: 3958.2555 - val_gain_tf: 0.0156\n",
      "Epoch 364/500\n",
      "768/768 [==============================] - 0s 343us/step - loss: 4077.9424 - gain_tf: -0.0621 - val_loss: 3952.1190 - val_gain_tf: 0.0160\n",
      "Epoch 365/500\n",
      "768/768 [==============================] - 0s 344us/step - loss: 4071.5382 - gain_tf: -0.0616 - val_loss: 3946.1348 - val_gain_tf: 0.0163\n",
      "Epoch 366/500\n",
      "768/768 [==============================] - 0s 348us/step - loss: 4065.2457 - gain_tf: -0.0612 - val_loss: 3940.0672 - val_gain_tf: 0.0166\n",
      "Epoch 367/500\n",
      "768/768 [==============================] - 0s 346us/step - loss: 4058.8957 - gain_tf: -0.0608 - val_loss: 3934.0781 - val_gain_tf: 0.0169\n",
      "Epoch 368/500\n",
      "768/768 [==============================] - 0s 323us/step - loss: 4052.6074 - gain_tf: -0.0604 - val_loss: 3928.0276 - val_gain_tf: 0.0173\n",
      "Epoch 369/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 4046.2723 - gain_tf: -0.0599 - val_loss: 3922.0654 - val_gain_tf: 0.0176\n",
      "Epoch 370/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 4040.0329 - gain_tf: -0.0595 - val_loss: 3915.9908 - val_gain_tf: 0.0179\n",
      "Epoch 371/500\n",
      "768/768 [==============================] - 0s 367us/step - loss: 4033.7469 - gain_tf: -0.0590 - val_loss: 3909.9473 - val_gain_tf: 0.0182\n",
      "Epoch 372/500\n",
      "768/768 [==============================] - 0s 308us/step - loss: 4027.4097 - gain_tf: -0.0586 - val_loss: 3904.0677 - val_gain_tf: 0.0185\n",
      "Epoch 373/500\n",
      "768/768 [==============================] - 0s 368us/step - loss: 4021.1494 - gain_tf: -0.0582 - val_loss: 3898.2017 - val_gain_tf: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/500\n",
      "768/768 [==============================] - 0s 311us/step - loss: 4014.9757 - gain_tf: -0.0578 - val_loss: 3892.1656 - val_gain_tf: 0.0192\n",
      "Epoch 375/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 4008.7156 - gain_tf: -0.0573 - val_loss: 3886.1956 - val_gain_tf: 0.0195\n",
      "Epoch 376/500\n",
      "768/768 [==============================] - 0s 330us/step - loss: 4002.4848 - gain_tf: -0.0569 - val_loss: 3880.2523 - val_gain_tf: 0.0198\n",
      "Epoch 377/500\n",
      "768/768 [==============================] - 0s 344us/step - loss: 3996.2499 - gain_tf: -0.0565 - val_loss: 3874.3543 - val_gain_tf: 0.0201\n",
      "Epoch 378/500\n",
      "768/768 [==============================] - 0s 348us/step - loss: 3990.0842 - gain_tf: -0.0560 - val_loss: 3868.3873 - val_gain_tf: 0.0205\n",
      "Epoch 379/500\n",
      "768/768 [==============================] - 0s 317us/step - loss: 3983.8251 - gain_tf: -0.0556 - val_loss: 3862.5790 - val_gain_tf: 0.0208\n",
      "Epoch 380/500\n",
      "768/768 [==============================] - 0s 318us/step - loss: 3977.6760 - gain_tf: -0.0551 - val_loss: 3856.7019 - val_gain_tf: 0.0211\n",
      "Epoch 381/500\n",
      "768/768 [==============================] - 0s 342us/step - loss: 3971.5156 - gain_tf: -0.0547 - val_loss: 3850.8074 - val_gain_tf: 0.0214\n",
      "Epoch 382/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 3965.3781 - gain_tf: -0.0543 - val_loss: 3844.8686 - val_gain_tf: 0.0217\n",
      "Epoch 383/500\n",
      "768/768 [==============================] - 0s 314us/step - loss: 3959.1700 - gain_tf: -0.0538 - val_loss: 3839.0722 - val_gain_tf: 0.0220\n",
      "Epoch 384/500\n",
      "768/768 [==============================] - 0s 353us/step - loss: 3953.1064 - gain_tf: -0.0534 - val_loss: 3833.1272 - val_gain_tf: 0.0224\n",
      "Epoch 385/500\n",
      "768/768 [==============================] - 0s 316us/step - loss: 3946.8497 - gain_tf: -0.0530 - val_loss: 3827.4807 - val_gain_tf: 0.0227\n",
      "Epoch 386/500\n",
      "768/768 [==============================] - 0s 325us/step - loss: 3940.8881 - gain_tf: -0.0526 - val_loss: 3821.4871 - val_gain_tf: 0.0230\n",
      "Epoch 387/500\n",
      "768/768 [==============================] - 0s 344us/step - loss: 3934.6612 - gain_tf: -0.0521 - val_loss: 3815.7791 - val_gain_tf: 0.0233\n",
      "Epoch 388/500\n",
      "768/768 [==============================] - 0s 317us/step - loss: 3928.5973 - gain_tf: -0.0517 - val_loss: 3809.9918 - val_gain_tf: 0.0236\n",
      "Epoch 389/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 3922.5767 - gain_tf: -0.0512 - val_loss: 3804.0855 - val_gain_tf: 0.0239\n",
      "Epoch 390/500\n",
      "768/768 [==============================] - 0s 297us/step - loss: 3916.4018 - gain_tf: -0.0508 - val_loss: 3798.4044 - val_gain_tf: 0.0242\n",
      "Epoch 391/500\n",
      "768/768 [==============================] - 0s 343us/step - loss: 3910.3540 - gain_tf: -0.0504 - val_loss: 3792.6878 - val_gain_tf: 0.0246\n",
      "Epoch 392/500\n",
      "768/768 [==============================] - 0s 312us/step - loss: 3904.3678 - gain_tf: -0.0499 - val_loss: 3786.8286 - val_gain_tf: 0.0249\n",
      "Epoch 393/500\n",
      "768/768 [==============================] - 0s 336us/step - loss: 3898.2988 - gain_tf: -0.0495 - val_loss: 3781.0442 - val_gain_tf: 0.0252\n",
      "Epoch 394/500\n",
      "768/768 [==============================] - 0s 328us/step - loss: 3892.2213 - gain_tf: -0.0490 - val_loss: 3775.3564 - val_gain_tf: 0.0255\n",
      "Epoch 395/500\n",
      "768/768 [==============================] - 0s 343us/step - loss: 3886.2184 - gain_tf: -0.0486 - val_loss: 3769.6395 - val_gain_tf: 0.0258\n",
      "Epoch 396/500\n",
      "768/768 [==============================] - 0s 322us/step - loss: 3880.1940 - gain_tf: -0.0482 - val_loss: 3763.9563 - val_gain_tf: 0.0261\n",
      "Epoch 397/500\n",
      "768/768 [==============================] - 0s 352us/step - loss: 3874.2216 - gain_tf: -0.0478 - val_loss: 3758.2110 - val_gain_tf: 0.0265\n",
      "Epoch 398/500\n",
      "768/768 [==============================] - 0s 298us/step - loss: 3868.2403 - gain_tf: -0.0473 - val_loss: 3752.4644 - val_gain_tf: 0.0268\n",
      "Epoch 399/500\n",
      "768/768 [==============================] - 0s 295us/step - loss: 3862.2196 - gain_tf: -0.0469 - val_loss: 3746.8156 - val_gain_tf: 0.0271\n",
      "Epoch 400/500\n",
      "768/768 [==============================] - 0s 333us/step - loss: 3856.2242 - gain_tf: -0.0464 - val_loss: 3741.2357 - val_gain_tf: 0.0274\n",
      "Epoch 401/500\n",
      "768/768 [==============================] - 0s 340us/step - loss: 3850.3071 - gain_tf: -0.0460 - val_loss: 3735.5634 - val_gain_tf: 0.0277\n",
      "Epoch 402/500\n",
      "768/768 [==============================] - 0s 297us/step - loss: 3844.3426 - gain_tf: -0.0456 - val_loss: 3729.9398 - val_gain_tf: 0.0280\n",
      "Epoch 403/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 3838.4465 - gain_tf: -0.0451 - val_loss: 3724.2425 - val_gain_tf: 0.0283\n",
      "Epoch 404/500\n",
      "768/768 [==============================] - 0s 324us/step - loss: 3832.4599 - gain_tf: -0.0447 - val_loss: 3718.6878 - val_gain_tf: 0.0286\n",
      "Epoch 405/500\n",
      "768/768 [==============================] - 0s 342us/step - loss: 3826.5821 - gain_tf: -0.0443 - val_loss: 3713.0476 - val_gain_tf: 0.0289\n",
      "Epoch 406/500\n",
      "768/768 [==============================] - 0s 312us/step - loss: 3820.6532 - gain_tf: -0.0438 - val_loss: 3707.4644 - val_gain_tf: 0.0293\n",
      "Epoch 407/500\n",
      "768/768 [==============================] - 0s 315us/step - loss: 3814.7907 - gain_tf: -0.0434 - val_loss: 3701.8203 - val_gain_tf: 0.0296\n",
      "Epoch 408/500\n",
      "768/768 [==============================] - 0s 317us/step - loss: 3808.8721 - gain_tf: -0.0429 - val_loss: 3696.2569 - val_gain_tf: 0.0299\n",
      "Epoch 409/500\n",
      "768/768 [==============================] - 0s 334us/step - loss: 3803.0054 - gain_tf: -0.0425 - val_loss: 3690.6819 - val_gain_tf: 0.0302\n",
      "Epoch 410/500\n",
      "768/768 [==============================] - 0s 344us/step - loss: 3797.1361 - gain_tf: -0.0420 - val_loss: 3685.1273 - val_gain_tf: 0.0305\n",
      "Epoch 411/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 3791.2897 - gain_tf: -0.0416 - val_loss: 3679.5620 - val_gain_tf: 0.0308\n",
      "Epoch 412/500\n",
      "768/768 [==============================] - 0s 327us/step - loss: 3785.4607 - gain_tf: -0.0412 - val_loss: 3673.9774 - val_gain_tf: 0.0311\n",
      "Epoch 413/500\n",
      "768/768 [==============================] - 0s 340us/step - loss: 3779.6012 - gain_tf: -0.0407 - val_loss: 3668.4599 - val_gain_tf: 0.0314\n",
      "Epoch 414/500\n",
      "768/768 [==============================] - 0s 299us/step - loss: 3773.8006 - gain_tf: -0.0403 - val_loss: 3662.9089 - val_gain_tf: 0.0317\n",
      "Epoch 415/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 3767.9820 - gain_tf: -0.0399 - val_loss: 3657.3871 - val_gain_tf: 0.0321\n",
      "Epoch 416/500\n",
      "768/768 [==============================] - 0s 335us/step - loss: 3762.1171 - gain_tf: -0.0394 - val_loss: 3652.0156 - val_gain_tf: 0.0324\n",
      "Epoch 417/500\n",
      "768/768 [==============================] - 0s 309us/step - loss: 3756.3872 - gain_tf: -0.0390 - val_loss: 3646.5140 - val_gain_tf: 0.0327\n",
      "Epoch 418/500\n",
      "768/768 [==============================] - 0s 330us/step - loss: 3750.6095 - gain_tf: -0.0386 - val_loss: 3641.0203 - val_gain_tf: 0.0330\n",
      "Epoch 419/500\n",
      "768/768 [==============================] - 0s 338us/step - loss: 3744.8324 - gain_tf: -0.0381 - val_loss: 3635.5494 - val_gain_tf: 0.0333\n",
      "Epoch 420/500\n",
      "768/768 [==============================] - 0s 343us/step - loss: 3739.0645 - gain_tf: -0.0377 - val_loss: 3630.1154 - val_gain_tf: 0.0336\n",
      "Epoch 421/500\n",
      "768/768 [==============================] - 0s 319us/step - loss: 3733.3462 - gain_tf: -0.0373 - val_loss: 3624.6242 - val_gain_tf: 0.0339\n",
      "Epoch 422/500\n",
      "768/768 [==============================] - 0s 352us/step - loss: 3727.5849 - gain_tf: -0.0368 - val_loss: 3619.1899 - val_gain_tf: 0.0342\n",
      "Epoch 423/500\n",
      "768/768 [==============================] - 0s 330us/step - loss: 3721.8397 - gain_tf: -0.0364 - val_loss: 3613.8092 - val_gain_tf: 0.0345\n",
      "Epoch 424/500\n",
      "768/768 [==============================] - 0s 297us/step - loss: 3716.0973 - gain_tf: -0.0360 - val_loss: 3608.4951 - val_gain_tf: 0.0348\n",
      "Epoch 425/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 3710.4879 - gain_tf: -0.0355 - val_loss: 3602.9645 - val_gain_tf: 0.0351\n",
      "Epoch 426/500\n",
      "768/768 [==============================] - 0s 311us/step - loss: 3704.7697 - gain_tf: -0.0351 - val_loss: 3597.5019 - val_gain_tf: 0.0355\n",
      "Epoch 427/500\n",
      "768/768 [==============================] - 0s 313us/step - loss: 3699.0237 - gain_tf: -0.0346 - val_loss: 3592.1720 - val_gain_tf: 0.0358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/500\n",
      "768/768 [==============================] - 0s 318us/step - loss: 3693.3832 - gain_tf: -0.0342 - val_loss: 3586.7836 - val_gain_tf: 0.0361\n",
      "Epoch 429/500\n",
      "768/768 [==============================] - 0s 318us/step - loss: 3687.7147 - gain_tf: -0.0337 - val_loss: 3581.4157 - val_gain_tf: 0.0364\n",
      "Epoch 430/500\n",
      "768/768 [==============================] - 0s 320us/step - loss: 3682.0244 - gain_tf: -0.0333 - val_loss: 3576.1359 - val_gain_tf: 0.0367\n",
      "Epoch 431/500\n",
      "768/768 [==============================] - 0s 326us/step - loss: 3676.4340 - gain_tf: -0.0329 - val_loss: 3570.7578 - val_gain_tf: 0.0370\n",
      "Epoch 432/500\n",
      "768/768 [==============================] - 0s 372us/step - loss: 3670.7704 - gain_tf: -0.0324 - val_loss: 3565.4604 - val_gain_tf: 0.0373\n",
      "Epoch 433/500\n",
      "768/768 [==============================] - 0s 307us/step - loss: 3665.1790 - gain_tf: -0.0320 - val_loss: 3560.1144 - val_gain_tf: 0.0376\n",
      "Epoch 434/500\n",
      "768/768 [==============================] - 0s 306us/step - loss: 3659.5307 - gain_tf: -0.0316 - val_loss: 3554.8473 - val_gain_tf: 0.0379\n",
      "Epoch 435/500\n",
      "768/768 [==============================] - 0s 335us/step - loss: 3653.9488 - gain_tf: -0.0311 - val_loss: 3549.5527 - val_gain_tf: 0.0382\n",
      "Epoch 436/500\n",
      "768/768 [==============================] - 0s 318us/step - loss: 3648.3497 - gain_tf: -0.0307 - val_loss: 3544.2909 - val_gain_tf: 0.0385\n",
      "Epoch 437/500\n",
      "768/768 [==============================] - 0s 341us/step - loss: 3642.7863 - gain_tf: -0.0302 - val_loss: 3538.9936 - val_gain_tf: 0.0388\n",
      "Epoch 438/500\n",
      "768/768 [==============================] - 0s 330us/step - loss: 3637.1632 - gain_tf: -0.0298 - val_loss: 3533.8307 - val_gain_tf: 0.0391\n",
      "Epoch 439/500\n",
      "768/768 [==============================] - 0s 341us/step - loss: 3631.7038 - gain_tf: -0.0294 - val_loss: 3528.4466 - val_gain_tf: 0.0394\n",
      "Epoch 440/500\n",
      "768/768 [==============================] - 0s 332us/step - loss: 3626.1025 - gain_tf: -0.0289 - val_loss: 3523.1964 - val_gain_tf: 0.0398\n",
      "Epoch 441/500\n",
      "768/768 [==============================] - 0s 326us/step - loss: 3620.4889 - gain_tf: -0.0285 - val_loss: 3518.1278 - val_gain_tf: 0.0401\n",
      "Epoch 442/500\n",
      "768/768 [==============================] - 0s 285us/step - loss: 3615.0444 - gain_tf: -0.0281 - val_loss: 3512.8579 - val_gain_tf: 0.0404\n",
      "Epoch 443/500\n",
      "768/768 [==============================] - 0s 319us/step - loss: 3609.5562 - gain_tf: -0.0276 - val_loss: 3507.5363 - val_gain_tf: 0.0407\n",
      "Epoch 444/500\n",
      "768/768 [==============================] - 0s 318us/step - loss: 3603.9656 - gain_tf: -0.0272 - val_loss: 3502.4178 - val_gain_tf: 0.0410\n",
      "Epoch 445/500\n",
      "768/768 [==============================] - 0s 382us/step - loss: 3598.4835 - gain_tf: -0.0267 - val_loss: 3497.2666 - val_gain_tf: 0.0413\n",
      "Epoch 446/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 3593.0468 - gain_tf: -0.0263 - val_loss: 3492.0034 - val_gain_tf: 0.0416\n",
      "Epoch 447/500\n",
      "768/768 [==============================] - 0s 284us/step - loss: 3587.4892 - gain_tf: -0.0258 - val_loss: 3486.9414 - val_gain_tf: 0.0419\n",
      "Epoch 448/500\n",
      "768/768 [==============================] - 0s 345us/step - loss: 3582.1436 - gain_tf: -0.0254 - val_loss: 3481.6274 - val_gain_tf: 0.0422\n",
      "Epoch 449/500\n",
      "768/768 [==============================] - 0s 317us/step - loss: 3576.6367 - gain_tf: -0.0250 - val_loss: 3476.4392 - val_gain_tf: 0.0425\n",
      "Epoch 450/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 3571.1078 - gain_tf: -0.0245 - val_loss: 3471.4512 - val_gain_tf: 0.0428\n",
      "Epoch 451/500\n",
      "768/768 [==============================] - 0s 298us/step - loss: 3565.7375 - gain_tf: -0.0241 - val_loss: 3466.3235 - val_gain_tf: 0.0431\n",
      "Epoch 452/500\n",
      "768/768 [==============================] - 0s 311us/step - loss: 3560.2994 - gain_tf: -0.0237 - val_loss: 3461.2358 - val_gain_tf: 0.0434\n",
      "Epoch 453/500\n",
      "768/768 [==============================] - 0s 325us/step - loss: 3554.9125 - gain_tf: -0.0233 - val_loss: 3456.1017 - val_gain_tf: 0.0437\n",
      "Epoch 454/500\n",
      "768/768 [==============================] - 0s 342us/step - loss: 3549.4601 - gain_tf: -0.0228 - val_loss: 3451.0835 - val_gain_tf: 0.0440\n",
      "Epoch 455/500\n",
      "768/768 [==============================] - 0s 275us/step - loss: 3544.1576 - gain_tf: -0.0224 - val_loss: 3445.8698 - val_gain_tf: 0.0443\n",
      "Epoch 456/500\n",
      "768/768 [==============================] - 0s 336us/step - loss: 3538.7232 - gain_tf: -0.0219 - val_loss: 3440.7902 - val_gain_tf: 0.0446\n",
      "Epoch 457/500\n",
      "768/768 [==============================] - 0s 314us/step - loss: 3533.3315 - gain_tf: -0.0215 - val_loss: 3435.7676 - val_gain_tf: 0.0450\n",
      "Epoch 458/500\n",
      "768/768 [==============================] - 0s 336us/step - loss: 3527.9553 - gain_tf: -0.0210 - val_loss: 3430.7813 - val_gain_tf: 0.0453\n",
      "Epoch 459/500\n",
      "768/768 [==============================] - 0s 335us/step - loss: 3522.6823 - gain_tf: -0.0206 - val_loss: 3425.6376 - val_gain_tf: 0.0456\n",
      "Epoch 460/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 3517.2706 - gain_tf: -0.0202 - val_loss: 3420.6654 - val_gain_tf: 0.0459\n",
      "Epoch 461/500\n",
      "768/768 [==============================] - 0s 310us/step - loss: 3511.9217 - gain_tf: -0.0197 - val_loss: 3415.7474 - val_gain_tf: 0.0462\n",
      "Epoch 462/500\n",
      "768/768 [==============================] - 0s 329us/step - loss: 3506.6893 - gain_tf: -0.0193 - val_loss: 3410.6345 - val_gain_tf: 0.0465\n",
      "Epoch 463/500\n",
      "768/768 [==============================] - 0s 315us/step - loss: 3501.3231 - gain_tf: -0.0188 - val_loss: 3405.6596 - val_gain_tf: 0.0468\n",
      "Epoch 464/500\n",
      "768/768 [==============================] - 0s 315us/step - loss: 3496.0395 - gain_tf: -0.0184 - val_loss: 3400.6546 - val_gain_tf: 0.0471\n",
      "Epoch 465/500\n",
      "768/768 [==============================] - 0s 323us/step - loss: 3490.7075 - gain_tf: -0.0180 - val_loss: 3395.7589 - val_gain_tf: 0.0474\n",
      "Epoch 466/500\n",
      "768/768 [==============================] - 0s 294us/step - loss: 3485.4664 - gain_tf: -0.0175 - val_loss: 3390.7798 - val_gain_tf: 0.0477\n",
      "Epoch 467/500\n",
      "768/768 [==============================] - 0s 317us/step - loss: 3480.2439 - gain_tf: -0.0171 - val_loss: 3385.7069 - val_gain_tf: 0.0480\n",
      "Epoch 468/500\n",
      "768/768 [==============================] - 0s 335us/step - loss: 3474.8738 - gain_tf: -0.0167 - val_loss: 3380.8996 - val_gain_tf: 0.0483\n",
      "Epoch 469/500\n",
      "768/768 [==============================] - 0s 347us/step - loss: 3469.7210 - gain_tf: -0.0162 - val_loss: 3375.8757 - val_gain_tf: 0.0486\n",
      "Epoch 470/500\n",
      "768/768 [==============================] - 0s 350us/step - loss: 3464.4388 - gain_tf: -0.0158 - val_loss: 3370.9668 - val_gain_tf: 0.0489\n",
      "Epoch 471/500\n",
      "768/768 [==============================] - 0s 313us/step - loss: 3459.2305 - gain_tf: -0.0153 - val_loss: 3366.0266 - val_gain_tf: 0.0492\n",
      "Epoch 472/500\n",
      "768/768 [==============================] - 0s 304us/step - loss: 3453.9774 - gain_tf: -0.0149 - val_loss: 3361.1755 - val_gain_tf: 0.0495\n",
      "Epoch 473/500\n",
      "768/768 [==============================] - 0s 280us/step - loss: 3448.7539 - gain_tf: -0.0144 - val_loss: 3356.3719 - val_gain_tf: 0.0498\n",
      "Epoch 474/500\n",
      "768/768 [==============================] - 0s 340us/step - loss: 3443.6508 - gain_tf: -0.0140 - val_loss: 3351.3669 - val_gain_tf: 0.0501\n",
      "Epoch 475/500\n",
      "768/768 [==============================] - 0s 331us/step - loss: 3438.4287 - gain_tf: -0.0136 - val_loss: 3346.4572 - val_gain_tf: 0.0504\n",
      "Epoch 476/500\n",
      "768/768 [==============================] - 0s 340us/step - loss: 3433.2173 - gain_tf: -0.0132 - val_loss: 3341.6397 - val_gain_tf: 0.0507\n",
      "Epoch 477/500\n",
      "768/768 [==============================] - 0s 309us/step - loss: 3428.0652 - gain_tf: -0.0127 - val_loss: 3336.8007 - val_gain_tf: 0.0510\n",
      "Epoch 478/500\n",
      "768/768 [==============================] - 0s 349us/step - loss: 3422.9344 - gain_tf: -0.0123 - val_loss: 3331.9388 - val_gain_tf: 0.0514\n",
      "Epoch 479/500\n",
      "768/768 [==============================] - 0s 310us/step - loss: 3417.7740 - gain_tf: -0.0118 - val_loss: 3327.1207 - val_gain_tf: 0.0517\n",
      "Epoch 480/500\n",
      "768/768 [==============================] - 0s 322us/step - loss: 3412.6331 - gain_tf: -0.0114 - val_loss: 3322.3354 - val_gain_tf: 0.0520\n",
      "Epoch 481/500\n",
      "768/768 [==============================] - 0s 343us/step - loss: 3407.4939 - gain_tf: -0.0109 - val_loss: 3317.6074 - val_gain_tf: 0.0523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482/500\n",
      "768/768 [==============================] - 0s 336us/step - loss: 3402.4388 - gain_tf: -0.0105 - val_loss: 3312.7545 - val_gain_tf: 0.0526\n",
      "Epoch 483/500\n",
      "768/768 [==============================] - 0s 311us/step - loss: 3397.3177 - gain_tf: -0.0101 - val_loss: 3307.9660 - val_gain_tf: 0.0529\n",
      "Epoch 484/500\n",
      "768/768 [==============================] - 0s 311us/step - loss: 3392.2254 - gain_tf: -0.0097 - val_loss: 3303.1950 - val_gain_tf: 0.0532\n",
      "Epoch 485/500\n",
      "768/768 [==============================] - 0s 324us/step - loss: 3387.1731 - gain_tf: -0.0092 - val_loss: 3298.3770 - val_gain_tf: 0.0535\n",
      "Epoch 486/500\n",
      "768/768 [==============================] - 0s 330us/step - loss: 3382.0649 - gain_tf: -0.0088 - val_loss: 3293.6682 - val_gain_tf: 0.0538\n",
      "Epoch 487/500\n",
      "768/768 [==============================] - 0s 326us/step - loss: 3377.0432 - gain_tf: -0.0083 - val_loss: 3288.8938 - val_gain_tf: 0.0541\n",
      "Epoch 488/500\n",
      "768/768 [==============================] - 0s 321us/step - loss: 3371.9579 - gain_tf: -0.0079 - val_loss: 3284.2139 - val_gain_tf: 0.0544\n",
      "Epoch 489/500\n",
      "768/768 [==============================] - 0s 309us/step - loss: 3366.9048 - gain_tf: -0.0074 - val_loss: 3279.5956 - val_gain_tf: 0.0547\n",
      "Epoch 490/500\n",
      "768/768 [==============================] - 0s 339us/step - loss: 3361.9407 - gain_tf: -0.0070 - val_loss: 3274.8340 - val_gain_tf: 0.0550\n",
      "Epoch 491/500\n",
      "768/768 [==============================] - 0s 343us/step - loss: 3356.9157 - gain_tf: -0.0066 - val_loss: 3270.0945 - val_gain_tf: 0.0553\n",
      "Epoch 492/500\n",
      "768/768 [==============================] - 0s 324us/step - loss: 3351.8845 - gain_tf: -0.0061 - val_loss: 3265.4265 - val_gain_tf: 0.0556\n",
      "Epoch 493/500\n",
      "768/768 [==============================] - 0s 292us/step - loss: 3346.9112 - gain_tf: -0.0057 - val_loss: 3260.7191 - val_gain_tf: 0.0559\n",
      "Epoch 494/500\n",
      "768/768 [==============================] - 0s 319us/step - loss: 3341.8867 - gain_tf: -0.0053 - val_loss: 3256.1089 - val_gain_tf: 0.0562\n",
      "Epoch 495/500\n",
      "768/768 [==============================] - 0s 308us/step - loss: 3336.9747 - gain_tf: -0.0048 - val_loss: 3251.3725 - val_gain_tf: 0.0565\n",
      "Epoch 496/500\n",
      "768/768 [==============================] - 0s 314us/step - loss: 3331.9615 - gain_tf: -0.0044 - val_loss: 3246.7559 - val_gain_tf: 0.0568\n",
      "Epoch 497/500\n",
      "768/768 [==============================] - 0s 325us/step - loss: 3327.0147 - gain_tf: -0.0040 - val_loss: 3242.1331 - val_gain_tf: 0.0571\n",
      "Epoch 498/500\n",
      "768/768 [==============================] - 0s 353us/step - loss: 3322.1030 - gain_tf: -0.0035 - val_loss: 3237.4565 - val_gain_tf: 0.0574\n",
      "Epoch 499/500\n",
      "768/768 [==============================] - 0s 314us/step - loss: 3317.0709 - gain_tf: -0.0031 - val_loss: 3233.0190 - val_gain_tf: 0.0577\n",
      "Epoch 500/500\n",
      "768/768 [==============================] - 0s 319us/step - loss: 3312.3071 - gain_tf: -0.0027 - val_loss: 3228.2376 - val_gain_tf: 0.0580\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import L1L2\n",
    "\n",
    "reg = L1L2(l1=0.01, l2=0.01)\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='relu', input_dim=x.shape[1]),)# W_regularizer=reg,)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[gain_tf])\n",
    "xTrain_a, yTrain_a = DACombine().fit_predict(xTrain, yTrain, size=1024)\n",
    "history = model.fit(xTrain_a, yTrain_a, nb_epoch=500, validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred = model.predict(xTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80., 120.,  60., 120., 180.,  80., 120., 100.,  80., 100., 180.,\n",
       "       200.,  40., 120., 120.,  80., 100., 120., 100., 100.,  80.,  80.,\n",
       "        60.,  80.,  60., 120.,  60., 120., 100., 100.,  60.,  80., 100.,\n",
       "       120.,  40., 100., 100.,  80., 120., 100.,  80., 120.,  80., 120.,\n",
       "        80., 120., 100., 120., 120., 100., 100., 120., 120., 120.,  80.,\n",
       "        40.,  80., 160., 120.,  80., 140., 100., 140., 120., 120., 100.,\n",
       "        80., 120.,  80.,  80., 120.,   0., 120.,  80., 120.,  80., 120.,\n",
       "       120., 100., 100., 120., 100., 120., 120.,  80.,  80., 120., 100.,\n",
       "        80.,  80., 120., 100.,  80., 120., 120., 120.,  40., 100., 120.,\n",
       "       120.,  80., 180., 120., 120., 120., 120., 120., 120., 120., 100.,\n",
       "       120.,  80., 100.,  60.,  60., 100., 120.,  80., 140.])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, yy = DACombine().retarget(xTrain, yTrain.ravel(), 20)\n",
    "#yy - yTrain.ravel()\n",
    "yy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
