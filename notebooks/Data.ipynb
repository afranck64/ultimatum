{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sb\n",
    "import imblearn\n",
    "\n",
    "# Read and sanitize the data\n",
    "df = pd.read_excel(\"../data/UG_HH_NEW_continuous_no200.xls\")\n",
    "#df = pd.read_excel(\"./UG_HH_NEW_categorical_no200.xls\")\n",
    "df = df.dropna()\n",
    "\n",
    "df_effort = df[['time_spent_prop', 'count_effort']]\n",
    "df_effort = (df_effort - df_effort.min()) / (df_effort.max() - df_effort.min())\n",
    "\n",
    "df['effort'] = df_effort['time_spent_prop'] * df_effort['count_effort']\n",
    "df = df[['time_spent_risk', 'cells', 'selfish', 'effort',\n",
    "         'Honesty_Humility','Extraversion', 'Agreeableness', 'min_offer']]\n",
    "\n",
    "#df = df[['selfish','Honesty_Humility','Extraversion', 'Agreeableness', 'min_offer']]\n",
    "\n",
    "\n",
    "NORMALISE_DATA = True\n",
    "\n",
    "\n",
    "x = df.values[:, :-1]\n",
    "y = df.values[:, -1:]\n",
    "\n",
    "if NORMALISE_DATA:\n",
    "    x_min = x.min(axis=0)\n",
    "    x_max = x.max(axis=0)\n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    \n",
    "NB_FEATURES = x.shape[1]\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 1/3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (continuous dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy / Loss - For model comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GAIN = 200\n",
    "\n",
    "def loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute loss for the ultimatum game,\n",
    "    as the difference between the possible gain and the actual one\n",
    "    \"\"\"\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    rejected = min_offer > predicted\n",
    "    res = predicted - min_offer\n",
    "    if rejected.sum() != 0:\n",
    "        res[rejected] = MAX_GAIN - min_offer[rejected]\n",
    "    bad_predictions = (predicted < 0) | (predicted > MAX_GAIN)\n",
    "    if bad_predictions.sum() != 0:\n",
    "        res[bad_predictions] = MAX_GAIN - min_offer[bad_predictions]\n",
    "    return res\n",
    "\n",
    "def loss_sum(min_offer, predicted):\n",
    "    return loss(min_offer, predicted).sum()\n",
    "\n",
    "def avg_loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute avg loss for the ultimatum game\n",
    "    \"\"\"\n",
    "    return np.mean(loss(min_offer, predicted))\n",
    "\n",
    "def mse(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute mse using the loss as error\n",
    "    \"\"\"\n",
    "    return np.mean(np.square(loss(min_offer, predicted)))\n",
    "\n",
    "def rejection_ratio(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute ratio of rejected proposals without consideration of values\n",
    "    \"\"\"\n",
    "    accepted = (min_offer <= predicted)\n",
    "    return 1 - np.mean(accepted)\n",
    "\n",
    "def avg_win_loss(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute avg_loss of accepted proposals\n",
    "    \"\"\"\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()\n",
    "    accepted = (min_offer <= predicted)\n",
    "    if accepted.sum() == 0:\n",
    "        return 0\n",
    "    return avg_loss(min_offer[accepted], predicted[accepted])\n",
    "\n",
    "\n",
    "def gain(min_offer, predicted):\n",
    "    min_offer = min_offer.ravel()\n",
    "    predicted = predicted.ravel()    \n",
    "    res = MAX_GAIN - predicted\n",
    "    res[predicted < min_offer] = 0\n",
    "    return res\n",
    "\n",
    "def avg_loss_ratio(min_offer, predicted):\n",
    "    \"\"\"\n",
    "    Compute the avg gain ratio in relation to the maximal gain\n",
    "    \"\"\"\n",
    "    return 1 - np.mean(gain(min_offer, predicted) / gain(min_offer, min_offer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_functions = [avg_loss, mse, rejection_ratio, avg_win_loss, avg_loss_ratio, loss_sum]\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def process_model(model, xTrain, yTrain, xTest, yTest, fit_kwargs=None, predict_kwargs=None):\n",
    "    fit_kwargs = {} if fit_kwargs is None else fit_kwargs\n",
    "    predict_kwargs = {} if predict_kwargs is None else predict_kwargs\n",
    "    model.fit(xTrain, yTrain, **fit_kwargs)\n",
    "    yPredict = model.predict(xTest, **predict_kwargs)\n",
    "    results = {func.__name__: func(yTest, yPredict) for func in benchmark_functions}\n",
    "    return results\n",
    "    \n",
    "def process_benchmark_cv(model, X, y, cv=5, metrics=None, fit_kwargs=None, predict_kwargs=None, augment_kwargs=None):\n",
    "    # We make sure original values aren't modified, even by mistake\n",
    "    X = np.copy(X)\n",
    "    y = np.copy(y)\n",
    "    \n",
    "    kf = KFold(n_splits=cv)\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        xTrain, yTrain = X[train_index], y[train_index]\n",
    "        if augment_kwargs:\n",
    "            xTrain, yTrain = DACombine().fit_predict(xTrain, yTrain, **augment_kwargs)\n",
    "        xTest, yTest = X[test_index], y[test_index]\n",
    "        benchmark_result = process_model(model, xTrain, yTrain, xTest, yTest, fit_kwargs, predict_kwargs)\n",
    "        results.append(benchmark_result)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Data augmentation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DACombine(object):\n",
    "    def __init__(self, size=None, nb_features=NB_FEATURES, max_gain=MAX_GAIN):\n",
    "        self.size = size\n",
    "        self.nb_features = nb_features\n",
    "        self.max_gain = max_gain\n",
    "    \n",
    "    def fit_predict(self, xTrain, yTrain, size=None, distance=10, upsample=True, include_xy=False, retarget=False, distribution=False, combine=False):\n",
    "        \"\"\"\n",
    "        :param size: (int) size of the new generated dataset\n",
    "        :param distance: (int) distance between parents or similar items\n",
    "        :param upsample: (bool) if True, try balance the dataset\n",
    "        :param include_xy: (bool) if True, include xTrain and yTrain to the data (on top of size items)\n",
    "        :param retarget: (bool) if True, set all targets to the nearest higher multiple of distance without generating new samples\n",
    "        :param distribution: (bool) if True, create new sample based on percentiles of features's std\n",
    "        :param combine: (bool) if True: combine different methods (dist + retarget)\n",
    "        \"\"\"\n",
    "        \n",
    "        size = size or self.size or len(xTrain) * 4\n",
    "        if combine:\n",
    "            if distribution:\n",
    "                xTrain, yTrain = self.dist_resample(xTrain, yTrain, size)\n",
    "        else:\n",
    "            if retarget:\n",
    "                return self.retarget(xTrain, yTrain, distance)\n",
    "\n",
    "            if distribution:\n",
    "                return self.dist_resample(xTrain, yTrain, size)\n",
    "    \n",
    "        indices = np.arange(self.nb_features)\n",
    "        np.random.shuffle(indices)\n",
    "        targets = yTrain.ravel()\n",
    "        if upsample:\n",
    "            targets, counts = np.unique(yTrain, return_counts=True)\n",
    "            #NOTE: minimize selection of target with only one sample\n",
    "            probs = (1 - counts/counts.sum())**2\n",
    "            probs[counts==1] = probs.min()\n",
    "            probs /= probs.sum()\n",
    "        else:\n",
    "            targets = yTrain.ravel()\n",
    "            probs = None\n",
    "        xRes = []\n",
    "        yRes = []\n",
    "        if include_xy:\n",
    "            xRes.extend(xTrain)\n",
    "            yRes.extend(yTrain.ravel())\n",
    "        for _ in range(size):\n",
    "            target = np.random.choice(targets, p=probs)\n",
    "            target_mask = (yTrain.ravel()<target+distance) & (yTrain.ravel()>=(target))\n",
    "            xTrain_target = xTrain[target_mask]\n",
    "            i = np.random.randint(xTrain_target.shape[0])\n",
    "            j = np.random.randint(xTrain_target.shape[0])\n",
    "            x = np.zeros_like(xTrain_target[0])\n",
    "            np.random.shuffle(indices)\n",
    "            split = np.random.randint(self.nb_features)\n",
    "            mask_i = indices[:split]\n",
    "            mask_j = indices[split:]\n",
    "            x[mask_i] = xTrain_target[i, mask_i]\n",
    "            x[mask_j] = xTrain_target[j, mask_j]\n",
    "            xRes.append(x)\n",
    "            yRes.append(target)\n",
    "        xRes = np.array(xRes)\n",
    "        yRes = np.array(yRes)\n",
    "        if combine and retarget:\n",
    "            return self.retarget(xRes, yRes, distance)\n",
    "        return np.array(xRes), np.array(yRes)\n",
    "\n",
    "    def retarget(self, xTrain, yTrain, distance=10):\n",
    "        yNew = np.zeros(yTrain.shape[0])\n",
    "        for y in np.arange(self.max_gain, 0, -distance):\n",
    "            mask = (yTrain <= y) & (yTrain > y-distance)\n",
    "            yNew[mask] = y + np.random.randint(0, distance, mask.shape)[mask]\n",
    "        yNew = np.array(yNew)\n",
    "        yNew[yNew > self.max_gain] = self.max_gain\n",
    "        return xTrain, yNew\n",
    "    \n",
    "    def dist_resample(self, xTrain, yTrain, size=None, std_ratio=0.1):\n",
    "        size = size or self.size or len(xTrain) * 4\n",
    "        xTrain_mean = xTrain.mean()\n",
    "        xTrain_std = xTrain.std()\n",
    "        xNew = []\n",
    "        yNew = []\n",
    "        for _ in range(size):\n",
    "            idx = np.random.randint(0, xTrain.shape[0])\n",
    "            x = np.random.normal(xTrain[idx], xTrain_std*std_ratio)\n",
    "            y = yTrain[idx]\n",
    "            xNew.append(x)\n",
    "            yNew.append(y)\n",
    "        return np.array(xNew), np.array(yNew)\n",
    "            \n",
    "\n",
    "    def fit_resample(self, xTrain, yTrain, size=None, distance=5, include_xy=True):\n",
    "        return self.fit_predict(xTrain, yTrain, size=size, distance=distance, include_xy=include_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import multiply\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "\n",
    "def sigmoid1024_tf(x):\n",
    "    return (1024**x) / (1024**x + 1)\n",
    "\n",
    "def sigmoid_tf(x):\n",
    "    return K.sigmoid(x)\n",
    "\n",
    "def gain_tf(y_true, y_pred):\n",
    "    math_pi = tf.constant(math.pi)\n",
    "    one = tf.constant(1.0)\n",
    "    ten = tf.constant(10.0)\n",
    "    x = tf.math.subtract(y_true, y_pred)\n",
    "    x = tf.math.truediv(x, ten)\n",
    "    left_mul = sigmoid_tf(x)\n",
    "    right_mul = tf.math.cos(tf.math.divide(x, math_pi))\n",
    "    return tf.math.multiply(left_mul, right_mul)\n",
    "\n",
    "\n",
    "def loss_tf(y_true, y_pred):\n",
    "    math_pi = tf.constant(math.pi)\n",
    "    one = tf.constant(1.0)\n",
    "    ten = tf.constant(10.0)\n",
    "    x0 = tf.math.subtract(y_true, y_pred)\n",
    "    x = tf.math.truediv(x0, ten)\n",
    "    left_mul = sigmoid_tf(x)\n",
    "    right_mul = tf.math.cos(tf.math.divide(x, math_pi))\n",
    "    return tf.math.subtract(one*2, tf.math.multiply(left_mul, right_mul))\n",
    "\n",
    "def _keras_model(loss=None, metrics=None):\n",
    "    \"\"\"\n",
    "    build a simple regression model\n",
    "    :param loss: (str|callable, default: loss_tf)\n",
    "    \"\"\"\n",
    "    if loss is None:\n",
    "        loss = loss_tf\n",
    "    if metrics is None:\n",
    "        metrics = [\"mse\"]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=NB_FEATURES, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def _keras_linear_regression(loss=None, metrics=None):\n",
    "    if loss is None:\n",
    "        loss = \"mse\"\n",
    "    if metrics is None:\n",
    "        metrics = [\"mse\"]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=NB_FEATURES, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def keras_linear_regression(loss=None, metrics=None, nb_epoch=100, batch_size=32, verbose=False):\n",
    "    build_fn = lambda : _keras_linear_regression(loss, metrics)\n",
    "    return KerasRegressor(build_fn=build_fn, epochs=nb_epoch, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "def keras_model(loss=None, metrics=None, nb_epoch=100, batch_size=32, verbose=False):\n",
    "    build_fn = lambda : _keras_model(loss, metrics)\n",
    "    return KerasRegressor(build_fn=build_fn, epochs=nb_epoch, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4,  5, 28, 13, 26, 38,  1,  3,  0,  1]),\n",
       " array([  0. ,  19.5,  39. ,  58.5,  78. ,  97.5, 117. , 136.5, 156. ,\n",
       "        175.5, 195. ]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imblearn\n",
    "import imblearn.over_sampling\n",
    "o_s = imblearn.over_sampling.RandomOverSampler()\n",
    "xTrain_a, yTrain_a = o_s.fit_resample(xTrain, yTrain.ravel(), )\n",
    "pd.DataFrame(xTrain).hist()\n",
    "pd.DataFrame(xTrain_a).hist()\n",
    "np.histogram(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_regression_base</th>\n",
       "      <td>66.760832</td>\n",
       "      <td>0.619677</td>\n",
       "      <td>25.299141</td>\n",
       "      <td>2390.192750</td>\n",
       "      <td>6236.575025</td>\n",
       "      <td>0.547302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_retarget</th>\n",
       "      <td>60.494354</td>\n",
       "      <td>0.559989</td>\n",
       "      <td>26.520345</td>\n",
       "      <td>2165.906901</td>\n",
       "      <td>5369.486092</td>\n",
       "      <td>0.469048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_x16</th>\n",
       "      <td>76.022773</td>\n",
       "      <td>0.691695</td>\n",
       "      <td>27.261765</td>\n",
       "      <td>2720.745870</td>\n",
       "      <td>7672.729765</td>\n",
       "      <td>0.625873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_x16-up</th>\n",
       "      <td>73.015110</td>\n",
       "      <td>0.661813</td>\n",
       "      <td>26.564852</td>\n",
       "      <td>2614.044330</td>\n",
       "      <td>7342.903378</td>\n",
       "      <td>0.592063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_x16_combine</th>\n",
       "      <td>60.690611</td>\n",
       "      <td>0.560757</td>\n",
       "      <td>26.740796</td>\n",
       "      <td>2172.990068</td>\n",
       "      <td>5394.117611</td>\n",
       "      <td>0.469048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression_x16_dist</th>\n",
       "      <td>67.022817</td>\n",
       "      <td>0.621765</td>\n",
       "      <td>25.952819</td>\n",
       "      <td>2399.656591</td>\n",
       "      <td>6248.532461</td>\n",
       "      <td>0.547302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_base</th>\n",
       "      <td>28.889683</td>\n",
       "      <td>0.238859</td>\n",
       "      <td>23.578000</td>\n",
       "      <td>1033.000000</td>\n",
       "      <td>1783.019841</td>\n",
       "      <td>0.095079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_retarget</th>\n",
       "      <td>35.382063</td>\n",
       "      <td>0.298694</td>\n",
       "      <td>26.749650</td>\n",
       "      <td>1267.600000</td>\n",
       "      <td>2378.544603</td>\n",
       "      <td>0.139048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_x16</th>\n",
       "      <td>79.748413</td>\n",
       "      <td>0.693918</td>\n",
       "      <td>37.701961</td>\n",
       "      <td>2854.000000</td>\n",
       "      <td>8635.765873</td>\n",
       "      <td>0.575873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_x16-up</th>\n",
       "      <td>85.020635</td>\n",
       "      <td>0.727323</td>\n",
       "      <td>42.134250</td>\n",
       "      <td>3041.000000</td>\n",
       "      <td>9363.555556</td>\n",
       "      <td>0.609683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_x16_combine</th>\n",
       "      <td>33.078413</td>\n",
       "      <td>0.277175</td>\n",
       "      <td>26.845150</td>\n",
       "      <td>1184.600000</td>\n",
       "      <td>2060.183492</td>\n",
       "      <td>0.111270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_regression_x16_dist</th>\n",
       "      <td>40.480952</td>\n",
       "      <td>0.345640</td>\n",
       "      <td>22.652078</td>\n",
       "      <td>1448.000000</td>\n",
       "      <td>3491.214286</td>\n",
       "      <td>0.223651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                avg_loss  avg_loss_ratio  avg_win_loss  \\\n",
       "linear_regression_base         66.760832        0.619677     25.299141   \n",
       "linear_regression_retarget     60.494354        0.559989     26.520345   \n",
       "linear_regression_x16          76.022773        0.691695     27.261765   \n",
       "linear_regression_x16-up       73.015110        0.661813     26.564852   \n",
       "linear_regression_x16_combine  60.690611        0.560757     26.740796   \n",
       "linear_regression_x16_dist     67.022817        0.621765     25.952819   \n",
       "log_regression_base            28.889683        0.238859     23.578000   \n",
       "log_regression_retarget        35.382063        0.298694     26.749650   \n",
       "log_regression_x16             79.748413        0.693918     37.701961   \n",
       "log_regression_x16-up          85.020635        0.727323     42.134250   \n",
       "log_regression_x16_combine     33.078413        0.277175     26.845150   \n",
       "log_regression_x16_dist        40.480952        0.345640     22.652078   \n",
       "\n",
       "                                  loss_sum          mse  rejection_ratio  \n",
       "linear_regression_base         2390.192750  6236.575025         0.547302  \n",
       "linear_regression_retarget     2165.906901  5369.486092         0.469048  \n",
       "linear_regression_x16          2720.745870  7672.729765         0.625873  \n",
       "linear_regression_x16-up       2614.044330  7342.903378         0.592063  \n",
       "linear_regression_x16_combine  2172.990068  5394.117611         0.469048  \n",
       "linear_regression_x16_dist     2399.656591  6248.532461         0.547302  \n",
       "log_regression_base            1033.000000  1783.019841         0.095079  \n",
       "log_regression_retarget        1267.600000  2378.544603         0.139048  \n",
       "log_regression_x16             2854.000000  8635.765873         0.575873  \n",
       "log_regression_x16-up          3041.000000  9363.555556         0.609683  \n",
       "log_regression_x16_combine     1184.600000  2060.183492         0.111270  \n",
       "log_regression_x16_dist        1448.000000  3491.214286         0.223651  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression, PassiveAggressiveRegressor, \\\n",
    "                                 ElasticNet, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble.bagging import BaggingRegressor, DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "benchmark_models = {\n",
    "    'linear_regression': LinearRegression(), #LogisticRegression(penalty='l1', solver='liblinear', multi_class='auto'), #keras_linear_regression(nb_epoch=100, batch_size=60)\n",
    "    'log_regression': LogisticRegression(penalty='l1', solver='liblinear', multi_class='auto'),\n",
    "}\n",
    "    \n",
    "augment_params = {\n",
    "    'base': {},\n",
    "    'retarget': {'retarget': True, 'distance': 10},\n",
    "#     'x2': {'size':len(xTrain)*2},\n",
    "#     'x2-up': {'size':len(xTrain)*2, 'upsample': True},\n",
    "#     'x2+xy': {'size':len(xTrain)*2, 'include_xy':True},\n",
    "#     'x4': {'size': len(xTrain)*4},\n",
    "#     'x4+xy-up': {'size': len(xTrain)*4, 'include_xy':True, 'upsample':True},\n",
    "    'x16': {'size': len(xTrain)*16},\n",
    "    'x16-up': {'size': len(xTrain)*16, 'upsample': True},\n",
    "    'x16_dist': {'size': len(xTrain)*16, 'distribution': True},\n",
    "    'x16_combine': {'size': len(xTrain)*16, 'retarget': True, 'distribution': True, 'upsample': True},\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for key, model in benchmark_models.items():\n",
    "    for aug_key, aug_params in augment_params.items():\n",
    "        results[key+\"_\" + aug_key] = process_benchmark_cv(model=model, X=x, y=y.ravel(), augment_kwargs=aug_params)\n",
    "\n",
    "results_mean = {key: item.mean() for key, item in results.items()}\n",
    "results_std = {key: item.std() for key, item in results.items()}\n",
    "pd.DataFrame(results_mean).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Actual best model:**\n",
    "- LogisticRegression (penalty='l1')\n",
    "\n",
    "** Data Augmentation improve following models:**\n",
    "- BaggingRegression\n",
    "- MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franck/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>extra_base</th>\n",
       "      <td>63.261825</td>\n",
       "      <td>0.588282</td>\n",
       "      <td>25.038583</td>\n",
       "      <td>2267.100000</td>\n",
       "      <td>5791.847738</td>\n",
       "      <td>0.507619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra_retarget</th>\n",
       "      <td>61.213413</td>\n",
       "      <td>0.564639</td>\n",
       "      <td>26.134481</td>\n",
       "      <td>2192.480000</td>\n",
       "      <td>5549.346300</td>\n",
       "      <td>0.474444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra_x16</th>\n",
       "      <td>71.646986</td>\n",
       "      <td>0.660093</td>\n",
       "      <td>26.425445</td>\n",
       "      <td>2564.703636</td>\n",
       "      <td>6980.089286</td>\n",
       "      <td>0.592063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra_x16-up</th>\n",
       "      <td>73.524963</td>\n",
       "      <td>0.676925</td>\n",
       "      <td>27.762957</td>\n",
       "      <td>2633.003782</td>\n",
       "      <td>7174.904159</td>\n",
       "      <td>0.608571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra_x16_combine</th>\n",
       "      <td>59.958841</td>\n",
       "      <td>0.553705</td>\n",
       "      <td>28.125683</td>\n",
       "      <td>2149.360000</td>\n",
       "      <td>5294.585259</td>\n",
       "      <td>0.451587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra_x16_dist</th>\n",
       "      <td>67.924206</td>\n",
       "      <td>0.625644</td>\n",
       "      <td>26.002177</td>\n",
       "      <td>2432.100000</td>\n",
       "      <td>6447.366389</td>\n",
       "      <td>0.547143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    avg_loss  avg_loss_ratio  avg_win_loss     loss_sum  \\\n",
       "extra_base         63.261825        0.588282     25.038583  2267.100000   \n",
       "extra_retarget     61.213413        0.564639     26.134481  2192.480000   \n",
       "extra_x16          71.646986        0.660093     26.425445  2564.703636   \n",
       "extra_x16-up       73.524963        0.676925     27.762957  2633.003782   \n",
       "extra_x16_combine  59.958841        0.553705     28.125683  2149.360000   \n",
       "extra_x16_dist     67.924206        0.625644     26.002177  2432.100000   \n",
       "\n",
       "                           mse  rejection_ratio  \n",
       "extra_base         5791.847738         0.507619  \n",
       "extra_retarget     5549.346300         0.474444  \n",
       "extra_x16          6980.089286         0.592063  \n",
       "extra_x16-up       7174.904159         0.608571  \n",
       "extra_x16_combine  5294.585259         0.451587  \n",
       "extra_x16_dist     6447.366389         0.547143  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, VotingClassifier\n",
    "benchmark_models = {\n",
    "    #'bag': BaggingRegressor(), \n",
    "    #'mlp': MLPRegressor(),\n",
    "    'extra': ExtraTreesRegressor(),\n",
    "}\n",
    "    \n",
    "augment_params = {\n",
    "    'base': {},\n",
    "    'retarget': {'retarget': True, 'distance': 10},\n",
    "    'x16': {'size': len(xTrain)*16},\n",
    "    'x16-up': {'size': len(xTrain)*16, 'upsample': True},\n",
    "    'x16_dist': {'size': len(xTrain)*16, 'distribution': True},\n",
    "    'x16_combine': {'size': len(xTrain)*16, 'retarget': True, 'distribution': True},\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for key, model in benchmark_models.items():\n",
    "    for aug_key, aug_params in augment_params.items():\n",
    "        results[key+\"_\" + aug_key] = process_benchmark_cv(model=model, X=x, y=y.ravel(), augment_kwargs=aug_params)\n",
    "\n",
    "results_mean = {key: item.mean() for key, item in results.items()}\n",
    "results_std = {key: item.std() for key, item in results.items()}\n",
    "pd.DataFrame(results_mean).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import L1L2\n",
    "\n",
    "reg = L1L2(l1=0.01, l2=0.01)\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='relu', input_dim=x.shape[1]),)# W_regularizer=reg,)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[gain_tf])\n",
    "xTrain_a, yTrain_a = DACombine().fit_predict(xTrain, yTrain, size=1024)\n",
    "history = model.fit(xTrain_a, yTrain_a, nb_epoch=500, validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred = model.predict(xTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, yy = DACombine().retarget(xTrain, yTrain.ravel(), 20)\n",
    "#yy - yTrain.ravel()\n",
    "yy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
