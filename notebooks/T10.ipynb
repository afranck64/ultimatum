{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prop                   200.0\n",
       "other_resp             200.0\n",
       "other_prop             200.0\n",
       "time_spent_risk     152000.0\n",
       "cells                   50.0\n",
       "selfish                 60.0\n",
       "time_spent_prop     269000.0\n",
       "count_effort            20.0\n",
       "Honesty_Humility         5.0\n",
       "Extraversion             5.0\n",
       "Agreeableness            5.0\n",
       "min_offer              200.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sb\n",
    "\n",
    "np.random.seed = 0\n",
    "\n",
    "#df = pd.read_excel(\"../data/HH_SURVEY1/UG_HH_NEW_continuous_no200_train.xls\")\n",
    "\n",
    "df = pd.read_excel(\"../data/t00/data.xls\")\n",
    "df_full = df.copy()\n",
    "#Drop 'protected' features\n",
    "drop_cols = ['prop', 'other_prop', 'other_resp']\n",
    "df = df[[col for col in df.columns if col not in drop_cols]]\n",
    "\n",
    "## comment/uncomment for shuffling\n",
    "#df = df.sample(frac=1.0)\n",
    "TEST_SIZE = 100\n",
    "# df_test = df.head(TEST_SIZE)\n",
    "# df_train = df.tail(df.shape[0] - TEST_SIZE)\n",
    "df_base = df.copy()\n",
    "\n",
    "df_train = df.head(df.shape[0] - TEST_SIZE)\n",
    "df_test = df.tail(TEST_SIZE)\n",
    "df_train.to_excel(\"../data/t10/train.xls\")\n",
    "df_test.to_excel(\"../data/t10/test.xls\")\n",
    "\n",
    "\n",
    "df_full = pd.read_excel(\"../data/t00/data.xls\")\n",
    "df_min = df_full.min()\n",
    "df_max = df_full.max()\n",
    "df_max[\"Honesty_Humility\"] = 5.0\n",
    "df_max[\"Extraversion\"] = 5.0\n",
    "df_max[\"Agreeableness\"] = 5.0\n",
    "df_max[\"cells\"] = 50\n",
    "df_max[\"selfish\"] = 60\n",
    "df_max[\"min_offer\"] = 200\n",
    "df_max[\"prop\"] = 200\n",
    "df_max[\"other_resp\"] = 200\n",
    "df_max[\"other_prop\"] = 200\n",
    "\n",
    "\n",
    "df.head()\n",
    "df_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine significant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance permutation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.utils.preprocessing import df_to_xy, df_to_xydf\n",
    "from notebooks.models import AcceptanceModel\n",
    "from notebooks.utils.benchmark import process_model, process_benchmark_cv\n",
    "from mlxtend.evaluate import feature_importance_permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from utils.preprocessing import df_to_xy, df_to_xydf\n",
    "\n",
    "# NB_REPETITIONS = 5\n",
    "\n",
    "# imp_vals = None\n",
    "# imp_all = None\n",
    "# for _ in range(NB_REPETITIONS):\n",
    "#     df_x, df_y = df_to_xydf(df_train.sample(frac=1.0), fuse_risk=True)\n",
    "#     model = AcceptanceModel()\n",
    "#     split = int(0.6 * df_x.shape[0])\n",
    "#     model.fit(df_x.values[:split], df_y.values.ravel()[:split])\n",
    "\n",
    "#     step_imp_vals, step_imp_all = feature_importance_permutation(\n",
    "#         predict_method=model.predict, \n",
    "#         X=df_x.values[split:],\n",
    "#         y=df_y.values.ravel()[split:],\n",
    "#         metric='accuracy',\n",
    "#         num_rounds=3,\n",
    "#         seed=None)\n",
    "#     if imp_vals is None:\n",
    "#         imp_vals = step_imp_vals\n",
    "#         imp_all = step_imp_all\n",
    "#     else:\n",
    "#         imp_vals += step_imp_vals\n",
    "#         imp_all += step_imp_all\n",
    "\n",
    "\n",
    "# imp_all /= NB_REPETITIONS\n",
    "# imp_vals /= NB_REPETITIONS\n",
    "# std = np.std(imp_all, axis=1)\n",
    "# indices = np.argsort(imp_vals)[::-1]\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(15, 8))\n",
    "# plt.title(\"Feature importance via permutation importance\")\n",
    "# plt.bar(df_x.columns[indices], imp_vals[indices],\n",
    "#         yerr=std[indices],)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# res = {}\n",
    "# features = list(df) + ['risk']\n",
    "# if 'min_offer' in features:\n",
    "#     features.remove('min_offer')\n",
    "# for col in features:\n",
    "#     df_train = df_train.sample(frac=1.0)\n",
    "#     if col == 'risk':    \n",
    "#         x, y = df_to_xy(df_base, select_columns=[col], fuse_risk=True, df_min=df_min, df_max=df_max)\n",
    "#         col = 'risk*'\n",
    "#     else:\n",
    "#         x, y = df_to_xy(df_base, select_columns=[col], df_min=df_min, df_max=df_max)\n",
    "#     model = AcceptanceModel()\n",
    "#     item_res = process_benchmark_cv(model, X=x, y=y)\n",
    "#     res[col] = item_res.mean()\n",
    "\n",
    "# res_single_df = pd.DataFrame(res).T\n",
    "# res_single_df.sort_values(by=['avg_loss_ratio'], inplace=True)\n",
    "# res_single_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "\n",
    "# features = list(df_train) + [\"risk\"]\n",
    "# if 'min_offer' in features:\n",
    "#     features.remove('min_offer')\n",
    "\n",
    "# res = {}\n",
    "# for cols in combinations(features, 2):\n",
    "#     df_train = df_train.sample(frac=1.0)\n",
    "#     #index should be a list\n",
    "#     cols = list(cols)\n",
    "#     if cols[0]==cols[1]: continue\n",
    "#     if \"risk\" in cols and (\"time_spent_risk\" in cols or \"cells\" in cols): continue\n",
    "#     if \"risk\" in cols:\n",
    "#         x, y = df_to_xy(df_base, centered=False, fuse_risk=True, select_columns=cols, df_min=df_min, df_max=df_max)\n",
    "#     else:\n",
    "#         x, y = df_to_xy(df_base, centered=False, select_columns=cols, df_min=df_min, df_max=df_max)\n",
    "#     model = AcceptanceModel()\n",
    "#     item_res = process_benchmark_cv(model, X=x, y=y)\n",
    "#     res[\":\".join(cols)] = item_res.mean()\n",
    "\n",
    "# res_duo_df = pd.DataFrame(res).T\n",
    "# res_duo_df.sort_values(by=['avg_loss_ratio'], inplace=True)\n",
    "# res_duo_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "#res_trio_df = res_duo_df\n",
    "\n",
    "# features = list(df_train)\n",
    "# if 'min_offer' in features:\n",
    "#     features.remove('min_offer')\n",
    "\n",
    "# res = {}\n",
    "# for cols in combinations(features, 3):\n",
    "#     df_train = df_train.sample(frac=1.0)\n",
    "#     #index should be a list\n",
    "#     cols = list(cols)\n",
    "#     if cols[0]==cols[1]: continue\n",
    "#     x, y = df_to_xy(df_base, centered=False, select_columns=cols, df_min=df_min, df_max=df_max)\n",
    "#     model = AcceptanceModel()\n",
    "#     item_res = process_benchmark_cv(model, X=x, y=y, cv=3)\n",
    "#     res[\":\".join(cols)] = item_res.mean()\n",
    "\n",
    "# res_trio_df = pd.DataFrame(res).T\n",
    "# res_trio_df.sort_values(by=['avg_loss_ratio'], inplace=True)\n",
    "# res_trio_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "\n",
    "# features = list(df)\n",
    "# if 'min_offer' in features:\n",
    "#     features.remove('min_offer')\n",
    "\n",
    "# res = {}\n",
    "# for cols in combinations(features, 4):\n",
    "#     #index should be a list\n",
    "#     cols = list(cols)\n",
    "#     if cols[0]==cols[1]: continue\n",
    "#     x, y = df_to_xy(df, centered=False, select_columns=cols, df_min=df_min, df_max=df_max)\n",
    "#     model = AcceptanceModel()\n",
    "#     item_res = process_benchmark_cv(model, X=x, y=y)\n",
    "#     res[\":\".join(cols)] = item_res.mean()\n",
    "\n",
    "# res_quad_df = pd.DataFrame(res).T\n",
    "# res_quad_df.sort_values(by=['avg_loss_ratio'], inplace=True)\n",
    "# res_quad_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     selfish     cells  count_effort  Honesty_Humility\n",
      "0   1.000000  0.510204          1.00          0.741935\n",
      "1   0.333333  0.122449          1.00          0.000000\n",
      "2   0.333333  1.000000          0.60          0.451613\n",
      "3   1.000000  1.000000          0.70          0.548387\n",
      "4   1.000000  0.469388          0.20          0.548387\n",
      "5   0.333333  0.306122          0.55          0.709677\n",
      "6   0.666667  0.795918          0.70          0.838710\n",
      "7   0.500000  0.224490          0.75          0.290323\n",
      "8   0.000000  0.734694          0.75          0.548387\n",
      "9   0.416667  1.000000          0.85          0.290323\n",
      "10  0.666667  0.183673          0.60          0.580645\n",
      "11  0.333333  0.387755          0.80          0.612903\n",
      "12  0.666667  0.612245          0.45          0.258065\n",
      "13  0.750000  1.000000          0.70          0.580645\n",
      "14  1.000000  0.387755          1.00          0.354839\n",
      "15  0.000000  0.387755          0.90          0.645161\n",
      "16  0.333333  1.000000          0.40          0.580645\n",
      "17  1.000000  0.224490          0.45          0.709677\n",
      "18  0.000000  0.979592          0.85          0.709677\n",
      "19  0.166667  0.163265          1.00          0.290323\n",
      "20  0.500000  0.326531          0.50          0.774194\n",
      "21  0.500000  0.387755          0.95          0.483871\n",
      "22  0.500000  0.755102          1.00          0.290323\n",
      "23  0.666667  0.163265          0.60          0.419355\n",
      "24  0.750000  0.183673          0.45          0.483871\n",
      "25  1.000000  1.000000          1.00          0.645161\n",
      "26  0.500000  0.387755          1.00          0.516129\n",
      "27  0.000000  0.387755          0.95          0.387097\n",
      "28  0.500000  1.000000          0.55          0.451613\n",
      "29  1.000000  0.346939          0.85          0.645161\n",
      "..       ...       ...           ...               ...\n",
      "49  1.000000  0.244898          0.50          0.354839\n",
      "50  0.833333  0.551020          1.00          0.741935\n",
      "51  0.500000  0.632653          1.00          0.290323\n",
      "52  0.750000  0.795918          0.05          0.548387\n",
      "53  0.750000  1.000000          1.00          0.580645\n",
      "54  1.000000  0.387755          0.50          0.870968\n",
      "55  0.416667  0.489796          0.85          0.903226\n",
      "56  0.583333  0.428571          0.45          0.548387\n",
      "57  0.500000  0.693878          0.70          0.645161\n",
      "58  0.250000  1.000000          0.60          0.838710\n",
      "59  0.833333  1.000000          0.40          0.322581\n",
      "60  0.333333  0.224490          0.60          0.354839\n",
      "61  0.000000  0.469388          0.95          0.387097\n",
      "62  0.333333  0.469388          0.55          0.354839\n",
      "63  0.500000  0.979592          0.50          0.580645\n",
      "64  0.000000  0.979592          0.25          0.612903\n",
      "65  0.500000  0.387755          0.85          0.741935\n",
      "66  0.000000  0.183673          0.80          0.516129\n",
      "67  0.750000  0.489796          1.00          0.290323\n",
      "68  0.333333  0.387755          0.40          0.612903\n",
      "69  0.750000  0.204082          0.30          0.387097\n",
      "70  0.750000  1.000000          1.00          0.000000\n",
      "71  0.750000  0.795918          0.40          0.677419\n",
      "72  0.000000  1.000000          0.70          0.709677\n",
      "73  0.000000  1.000000          0.55          0.193548\n",
      "74  0.500000  0.142857          0.90          0.709677\n",
      "75  0.500000  0.979592          0.75          0.225806\n",
      "76  0.750000  0.183673          0.40          0.451613\n",
      "77  0.500000  0.183673          0.70          0.580645\n",
      "78  0.666667  0.612245          1.00          0.516129\n",
      "\n",
      "[79 rows x 4 columns]     min_offer\n",
      "0          50\n",
      "1          50\n",
      "2          80\n",
      "3          50\n",
      "4         100\n",
      "5         100\n",
      "6         100\n",
      "7         100\n",
      "8          90\n",
      "9          40\n",
      "10        100\n",
      "11        105\n",
      "12        100\n",
      "13         20\n",
      "14          5\n",
      "15         80\n",
      "16        100\n",
      "17         50\n",
      "18        100\n",
      "19         15\n",
      "20        100\n",
      "21         75\n",
      "22        100\n",
      "23         80\n",
      "24        100\n",
      "25        150\n",
      "26         75\n",
      "27        100\n",
      "28         90\n",
      "29         50\n",
      "..        ...\n",
      "49         50\n",
      "50         40\n",
      "51        100\n",
      "52         95\n",
      "53         75\n",
      "54         50\n",
      "55         95\n",
      "56        100\n",
      "57        100\n",
      "58        100\n",
      "59        150\n",
      "60        100\n",
      "61         70\n",
      "62         50\n",
      "63         90\n",
      "64        100\n",
      "65        100\n",
      "66         85\n",
      "67         80\n",
      "68        100\n",
      "69         30\n",
      "70         80\n",
      "71        100\n",
      "72        100\n",
      "73         80\n",
      "74         90\n",
      "75         80\n",
      "76        100\n",
      "77         50\n",
      "78         50\n",
      "\n",
      "[79 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#top_columns = ['time_spent_prop', 'count_effort']\n",
    "\n",
    "#top_columns = ['time_spent_prop', 'count_effort', 'selfish', 'Honesty_Humility']\n",
    "\n",
    "top_columns = ['selfish', 'cells', 'count_effort', 'Honesty_Humility']\n",
    "#top_columns = [\"risk\", \"time_spent_prop\"]\n",
    "epsilon = 0.01\n",
    "# if res_duo_df.avg_loss_ratio[0] - epsilon < res_trio_df.avg_loss_ratio[0]:\n",
    "#     top_columns = res_duo_df.index[0].split(':')\n",
    "# else:\n",
    "#     top_columns = res_trio_df.index[0].split(':')\n",
    "# # if res_single_df.avg_loss_ratio[0] - epsilon < res_duo_df.avg_loss_ratio[0] and \\\n",
    "# #         res_single_df.avg_loss_ratio[0] - epsilon < res_trio_df.avg_loss_ratio[0]:\n",
    "# #     top_columns = [res_single_df.index[0]]\n",
    "\n",
    "if \"risk\" in top_columns:\n",
    "    x, y = df_to_xy(df_train, centered=False, fuse_risk=True, select_columns=top_columns, min_target=5, max_target=190, df_min=df_min, df_max=df_max)\n",
    "else:\n",
    "    x, y = df_to_xy(df_train, centered=False, select_columns=top_columns, min_target=5, max_target=190, df_min=df_min, df_max=df_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(x.shape[0] * 0.8)\n",
    "xTrain, yTrain = x[:split], y[:split]\n",
    "xTest, yTest = x[split:], y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AcceptanceModel(step=5, zero_one=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AVG loss ratio:  0.26710413549982726\n",
      "Val Mean gain:  93.125\n",
      "Val AVG loss ratio:  0.18849425763388372\n"
     ]
    }
   ],
   "source": [
    "from models.metrics import gain_mean, avg_loss_ratio\n",
    "\n",
    "model.fit(xTrain, yTrain)\n",
    "yPred = model.predict(xTest)\n",
    "\n",
    "print(\"Train AVG loss ratio: \", avg_loss_ratio(yTrain, model.predict(xTrain)))\n",
    "\n",
    "print(\"Val Mean gain: \", gain_mean(yTest, yPred))\n",
    "print(\"Val AVG loss ratio: \", avg_loss_ratio(yTest, yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values:  [ 30  50  80  85  90 100]\n",
      "Unique predicted values:  [100. 105. 110. 115.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values: \", np.unique(yTest))\n",
    "print(\"Unique predicted values: \", np.unique(yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Generate data for the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top acc: 0.7405344902442806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor, BaggingClassifier\n",
    "\n",
    "\n",
    "top_model = AcceptanceModel.get_trained_model(xTrain, yTrain)\n",
    "\n",
    "top_loss_ratio = avg_loss_ratio(yTrain, top_model.predict(xTrain))\n",
    "\n",
    "print(\"top acc:\", 1 - top_loss_ratio,)   # \"Val acc: \", avg_loss_ratio(yTest, top_model.predict(xTest)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     selfish     cells  count_effort  Honesty_Humility\n",
      "0   0.416667  0.979592          0.55          0.290323\n",
      "1   0.500000  0.551020          0.65          0.483871\n",
      "2   0.500000  0.061224          0.25          0.677419\n",
      "3   0.250000  0.387755          1.00          0.677419\n",
      "4   0.250000  0.346939          0.80          0.612903\n",
      "5   0.333333  0.326531          0.50          0.806452\n",
      "6   1.000000  0.224490          0.55          0.419355\n",
      "7   0.666667  0.387755          0.50          0.548387\n",
      "8   0.500000  1.000000          0.70          0.677419\n",
      "9   0.500000  0.183673          0.45          0.322581\n",
      "10  0.666667  0.183673          0.80          0.225806\n",
      "11  0.666667  1.000000          1.00          0.645161\n",
      "12  0.250000  0.285714          1.00          0.645161\n",
      "13  0.000000  0.326531          0.70          0.483871\n",
      "14  0.750000  1.000000          0.75          0.225806\n",
      "15  0.666667  1.000000          0.75          0.322581\n",
      "16  0.833333  0.469388          0.75          0.677419\n",
      "17  0.000000  0.979592          0.60          0.806452\n",
      "18  0.000000  0.204082          0.10          0.548387\n",
      "19  0.666667  0.673469          0.05          0.516129\n",
      "20  0.500000  1.000000          0.60          0.645161\n",
      "21  0.250000  0.897959          0.85          0.387097\n",
      "22  1.000000  0.755102          0.40          0.516129\n",
      "23  0.750000  1.000000          0.75          0.387097\n",
      "24  0.416667  1.000000          0.25          0.387097\n",
      "25  1.000000  0.918367          0.30          0.612903\n",
      "26  0.666667  0.428571          0.45          0.516129\n",
      "27  0.000000  0.591837          0.75          0.709677\n",
      "28  0.750000  0.836735          1.00          0.516129\n",
      "29  0.750000  1.000000          0.30          0.387097\n",
      "..       ...       ...           ...               ...\n",
      "70  0.250000  0.061224          0.70          0.193548\n",
      "71  0.166667  1.000000          0.60          0.516129\n",
      "72  1.000000  0.183673          0.75          0.516129\n",
      "73  0.333333  0.387755          0.50          0.645161\n",
      "74  0.500000  0.306122          0.10          0.677419\n",
      "75  0.750000  0.591837          0.65          0.387097\n",
      "76  0.500000  0.061224          0.50          0.645161\n",
      "77  0.416667  0.224490          0.55          0.419355\n",
      "78  0.500000  0.387755          1.00          0.258065\n",
      "79  0.333333  0.795918          0.45          0.967742\n",
      "80  0.500000  0.183673          1.00          0.419355\n",
      "81  0.500000  0.224490          0.60          0.419355\n",
      "82  0.500000  0.387755          0.60          0.483871\n",
      "83  0.500000  0.346939          0.85          0.548387\n",
      "84  0.250000  1.000000          0.40          0.612903\n",
      "85  0.000000  0.306122          0.85          0.903226\n",
      "86  1.000000  0.081633          0.40          0.419355\n",
      "87  1.000000  0.795918          0.55          0.677419\n",
      "88  1.000000  0.387755          0.95          0.258065\n",
      "89  0.000000  0.183673          0.95          0.677419\n",
      "90  0.000000  0.632653          1.00          0.580645\n",
      "91  0.666667  0.183673          0.40          0.451613\n",
      "92  1.000000  1.000000          1.00          0.580645\n",
      "93  0.000000  0.387755          0.90          0.580645\n",
      "94  0.500000  0.204082          0.90          0.483871\n",
      "95  0.666667  0.469388          1.00          0.451613\n",
      "96  0.250000  0.142857          0.85          0.741935\n",
      "97  1.000000  0.306122          0.95          0.483871\n",
      "98  0.166667  0.489796          0.35          0.903226\n",
      "99  0.750000  0.489796          0.60          0.612903\n",
      "\n",
      "[100 rows x 4 columns]     min_offer\n",
      "0         100\n",
      "1         120\n",
      "2         100\n",
      "3          90\n",
      "4         100\n",
      "5          80\n",
      "6         100\n",
      "7          80\n",
      "8         100\n",
      "9         100\n",
      "10         90\n",
      "11         25\n",
      "12        125\n",
      "13         50\n",
      "14         50\n",
      "15         10\n",
      "16        100\n",
      "17        195\n",
      "18         10\n",
      "19         60\n",
      "20        100\n",
      "21         50\n",
      "22         80\n",
      "23        110\n",
      "24         25\n",
      "25         50\n",
      "26         90\n",
      "27        100\n",
      "28         80\n",
      "29         75\n",
      "..        ...\n",
      "70         10\n",
      "71         80\n",
      "72        100\n",
      "73         75\n",
      "74         50\n",
      "75        100\n",
      "76         90\n",
      "77         35\n",
      "78         50\n",
      "79         75\n",
      "80         50\n",
      "81         80\n",
      "82         50\n",
      "83         90\n",
      "84         75\n",
      "85        100\n",
      "86         85\n",
      "87         60\n",
      "88         75\n",
      "89        100\n",
      "90         90\n",
      "91         85\n",
      "92         50\n",
      "93        105\n",
      "94        100\n",
      "95         50\n",
      "96         75\n",
      "97         50\n",
      "98        100\n",
      "99         85\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selfish</th>\n",
       "      <th>cells</th>\n",
       "      <th>count_effort</th>\n",
       "      <th>Honesty_Humility</th>\n",
       "      <th>ai_offer</th>\n",
       "      <th>min_offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>2.8</td>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>3.4</td>\n",
       "      <td>105</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>105</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>3.8</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   selfish  cells  count_effort  Honesty_Humility  ai_offer  min_offer\n",
       "0       25     49            11               2.8       110        100\n",
       "1       30     28            13               3.4       105        120\n",
       "2       30      4             5               4.0       105        100\n",
       "3       15     20            20               4.0       100         90\n",
       "4       15     18            16               3.8       100        100"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and sanitize the data\n",
    "df_train = df.head(df.shape[0] - 100)\n",
    "#df_test = df.tail(100)\n",
    "df_test = pd.read_excel(\"../data/HH_SURVEY1/UG_HH_NEW_continuous_no200_test.xls\")\n",
    "\n",
    "if \"risk\" in top_columns:\n",
    "    df_features, df_y = df_to_xydf(df_test, centered=False, fuse_risk=True, select_columns=top_columns, df_min=df_min, df_max=df_max)\n",
    "else:\n",
    "    df_features, df_y = df_to_xydf(df_test, centered=False, select_columns=top_columns, df_min=df_min, df_max=df_max)\n",
    "predictions = top_model.predict(df_features.values).astype(int)\n",
    "\n",
    "df_final = df_test[top_columns].copy()\n",
    "#RESCALE FEATURES\n",
    "df_final['ai_offer'] = predictions.ravel()\n",
    "df_final['min_offer'] = df_y['min_offer']\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the model and model infos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([110, 105, 100,  95])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['ai_offer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test/ai - mean gain:  89.35\n",
      "Test/ai - avg loss ratio:  0.2515748921923574\n"
     ]
    }
   ],
   "source": [
    "print(\"Test/ai - mean gain: \", gain_mean(df_final['min_offer'], df_final['ai_offer']))\n",
    "print(\"Test/ai - avg loss ratio: \", avg_loss_ratio(df_final['min_offer'], df_final['ai_offer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new data\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "from utils.explanation import get_pdf\n",
    "\n",
    "test_gain_mean = gain_mean(df_final['min_offer'], df_final['ai_offer'])\n",
    "test_avg_loss_ratio = avg_loss_ratio(df_final['min_offer'], df_final['ai_offer'])\n",
    "infos_filename = \"../data/t10/model.json\"\n",
    "model_filename = \"../data/t10/model.pkl\"\n",
    "pdf, bins_pdf = get_pdf(yTrain)\n",
    "err = top_model.predict(xTrain) - yTrain\n",
    "train_err_pdf, bins_train_err_pdf = np.histogram(err, bins=np.arange(-200, 200, 5), density=True)\n",
    "\n",
    "infos = {\n",
    "    \"test_gain_mean\": test_gain_mean,\n",
    "    \"test_avg_loss_ratio\": test_avg_loss_ratio,\n",
    "    \"val_gain_mean\": gain_mean(yTest, yPred),\n",
    "    \"val_avg_loss_ratio\": avg_loss_ratio(yTest, yPred),\n",
    "    \"top_columns\": list(top_columns),\n",
    "    \"pdf\": pdf.tolist(),\n",
    "    \"acc\": 1 - avg_loss_ratio(yTest, yPred),\n",
    "    \"bins_pdf\": bins_pdf.tolist(),\n",
    "    \"train_err_pdf\": train_err_pdf.tolist(),\n",
    "    \"bins_train_err_pdf\": bins_train_err_pdf.tolist()\n",
    "}\n",
    "\n",
    "save_actual = False\n",
    "old_infos = {}\n",
    "if os.path.exists(infos_filename):\n",
    "    with open(infos_filename) as inp_f:\n",
    "        old_infos = json.load(inp_f)\n",
    "        \n",
    "if old_infos:\n",
    "    if infos[\"test_avg_loss_ratio\"] < old_infos[\"test_avg_loss_ratio\"]:\n",
    "        save_actual = True\n",
    "else:\n",
    "    save_actual = True\n",
    "\n",
    "\n",
    "if save_actual:\n",
    "    with open(infos_filename, \"w\") as out_f:\n",
    "        json.dump(infos, out_f, indent=4)\n",
    "    df_final.to_excel(\"../data/t10/test_PRED.xls\", index=False)\n",
    "    joblib.dump(value=model, filename=model_filename)\n",
    "    print(\"Saved new data\")\n",
    "else:\n",
    "    print(\"Kept old data\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ai_offer = 110\n",
    "offer = 95\n",
    "\n",
    "delta = ai_offer - offer\n",
    "\n",
    "@np.vectorize\n",
    "def sigmoid1024(x):\n",
    "    base = 2000.0**2\n",
    "    return (base**x/(base**x + 1))\n",
    "\n",
    "@np.vectorize\n",
    "def loss(x):\n",
    "    offset = +5\n",
    "    x1 = (x + offset) / 16.0\n",
    "    x2 = (x) / 40.0\n",
    "    return (1 - sigmoid1024(x1) *  np.cos(x2/np.pi))\n",
    "\n",
    "def gain(x):\n",
    "    return 1 - loss(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.gain(x)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dy = top_model.predict(xTrain) - yTrain.ravel()\n",
    "#plt.plot(dy)\n",
    "vals, bins = np.histogram(dy, bins=np.arange(-200, 200, 5), density=True)\n",
    "\n",
    "\n",
    "_ = plt.hist(dy, density=True, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f57cfd01518>]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nvals = vals/vals.max() * (1 - 0.22)\n",
    "\n",
    "plt.plot(nvals, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06381502890173411"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_offer = 100\n",
    "offer = 50\n",
    "\n",
    "err = ai_offer - offer\n",
    "\n",
    "idx = int((err + 200)/5)\n",
    "\n",
    "n_train_err_pdf = train_err_pdf / train_err_pdf.max()\n",
    "\n",
    "n_train_err_pdf[30] * 0.92"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
