{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "      <th>q4</th>\n",
       "      <th>q5</th>\n",
       "      <th>q6</th>\n",
       "      <th>q7</th>\n",
       "      <th>q8</th>\n",
       "      <th>q9</th>\n",
       "      <th>q10</th>\n",
       "      <th>...</th>\n",
       "      <th>equal_income</th>\n",
       "      <th>asian</th>\n",
       "      <th>white</th>\n",
       "      <th>lazy_stupid</th>\n",
       "      <th>diligent</th>\n",
       "      <th>completely_selfish</th>\n",
       "      <th>complete_donor</th>\n",
       "      <th>expect_50less</th>\n",
       "      <th>expect_100</th>\n",
       "      <th>min_offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   q1  q2  q3  q4  q5  q6  q7  q8  q9  q10    ...      equal_income  asian  \\\n",
       "0   2   4   1   2   4   2   5   4   2    5    ...                 0      0   \n",
       "1   3   1   5   1   4   5   5   1   3    2    ...                 0      0   \n",
       "2   3   4   3   4   2   5   3   3   2    4    ...                 0      0   \n",
       "3   4   4   2   4   3   3   4   4   2    4    ...                 0      0   \n",
       "4   4   4   2   4   4   2   5   4   3    5    ...                 0      0   \n",
       "\n",
       "   white  lazy_stupid  diligent  completely_selfish  complete_donor  \\\n",
       "0      0            0         0                   0               0   \n",
       "1      0            1         0                   1               0   \n",
       "2      0            1         0                   0               0   \n",
       "3      0            1         0                   0               0   \n",
       "4      0            0         0                   0               0   \n",
       "\n",
       "   expect_50less  expect_100  min_offer  \n",
       "0              0           0         80  \n",
       "1              1           0         50  \n",
       "2              0           1        100  \n",
       "3              0           1        100  \n",
       "4              0           0         95  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sb\n",
    "\n",
    "df = pd.read_excel(\"../data/UG_HH_NEW_categorical_no200.xls\")\n",
    "df = df.dropna()\n",
    "\n",
    "df_full = pd.read_excel(\"../data/UG_HH_NEW_continuous_no200.xls\")\n",
    "df_min = df_full.min()\n",
    "df_max = df_full.max()\n",
    "\n",
    "#Drop 'protected' features\n",
    "drop_cols = ['prop', 'other_prop', 'other_resp']\n",
    "df = df[[col for col in df if col not in drop_cols]]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sb.pairplot(df, x_vars=('prop','other_resp','other_prop'), y_vars='min_offer', height=7, aspect=0.7, kind='reg')\n",
    "# sb.pairplot(df, x_vars=('cells', 'selfish','count_effort'), y_vars='min_offer', height=7, aspect=0.7)\n",
    "# sb.pairplot(df, x_vars=('Honesty_Humility', 'Extraversion','Agreeableness'), y_vars='min_offer', height=7, aspect=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine significant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q26</th>\n",
       "      <td>27.164286</td>\n",
       "      <td>0.218293</td>\n",
       "      <td>25.215990</td>\n",
       "      <td>967.0</td>\n",
       "      <td>1470.575397</td>\n",
       "      <td>0.060782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>27.049206</td>\n",
       "      <td>0.218445</td>\n",
       "      <td>24.688663</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1491.158730</td>\n",
       "      <td>0.063902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q12</th>\n",
       "      <td>27.049206</td>\n",
       "      <td>0.219333</td>\n",
       "      <td>24.239084</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1518.658730</td>\n",
       "      <td>0.067143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>27.049206</td>\n",
       "      <td>0.219333</td>\n",
       "      <td>24.239084</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1518.658730</td>\n",
       "      <td>0.067143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genius</th>\n",
       "      <td>27.049206</td>\n",
       "      <td>0.219333</td>\n",
       "      <td>24.239084</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1518.658730</td>\n",
       "      <td>0.067143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asian</th>\n",
       "      <td>27.049206</td>\n",
       "      <td>0.219333</td>\n",
       "      <td>24.239084</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1518.658730</td>\n",
       "      <td>0.067143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>27.104762</td>\n",
       "      <td>0.219796</td>\n",
       "      <td>24.299690</td>\n",
       "      <td>965.0</td>\n",
       "      <td>1521.436508</td>\n",
       "      <td>0.066989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q3</th>\n",
       "      <td>27.220635</td>\n",
       "      <td>0.220885</td>\n",
       "      <td>24.426584</td>\n",
       "      <td>969.0</td>\n",
       "      <td>1523.515873</td>\n",
       "      <td>0.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q29</th>\n",
       "      <td>27.220635</td>\n",
       "      <td>0.220975</td>\n",
       "      <td>24.415869</td>\n",
       "      <td>969.0</td>\n",
       "      <td>1521.801587</td>\n",
       "      <td>0.070571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donation_c</th>\n",
       "      <td>27.550000</td>\n",
       "      <td>0.221657</td>\n",
       "      <td>25.626380</td>\n",
       "      <td>981.0</td>\n",
       "      <td>1488.750000</td>\n",
       "      <td>0.060845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donation_b</th>\n",
       "      <td>27.494444</td>\n",
       "      <td>0.222280</td>\n",
       "      <td>25.108020</td>\n",
       "      <td>979.0</td>\n",
       "      <td>1507.964286</td>\n",
       "      <td>0.063032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q8</th>\n",
       "      <td>27.633333</td>\n",
       "      <td>0.224001</td>\n",
       "      <td>24.881291</td>\n",
       "      <td>984.0</td>\n",
       "      <td>1556.579365</td>\n",
       "      <td>0.067143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q9</th>\n",
       "      <td>27.548413</td>\n",
       "      <td>0.224493</td>\n",
       "      <td>24.276461</td>\n",
       "      <td>981.0</td>\n",
       "      <td>1571.678571</td>\n",
       "      <td>0.079697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity</th>\n",
       "      <td>27.820635</td>\n",
       "      <td>0.224555</td>\n",
       "      <td>25.433943</td>\n",
       "      <td>990.0</td>\n",
       "      <td>1538.515873</td>\n",
       "      <td>0.062898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q4</th>\n",
       "      <td>27.620635</td>\n",
       "      <td>0.225058</td>\n",
       "      <td>24.406768</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1575.801587</td>\n",
       "      <td>0.069102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donation_a</th>\n",
       "      <td>27.854762</td>\n",
       "      <td>0.225382</td>\n",
       "      <td>25.503640</td>\n",
       "      <td>992.0</td>\n",
       "      <td>1522.551587</td>\n",
       "      <td>0.062560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q17</th>\n",
       "      <td>27.872222</td>\n",
       "      <td>0.225556</td>\n",
       "      <td>25.523377</td>\n",
       "      <td>992.0</td>\n",
       "      <td>1527.130952</td>\n",
       "      <td>0.062967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>27.677778</td>\n",
       "      <td>0.225561</td>\n",
       "      <td>24.438558</td>\n",
       "      <td>985.0</td>\n",
       "      <td>1577.515873</td>\n",
       "      <td>0.068776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Europe</th>\n",
       "      <td>28.042063</td>\n",
       "      <td>0.225649</td>\n",
       "      <td>26.103436</td>\n",
       "      <td>998.0</td>\n",
       "      <td>1517.353175</td>\n",
       "      <td>0.058921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal_income</th>\n",
       "      <td>27.572222</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>23.797917</td>\n",
       "      <td>982.0</td>\n",
       "      <td>1593.067460</td>\n",
       "      <td>0.095471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q19</th>\n",
       "      <td>27.936508</td>\n",
       "      <td>0.226337</td>\n",
       "      <td>25.669886</td>\n",
       "      <td>995.0</td>\n",
       "      <td>1523.166667</td>\n",
       "      <td>0.069209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>27.938095</td>\n",
       "      <td>0.226390</td>\n",
       "      <td>25.198085</td>\n",
       "      <td>995.0</td>\n",
       "      <td>1578.936508</td>\n",
       "      <td>0.065291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q13</th>\n",
       "      <td>28.084127</td>\n",
       "      <td>0.227516</td>\n",
       "      <td>25.819995</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1532.674603</td>\n",
       "      <td>0.071432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q27</th>\n",
       "      <td>27.919841</td>\n",
       "      <td>0.227748</td>\n",
       "      <td>24.658604</td>\n",
       "      <td>994.0</td>\n",
       "      <td>1586.670635</td>\n",
       "      <td>0.074966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q24</th>\n",
       "      <td>28.102381</td>\n",
       "      <td>0.227945</td>\n",
       "      <td>25.295287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1576.924603</td>\n",
       "      <td>0.064412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q14</th>\n",
       "      <td>28.188095</td>\n",
       "      <td>0.228849</td>\n",
       "      <td>25.461900</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>1581.575397</td>\n",
       "      <td>0.063748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expect_50less</th>\n",
       "      <td>26.493651</td>\n",
       "      <td>0.229416</td>\n",
       "      <td>19.460685</td>\n",
       "      <td>943.0</td>\n",
       "      <td>1566.436508</td>\n",
       "      <td>0.199306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q5</th>\n",
       "      <td>28.548413</td>\n",
       "      <td>0.229580</td>\n",
       "      <td>26.662744</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1553.130952</td>\n",
       "      <td>0.059503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q23</th>\n",
       "      <td>28.271429</td>\n",
       "      <td>0.229705</td>\n",
       "      <td>25.557956</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1571.119048</td>\n",
       "      <td>0.074555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complete_donor</th>\n",
       "      <td>28.473810</td>\n",
       "      <td>0.231102</td>\n",
       "      <td>26.156306</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1551.289683</td>\n",
       "      <td>0.062587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q21</th>\n",
       "      <td>28.478571</td>\n",
       "      <td>0.231952</td>\n",
       "      <td>25.236352</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1625.273810</td>\n",
       "      <td>0.077717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q2</th>\n",
       "      <td>28.538889</td>\n",
       "      <td>0.232833</td>\n",
       "      <td>25.410196</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1621.234127</td>\n",
       "      <td>0.069417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q1</th>\n",
       "      <td>28.534921</td>\n",
       "      <td>0.233516</td>\n",
       "      <td>24.896335</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1656.658730</td>\n",
       "      <td>0.075633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q30</th>\n",
       "      <td>28.634921</td>\n",
       "      <td>0.233884</td>\n",
       "      <td>25.486863</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1614.849206</td>\n",
       "      <td>0.106143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q7</th>\n",
       "      <td>28.739683</td>\n",
       "      <td>0.234029</td>\n",
       "      <td>25.592135</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1648.936508</td>\n",
       "      <td>0.066725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q25</th>\n",
       "      <td>28.825397</td>\n",
       "      <td>0.235025</td>\n",
       "      <td>25.615206</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>1639.777778</td>\n",
       "      <td>0.068026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q10</th>\n",
       "      <td>29.207937</td>\n",
       "      <td>0.237119</td>\n",
       "      <td>27.007576</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>1583.071429</td>\n",
       "      <td>0.064555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mood</th>\n",
       "      <td>29.411905</td>\n",
       "      <td>0.239683</td>\n",
       "      <td>26.758080</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>1626.273810</td>\n",
       "      <td>0.061762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>29.669841</td>\n",
       "      <td>0.242947</td>\n",
       "      <td>26.132520</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>1721.920635</td>\n",
       "      <td>0.077254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q18</th>\n",
       "      <td>29.510317</td>\n",
       "      <td>0.243803</td>\n",
       "      <td>24.950605</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>1750.599206</td>\n",
       "      <td>0.108311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lazy_stupid</th>\n",
       "      <td>29.993651</td>\n",
       "      <td>0.249697</td>\n",
       "      <td>24.852064</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1824.769841</td>\n",
       "      <td>0.097235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q28</th>\n",
       "      <td>30.667460</td>\n",
       "      <td>0.249876</td>\n",
       "      <td>28.165179</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>1705.472222</td>\n",
       "      <td>0.064718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diligent</th>\n",
       "      <td>30.250000</td>\n",
       "      <td>0.253335</td>\n",
       "      <td>24.450486</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1851.535714</td>\n",
       "      <td>0.129844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q16</th>\n",
       "      <td>30.338889</td>\n",
       "      <td>0.253843</td>\n",
       "      <td>24.547251</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1869.535714</td>\n",
       "      <td>0.133778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completely_selfish</th>\n",
       "      <td>30.642857</td>\n",
       "      <td>0.254171</td>\n",
       "      <td>25.634689</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1833.738095</td>\n",
       "      <td>0.085722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q22</th>\n",
       "      <td>31.295238</td>\n",
       "      <td>0.257987</td>\n",
       "      <td>27.780208</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>1768.888889</td>\n",
       "      <td>0.091009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>31.275397</td>\n",
       "      <td>0.259097</td>\n",
       "      <td>26.262031</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>1874.559524</td>\n",
       "      <td>0.095115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q6</th>\n",
       "      <td>31.477778</td>\n",
       "      <td>0.260742</td>\n",
       "      <td>26.669873</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>1891.682540</td>\n",
       "      <td>0.095205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q11</th>\n",
       "      <td>31.573016</td>\n",
       "      <td>0.264669</td>\n",
       "      <td>25.350860</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>1967.285714</td>\n",
       "      <td>0.115991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q20</th>\n",
       "      <td>32.544444</td>\n",
       "      <td>0.267421</td>\n",
       "      <td>29.658266</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>1820.198413</td>\n",
       "      <td>0.065463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rich</th>\n",
       "      <td>32.050794</td>\n",
       "      <td>0.267636</td>\n",
       "      <td>26.130189</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>1963.880952</td>\n",
       "      <td>0.114732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not_a_genius</th>\n",
       "      <td>31.993651</td>\n",
       "      <td>0.270307</td>\n",
       "      <td>25.582834</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>2031.436508</td>\n",
       "      <td>0.122698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>32.437302</td>\n",
       "      <td>0.271503</td>\n",
       "      <td>26.014213</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>2017.948413</td>\n",
       "      <td>0.120357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expect_100</th>\n",
       "      <td>33.406349</td>\n",
       "      <td>0.288553</td>\n",
       "      <td>24.119866</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>2153.531746</td>\n",
       "      <td>0.223826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crt_performance</th>\n",
       "      <td>35.000794</td>\n",
       "      <td>0.297680</td>\n",
       "      <td>27.401640</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>2283.361111</td>\n",
       "      <td>0.139515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q15</th>\n",
       "      <td>35.237302</td>\n",
       "      <td>0.299830</td>\n",
       "      <td>26.969582</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>2291.194444</td>\n",
       "      <td>0.132186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>almost_genius</th>\n",
       "      <td>37.188095</td>\n",
       "      <td>0.321737</td>\n",
       "      <td>27.374378</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2545.464286</td>\n",
       "      <td>0.172698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     avg_loss  avg_loss_ratio  avg_win_loss  loss_sum  \\\n",
       "q26                 27.164286        0.218293     25.215990     967.0   \n",
       "India               27.049206        0.218445     24.688663     963.0   \n",
       "q12                 27.049206        0.219333     24.239084     963.0   \n",
       "USA                 27.049206        0.219333     24.239084     963.0   \n",
       "genius              27.049206        0.219333     24.239084     963.0   \n",
       "asian               27.049206        0.219333     24.239084     963.0   \n",
       "white               27.104762        0.219796     24.299690     965.0   \n",
       "q3                  27.220635        0.220885     24.426584     969.0   \n",
       "q29                 27.220635        0.220975     24.415869     969.0   \n",
       "donation_c          27.550000        0.221657     25.626380     981.0   \n",
       "donation_b          27.494444        0.222280     25.108020     979.0   \n",
       "q8                  27.633333        0.224001     24.881291     984.0   \n",
       "q9                  27.548413        0.224493     24.276461     981.0   \n",
       "ethnicity           27.820635        0.224555     25.433943     990.0   \n",
       "q4                  27.620635        0.225058     24.406768     983.0   \n",
       "donation_a          27.854762        0.225382     25.503640     992.0   \n",
       "q17                 27.872222        0.225556     25.523377     992.0   \n",
       "age                 27.677778        0.225561     24.438558     985.0   \n",
       "Europe              28.042063        0.225649     26.103436     998.0   \n",
       "equal_income        27.572222        0.226000     23.797917     982.0   \n",
       "q19                 27.936508        0.226337     25.669886     995.0   \n",
       "male                27.938095        0.226390     25.198085     995.0   \n",
       "q13                 28.084127        0.227516     25.819995    1000.0   \n",
       "q27                 27.919841        0.227748     24.658604     994.0   \n",
       "q24                 28.102381        0.227945     25.295287    1000.0   \n",
       "q14                 28.188095        0.228849     25.461900    1004.0   \n",
       "expect_50less       26.493651        0.229416     19.460685     943.0   \n",
       "q5                  28.548413        0.229580     26.662744    1016.0   \n",
       "q23                 28.271429        0.229705     25.557956    1007.0   \n",
       "complete_donor      28.473810        0.231102     26.156306    1014.0   \n",
       "q21                 28.478571        0.231952     25.236352    1013.0   \n",
       "q2                  28.538889        0.232833     25.410196    1016.0   \n",
       "q1                  28.534921        0.233516     24.896335    1015.0   \n",
       "q30                 28.634921        0.233884     25.486863    1020.0   \n",
       "q7                  28.739683        0.234029     25.592135    1023.0   \n",
       "q25                 28.825397        0.235025     25.615206    1026.0   \n",
       "q10                 29.207937        0.237119     27.007576    1040.0   \n",
       "mood                29.411905        0.239683     26.758080    1047.0   \n",
       "country             29.669841        0.242947     26.132520    1056.0   \n",
       "q18                 29.510317        0.243803     24.950605    1051.0   \n",
       "lazy_stupid         29.993651        0.249697     24.852064    1069.0   \n",
       "q28                 30.667460        0.249876     28.165179    1092.0   \n",
       "diligent            30.250000        0.253335     24.450486    1078.0   \n",
       "q16                 30.338889        0.253843     24.547251    1080.0   \n",
       "completely_selfish  30.642857        0.254171     25.634689    1091.0   \n",
       "q22                 31.295238        0.257987     27.780208    1113.0   \n",
       "poor                31.275397        0.259097     26.262031    1114.0   \n",
       "q6                  31.477778        0.260742     26.669873    1121.0   \n",
       "q11                 31.573016        0.264669     25.350860    1126.0   \n",
       "q20                 32.544444        0.267421     29.658266    1158.0   \n",
       "rich                32.050794        0.267636     26.130189    1142.0   \n",
       "not_a_genius        31.993651        0.270307     25.582834    1141.0   \n",
       "income              32.437302        0.271503     26.014213    1156.0   \n",
       "expect_100          33.406349        0.288553     24.119866    1191.0   \n",
       "crt_performance     35.000794        0.297680     27.401640    1248.0   \n",
       "q15                 35.237302        0.299830     26.969582    1255.0   \n",
       "almost_genius       37.188095        0.321737     27.374378    1328.0   \n",
       "\n",
       "                            mse  rejection_ratio  \n",
       "q26                 1470.575397         0.060782  \n",
       "India               1491.158730         0.063902  \n",
       "q12                 1518.658730         0.067143  \n",
       "USA                 1518.658730         0.067143  \n",
       "genius              1518.658730         0.067143  \n",
       "asian               1518.658730         0.067143  \n",
       "white               1521.436508         0.066989  \n",
       "q3                  1523.515873         0.066000  \n",
       "q29                 1521.801587         0.070571  \n",
       "donation_c          1488.750000         0.060845  \n",
       "donation_b          1507.964286         0.063032  \n",
       "q8                  1556.579365         0.067143  \n",
       "q9                  1571.678571         0.079697  \n",
       "ethnicity           1538.515873         0.062898  \n",
       "q4                  1575.801587         0.069102  \n",
       "donation_a          1522.551587         0.062560  \n",
       "q17                 1527.130952         0.062967  \n",
       "age                 1577.515873         0.068776  \n",
       "Europe              1517.353175         0.058921  \n",
       "equal_income        1593.067460         0.095471  \n",
       "q19                 1523.166667         0.069209  \n",
       "male                1578.936508         0.065291  \n",
       "q13                 1532.674603         0.071432  \n",
       "q27                 1586.670635         0.074966  \n",
       "q24                 1576.924603         0.064412  \n",
       "q14                 1581.575397         0.063748  \n",
       "expect_50less       1566.436508         0.199306  \n",
       "q5                  1553.130952         0.059503  \n",
       "q23                 1571.119048         0.074555  \n",
       "complete_donor      1551.289683         0.062587  \n",
       "q21                 1625.273810         0.077717  \n",
       "q2                  1621.234127         0.069417  \n",
       "q1                  1656.658730         0.075633  \n",
       "q30                 1614.849206         0.106143  \n",
       "q7                  1648.936508         0.066725  \n",
       "q25                 1639.777778         0.068026  \n",
       "q10                 1583.071429         0.064555  \n",
       "mood                1626.273810         0.061762  \n",
       "country             1721.920635         0.077254  \n",
       "q18                 1750.599206         0.108311  \n",
       "lazy_stupid         1824.769841         0.097235  \n",
       "q28                 1705.472222         0.064718  \n",
       "diligent            1851.535714         0.129844  \n",
       "q16                 1869.535714         0.133778  \n",
       "completely_selfish  1833.738095         0.085722  \n",
       "q22                 1768.888889         0.091009  \n",
       "poor                1874.559524         0.095115  \n",
       "q6                  1891.682540         0.095205  \n",
       "q11                 1967.285714         0.115991  \n",
       "q20                 1820.198413         0.065463  \n",
       "rich                1963.880952         0.114732  \n",
       "not_a_genius        2031.436508         0.122698  \n",
       "income              2017.948413         0.120357  \n",
       "expect_100          2153.531746         0.223826  \n",
       "crt_performance     2283.361111         0.139515  \n",
       "q15                 2291.194444         0.132186  \n",
       "almost_genius       2545.464286         0.172698  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.preprocessing import df_to_xy, df_to_xydf\n",
    "from models import AcceptanceModel\n",
    "from utils.benchmark import process_model, process_benchmark_cv\n",
    "\n",
    "res = {}\n",
    "features = list(df)\n",
    "if 'min_offer' in features:\n",
    "    features.remove('min_offer')\n",
    "for col in features:\n",
    "    if col == 'risk':    \n",
    "        x, y = df_to_xy(df, select_columns=[col], fuse_risk=True, df_min=df_min, df_max=df_max)\n",
    "        col = 'risk*'\n",
    "    else:\n",
    "        x, y = df_to_xy(df, select_columns=[col], df_min=df_min, df_max=df_max)\n",
    "    model = AcceptanceModel()\n",
    "    item_res = process_benchmark_cv(model, X=x, y=y)\n",
    "    res[col] = item_res.mean()\n",
    "\n",
    "res_single_df = pd.DataFrame(res).T\n",
    "res_single_df.sort_values(by=['avg_loss_ratio'], inplace=True)\n",
    "res_single_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q26:q29</th>\n",
       "      <td>26.792857</td>\n",
       "      <td>0.215351</td>\n",
       "      <td>24.822051</td>\n",
       "      <td>954.0</td>\n",
       "      <td>1445.003968</td>\n",
       "      <td>0.064047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q26:asian</th>\n",
       "      <td>26.821429</td>\n",
       "      <td>0.215440</td>\n",
       "      <td>24.852354</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1451.718254</td>\n",
       "      <td>0.062905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q4:q29</th>\n",
       "      <td>26.715873</td>\n",
       "      <td>0.215463</td>\n",
       "      <td>24.343128</td>\n",
       "      <td>951.0</td>\n",
       "      <td>1479.730159</td>\n",
       "      <td>0.067550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q26:white</th>\n",
       "      <td>26.849206</td>\n",
       "      <td>0.215671</td>\n",
       "      <td>24.882657</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1452.968254</td>\n",
       "      <td>0.062905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q16:India</th>\n",
       "      <td>26.771429</td>\n",
       "      <td>0.215807</td>\n",
       "      <td>24.400271</td>\n",
       "      <td>953.0</td>\n",
       "      <td>1487.269841</td>\n",
       "      <td>0.066989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q4:white</th>\n",
       "      <td>26.854762</td>\n",
       "      <td>0.216678</td>\n",
       "      <td>24.487716</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1483.797619</td>\n",
       "      <td>0.066526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q4:donation_b</th>\n",
       "      <td>26.994444</td>\n",
       "      <td>0.216871</td>\n",
       "      <td>25.030709</td>\n",
       "      <td>961.0</td>\n",
       "      <td>1462.964286</td>\n",
       "      <td>0.062723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donation_b:ethnicity</th>\n",
       "      <td>27.022222</td>\n",
       "      <td>0.217017</td>\n",
       "      <td>25.059280</td>\n",
       "      <td>962.0</td>\n",
       "      <td>1468.103175</td>\n",
       "      <td>0.062569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q3:donation_b</th>\n",
       "      <td>27.022222</td>\n",
       "      <td>0.217017</td>\n",
       "      <td>25.059280</td>\n",
       "      <td>962.0</td>\n",
       "      <td>1468.103175</td>\n",
       "      <td>0.062569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q12:q13</th>\n",
       "      <td>27.100000</td>\n",
       "      <td>0.217970</td>\n",
       "      <td>25.168290</td>\n",
       "      <td>965.0</td>\n",
       "      <td>1461.285714</td>\n",
       "      <td>0.074830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       avg_loss  avg_loss_ratio  avg_win_loss  loss_sum  \\\n",
       "q26:q29               26.792857        0.215351     24.822051     954.0   \n",
       "q26:asian             26.821429        0.215440     24.852354     955.0   \n",
       "q4:q29                26.715873        0.215463     24.343128     951.0   \n",
       "q26:white             26.849206        0.215671     24.882657     956.0   \n",
       "q16:India             26.771429        0.215807     24.400271     953.0   \n",
       "q4:white              26.854762        0.216678     24.487716     956.0   \n",
       "q4:donation_b         26.994444        0.216871     25.030709     961.0   \n",
       "donation_b:ethnicity  27.022222        0.217017     25.059280     962.0   \n",
       "q3:donation_b         27.022222        0.217017     25.059280     962.0   \n",
       "q12:q13               27.100000        0.217970     25.168290     965.0   \n",
       "\n",
       "                              mse  rejection_ratio  \n",
       "q26:q29               1445.003968         0.064047  \n",
       "q26:asian             1451.718254         0.062905  \n",
       "q4:q29                1479.730159         0.067550  \n",
       "q26:white             1452.968254         0.062905  \n",
       "q16:India             1487.269841         0.066989  \n",
       "q4:white              1483.797619         0.066526  \n",
       "q4:donation_b         1462.964286         0.062723  \n",
       "donation_b:ethnicity  1468.103175         0.062569  \n",
       "q3:donation_b         1468.103175         0.062569  \n",
       "q12:q13               1461.285714         0.074830  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "features = list(df)\n",
    "if 'min_offer' in features:\n",
    "    features.remove('min_offer')\n",
    "\n",
    "res = {}\n",
    "for cols in combinations(features, 2):\n",
    "    #index should be a list\n",
    "    cols = list(cols)\n",
    "    if cols[0]==cols[1]: continue\n",
    "    x, y = df_to_xy(df, select_columns=cols, df_min=df_min, df_max=df_max)\n",
    "    model = AcceptanceModel()\n",
    "    item_res = process_benchmark_cv(model, X=x, y=y)\n",
    "    res[\":\".join(cols)] = item_res.mean()\n",
    "\n",
    "res_duo_df = pd.DataFrame(res).T\n",
    "res_duo_df.sort_values(by=['avg_loss_ratio'], inplace=True)\n",
    "res_duo_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_loss</th>\n",
       "      <th>avg_loss_ratio</th>\n",
       "      <th>avg_win_loss</th>\n",
       "      <th>loss_sum</th>\n",
       "      <th>mse</th>\n",
       "      <th>rejection_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q4:q26:asian</th>\n",
       "      <td>26.738095</td>\n",
       "      <td>0.214699</td>\n",
       "      <td>24.766640</td>\n",
       "      <td>952.0</td>\n",
       "      <td>1448.523810</td>\n",
       "      <td>0.063368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q12:q16:white</th>\n",
       "      <td>26.688095</td>\n",
       "      <td>0.215220</td>\n",
       "      <td>24.310931</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1478.519841</td>\n",
       "      <td>0.073470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q4:q12:white</th>\n",
       "      <td>26.715873</td>\n",
       "      <td>0.215335</td>\n",
       "      <td>24.347538</td>\n",
       "      <td>951.0</td>\n",
       "      <td>1482.269841</td>\n",
       "      <td>0.066063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q26:genius:asian</th>\n",
       "      <td>26.821429</td>\n",
       "      <td>0.215440</td>\n",
       "      <td>24.852354</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1451.718254</td>\n",
       "      <td>0.062905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q26:USA:asian</th>\n",
       "      <td>26.821429</td>\n",
       "      <td>0.215440</td>\n",
       "      <td>24.852354</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1451.718254</td>\n",
       "      <td>0.062905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q4:q29:USA</th>\n",
       "      <td>26.717460</td>\n",
       "      <td>0.215454</td>\n",
       "      <td>24.348485</td>\n",
       "      <td>951.0</td>\n",
       "      <td>1479.301587</td>\n",
       "      <td>0.067532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q26:age:USA</th>\n",
       "      <td>26.850000</td>\n",
       "      <td>0.215649</td>\n",
       "      <td>24.875731</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1454.718254</td>\n",
       "      <td>0.063394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q26:asian:white</th>\n",
       "      <td>26.849206</td>\n",
       "      <td>0.215671</td>\n",
       "      <td>24.882657</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1452.968254</td>\n",
       "      <td>0.062905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q26:USA:white</th>\n",
       "      <td>26.849206</td>\n",
       "      <td>0.215671</td>\n",
       "      <td>24.882657</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1452.968254</td>\n",
       "      <td>0.062905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q26:ethnicity:asian</th>\n",
       "      <td>26.849206</td>\n",
       "      <td>0.215718</td>\n",
       "      <td>24.880925</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1451.857143</td>\n",
       "      <td>0.062596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      avg_loss  avg_loss_ratio  avg_win_loss  loss_sum  \\\n",
       "q4:q26:asian         26.738095        0.214699     24.766640     952.0   \n",
       "q12:q16:white        26.688095        0.215220     24.310931     950.0   \n",
       "q4:q12:white         26.715873        0.215335     24.347538     951.0   \n",
       "q26:genius:asian     26.821429        0.215440     24.852354     955.0   \n",
       "q26:USA:asian        26.821429        0.215440     24.852354     955.0   \n",
       "q4:q29:USA           26.717460        0.215454     24.348485     951.0   \n",
       "q26:age:USA          26.850000        0.215649     24.875731     956.0   \n",
       "q26:asian:white      26.849206        0.215671     24.882657     956.0   \n",
       "q26:USA:white        26.849206        0.215671     24.882657     956.0   \n",
       "q26:ethnicity:asian  26.849206        0.215718     24.880925     956.0   \n",
       "\n",
       "                             mse  rejection_ratio  \n",
       "q4:q26:asian         1448.523810         0.063368  \n",
       "q12:q16:white        1478.519841         0.073470  \n",
       "q4:q12:white         1482.269841         0.066063  \n",
       "q26:genius:asian     1451.718254         0.062905  \n",
       "q26:USA:asian        1451.718254         0.062905  \n",
       "q4:q29:USA           1479.301587         0.067532  \n",
       "q26:age:USA          1454.718254         0.063394  \n",
       "q26:asian:white      1452.968254         0.062905  \n",
       "q26:USA:white        1452.968254         0.062905  \n",
       "q26:ethnicity:asian  1451.857143         0.062596  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "features = list(df)\n",
    "if 'min_offer' in features:\n",
    "    features.remove('min_offer')\n",
    "\n",
    "res = {}\n",
    "for cols in combinations(features, 3):\n",
    "    #index should be a list\n",
    "    cols = list(cols)\n",
    "    if cols[0]==cols[1]: continue\n",
    "    x, y = df_to_xy(df, select_columns=cols, df_min=df_min, df_max=df_max)\n",
    "    model = AcceptanceModel()\n",
    "    item_res = process_benchmark_cv(model, X=x, y=y)\n",
    "    res[\":\".join(cols)] = item_res.mean()\n",
    "\n",
    "res_trio_df = pd.DataFrame(res).T\n",
    "res_trio_df.sort_values(by=['avg_loss_ratio'], inplace=True)\n",
    "res_trio_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "features = list(df)\n",
    "if 'min_offer' in features:\n",
    "    features.remove('min_offer')\n",
    "\n",
    "res = {}\n",
    "for cols in combinations(features, 4):\n",
    "    #index should be a list\n",
    "    cols = list(cols)\n",
    "    if cols[0]==cols[1]: continue\n",
    "    x, y = df_to_xy(df, select_columns=cols, df_min=df_min, df_max=df_max)\n",
    "    model = AcceptanceModel()\n",
    "    item_res = process_benchmark_cv(model, X=x, y=y)\n",
    "    res[\":\".join(cols)] = item_res.mean()\n",
    "\n",
    "res_quad_df = pd.DataFrame(res).T\n",
    "res_quad_df.sort_values(by=['avg_loss_ratio'], inplace=True)\n",
    "res_quad_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_columns = ['selfish', 'time_spent_prop']\n",
    "x, y = df_to_xy(df, select_columns=top_columns, min_target=20, max_target=180)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(x.shape[0] * 0.6)\n",
    "xTrain, yTrain = x[:split], y[:split]\n",
    "xTest, yTest = x[split:], y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AcceptanceModel()\n",
    "model.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean gain:  97.65625\n",
      "AVG loss ratio:  0.16550664472329668\n"
     ]
    }
   ],
   "source": [
    "from models.metrics import gain_mean, avg_loss_ratio\n",
    "yPred = model.predict(xTest)\n",
    "print(\"Mean gain: \", gain_mean(yTest, yPred))\n",
    "print(\"AVG loss ratio: \", avg_loss_ratio(yTest, yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted values:  [ 95. 100. 105. 110.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique predicted values: \", np.unique(yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
